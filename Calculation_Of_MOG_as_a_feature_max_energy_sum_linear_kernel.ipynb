{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy0\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:0\n",
      "The SheetValueTestis:1\n",
      "[  3191.66832918   6975.55735661  16293.3553616    8498.53491272\n",
      "   3863.44014963   5340.91521197  13220.97007481  10737.44139651]\n",
      "[  5.56265536e+07   1.64496836e+08   4.93904559e+08   2.87980101e+08\n",
      "   7.95892515e+07   1.23300053e+08   4.08940736e+08   3.74078890e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.985039 (0.006366)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=0.5, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.990016 (0.005012)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.992531 (0.006083)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.99      1.00      1.00       101\n",
      "      Human       1.00      0.98      0.99        49\n",
      "     Animal       1.00      1.00      1.00        52\n",
      "\n",
      "avg / total       1.00      1.00      1.00       202\n",
      "\n",
      "The accuracy is:0.99504950495\n",
      "The confusion_matrix is:\n",
      "[[101   0   0]\n",
      " [  1  48   0]\n",
      " [  0   0  52]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.99      1.00       101\n",
      "      Human       1.00      1.00      1.00        49\n",
      "     Animal       0.98      1.00      0.99        52\n",
      "\n",
      "avg / total       1.00      1.00      1.00       202\n",
      "\n",
      "The accuracy is:0.99504950495\n",
      "The confusion_matrix is:\n",
      "[[100   0   1]\n",
      " [  0  49   0]\n",
      " [  0   0  52]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.98      0.99       101\n",
      "      Human       0.98      1.00      0.99        49\n",
      "     Animal       0.98      1.00      0.99        52\n",
      "\n",
      "avg / total       0.99      0.99      0.99       202\n",
      "\n",
      "The accuracy is:0.990099009901\n",
      "The confusion_matrix is:\n",
      "[[99  1  1]\n",
      " [ 0 49  0]\n",
      " [ 0  0 52]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc   SVM_acc    KNN_acc\n",
      "0          99.50495  99.50495  99.009901\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                  DecisionTree_acc                          SVM_acc  \\\n",
      "0  [101, 0, 0, 1, 48, 0, 0, 0, 52]  [100, 0, 1, 0, 49, 0, 0, 0, 52]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [99, 1, 1, 0, 49, 0, 0, 0, 52]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy1\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:2\n",
      "The SheetValueTestis:3\n",
      "[  3201.26184539   6894.79800499  16157.64339152   8983.53366584\n",
      "   3983.31421446   5480.0074813   13619.27306733  11340.96009975]\n",
      "[  5.74336400e+07   1.61313742e+08   4.84320211e+08   2.91562970e+08\n",
      "   8.26885271e+07   1.22219622e+08   4.15730429e+08   3.98861714e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.990039 (0.008426)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=5.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.991273 (0.003049)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.988781 (0.008287)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.99      0.99      0.99       101\n",
      "      Human       0.98      0.98      0.98        49\n",
      "     Animal       1.00      1.00      1.00        52\n",
      "\n",
      "avg / total       0.99      0.99      0.99       202\n",
      "\n",
      "The accuracy is:0.990099009901\n",
      "The confusion_matrix is:\n",
      "[[100   1   0]\n",
      " [  1  48   0]\n",
      " [  0   0  52]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.99      1.00      1.00       101\n",
      "      Human       1.00      0.98      0.99        49\n",
      "     Animal       1.00      1.00      1.00        52\n",
      "\n",
      "avg / total       1.00      1.00      1.00       202\n",
      "\n",
      "The accuracy is:0.99504950495\n",
      "The confusion_matrix is:\n",
      "[[101   0   0]\n",
      " [  1  48   0]\n",
      " [  0   0  52]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.99      1.00      1.00       101\n",
      "      Human       1.00      0.98      0.99        49\n",
      "     Animal       1.00      1.00      1.00        52\n",
      "\n",
      "avg / total       1.00      1.00      1.00       202\n",
      "\n",
      "The accuracy is:0.99504950495\n",
      "The confusion_matrix is:\n",
      "[[101   0   0]\n",
      " [  1  48   0]\n",
      " [  0   0  52]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc   SVM_acc    KNN_acc\n",
      "0         99.504950  99.50495  99.009901\n",
      "1         99.009901  99.50495  99.504950\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                  DecisionTree_acc                          SVM_acc  \\\n",
      "0  [101, 0, 0, 1, 48, 0, 0, 0, 52]  [100, 0, 1, 0, 49, 0, 0, 0, 52]   \n",
      "1  [100, 1, 0, 1, 48, 0, 0, 0, 52]  [101, 0, 0, 1, 48, 0, 0, 0, 52]   \n",
      "\n",
      "                           KNN_acc  \n",
      "0   [99, 1, 1, 0, 49, 0, 0, 0, 52]  \n",
      "1  [101, 0, 0, 1, 48, 0, 0, 0, 52]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy2\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:4\n",
      "The SheetValueTestis:5\n",
      "[  3139.58281445   6758.79701121  15882.90410959   8741.65753425\n",
      "   4138.01992528   5803.97633873  13755.8630137   11537.30136986]\n",
      "[  5.55026948e+07   1.63811592e+08   4.79885153e+08   2.87804620e+08\n",
      "   8.48425618e+07   1.38602482e+08   4.25209930e+08   3.99651592e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.986297 (0.009967)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=5.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.990047 (0.004957)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.992523 (0.004663)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.99      0.99       100\n",
      "      Human       0.98      0.98      0.98        49\n",
      "     Animal       0.98      1.00      0.99        52\n",
      "\n",
      "avg / total       0.99      0.99      0.99       201\n",
      "\n",
      "The accuracy is:0.990049751244\n",
      "The confusion_matrix is:\n",
      "[[99  1  0]\n",
      " [ 0 48  1]\n",
      " [ 0  0 52]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.99      0.99       100\n",
      "      Human       0.98      0.98      0.98        49\n",
      "     Animal       0.98      1.00      0.99        52\n",
      "\n",
      "avg / total       0.99      0.99      0.99       201\n",
      "\n",
      "The accuracy is:0.990049751244\n",
      "The confusion_matrix is:\n",
      "[[99  1  0]\n",
      " [ 0 48  1]\n",
      " [ 0  0 52]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00       100\n",
      "      Human       1.00      1.00      1.00        49\n",
      "     Animal       1.00      1.00      1.00        52\n",
      "\n",
      "avg / total       1.00      1.00      1.00       201\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[100   0   0]\n",
      " [  0  49   0]\n",
      " [  0   0  52]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0         99.504950  99.504950   99.009901\n",
      "1         99.009901  99.504950   99.504950\n",
      "2         99.004975  99.004975  100.000000\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                  DecisionTree_acc                          SVM_acc  \\\n",
      "0  [101, 0, 0, 1, 48, 0, 0, 0, 52]  [100, 0, 1, 0, 49, 0, 0, 0, 52]   \n",
      "1  [100, 1, 0, 1, 48, 0, 0, 0, 52]  [101, 0, 0, 1, 48, 0, 0, 0, 52]   \n",
      "2   [99, 1, 0, 0, 48, 1, 0, 0, 52]   [99, 1, 0, 0, 48, 1, 0, 0, 52]   \n",
      "\n",
      "                           KNN_acc  \n",
      "0   [99, 1, 1, 0, 49, 0, 0, 0, 52]  \n",
      "1  [101, 0, 0, 1, 48, 0, 0, 0, 52]  \n",
      "2  [100, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy3\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:6\n",
      "The SheetValueTestis:7\n",
      "[  3118.17288557   6908.3681592   16135.11442786   8549.14800995\n",
      "   3828.49626866   5373.02238806  13356.45646766  11229.60074627]\n",
      "[  5.31141371e+07   1.69345160e+08   4.85262579e+08   2.79067881e+08\n",
      "   7.77199349e+07   1.23357120e+08   4.11982818e+08   3.97528471e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.985085 (0.004955)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=0.5, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.992547 (0.006086)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.991297 (0.009294)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.98      0.99       100\n",
      "      Human       0.96      1.00      0.98        49\n",
      "     Animal       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       0.99      0.99      0.99       200\n",
      "\n",
      "The accuracy is:0.99\n",
      "The confusion_matrix is:\n",
      "[[98  2  0]\n",
      " [ 0 49  0]\n",
      " [ 0  0 51]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.97      0.98       100\n",
      "      Human       0.94      1.00      0.97        49\n",
      "     Animal       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       0.99      0.98      0.99       200\n",
      "\n",
      "The accuracy is:0.985\n",
      "The confusion_matrix is:\n",
      "[[97  3  0]\n",
      " [ 0 49  0]\n",
      " [ 0  0 51]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.99      0.99       100\n",
      "      Human       0.98      1.00      0.99        49\n",
      "     Animal       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       1.00      0.99      1.00       200\n",
      "\n",
      "The accuracy is:0.995\n",
      "The confusion_matrix is:\n",
      "[[99  1  0]\n",
      " [ 0 49  0]\n",
      " [ 0  0 51]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0         99.504950  99.504950   99.009901\n",
      "1         99.009901  99.504950   99.504950\n",
      "2         99.004975  99.004975  100.000000\n",
      "3         99.000000  98.500000   99.500000\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                  DecisionTree_acc                          SVM_acc  \\\n",
      "0  [101, 0, 0, 1, 48, 0, 0, 0, 52]  [100, 0, 1, 0, 49, 0, 0, 0, 52]   \n",
      "1  [100, 1, 0, 1, 48, 0, 0, 0, 52]  [101, 0, 0, 1, 48, 0, 0, 0, 52]   \n",
      "2   [99, 1, 0, 0, 48, 1, 0, 0, 52]   [99, 1, 0, 0, 48, 1, 0, 0, 52]   \n",
      "3   [98, 2, 0, 0, 49, 0, 0, 0, 51]   [97, 3, 0, 0, 49, 0, 0, 0, 51]   \n",
      "\n",
      "                           KNN_acc  \n",
      "0   [99, 1, 1, 0, 49, 0, 0, 0, 52]  \n",
      "1  [101, 0, 0, 1, 48, 0, 0, 0, 52]  \n",
      "2  [100, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "3   [99, 1, 0, 0, 49, 0, 0, 0, 51]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy4\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:8\n",
      "The SheetValueTestis:9\n",
      "[  3087.46086957   6967.75279503  16081.39006211   8552.97267081\n",
      "   3980.6931677    5659.9515528   13495.9552795   10560.80248447]\n",
      "[  5.49574011e+07   1.67379601e+08   4.86114771e+08   2.89322863e+08\n",
      "   8.24084589e+07   1.32495420e+08   4.10251432e+08   3.66116201e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.983851 (0.010830)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=5.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.990062 (0.006334)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.992547 (0.009129)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.97      0.98       100\n",
      "      Human       0.96      1.00      0.98        48\n",
      "     Animal       0.98      1.00      0.99        51\n",
      "\n",
      "avg / total       0.99      0.98      0.98       199\n",
      "\n",
      "The accuracy is:0.984924623116\n",
      "The confusion_matrix is:\n",
      "[[97  2  1]\n",
      " [ 0 48  0]\n",
      " [ 0  0 51]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00       100\n",
      "      Human       1.00      1.00      1.00        48\n",
      "     Animal       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       1.00      1.00      1.00       199\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[100   0   0]\n",
      " [  0  48   0]\n",
      " [  0   0  51]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.98      0.99       100\n",
      "      Human       0.98      1.00      0.99        48\n",
      "     Animal       0.98      1.00      0.99        51\n",
      "\n",
      "avg / total       0.99      0.99      0.99       199\n",
      "\n",
      "The accuracy is:0.989949748744\n",
      "The confusion_matrix is:\n",
      "[[98  1  1]\n",
      " [ 0 48  0]\n",
      " [ 0  0 51]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc     SVM_acc     KNN_acc\n",
      "0         99.504950   99.504950   99.009901\n",
      "1         99.009901   99.504950   99.504950\n",
      "2         99.004975   99.004975  100.000000\n",
      "3         99.000000   98.500000   99.500000\n",
      "4         98.492462  100.000000   98.994975\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                  DecisionTree_acc                          SVM_acc  \\\n",
      "0  [101, 0, 0, 1, 48, 0, 0, 0, 52]  [100, 0, 1, 0, 49, 0, 0, 0, 52]   \n",
      "1  [100, 1, 0, 1, 48, 0, 0, 0, 52]  [101, 0, 0, 1, 48, 0, 0, 0, 52]   \n",
      "2   [99, 1, 0, 0, 48, 1, 0, 0, 52]   [99, 1, 0, 0, 48, 1, 0, 0, 52]   \n",
      "3   [98, 2, 0, 0, 49, 0, 0, 0, 51]   [97, 3, 0, 0, 49, 0, 0, 0, 51]   \n",
      "4   [97, 2, 1, 0, 48, 0, 0, 0, 51]  [100, 0, 0, 0, 48, 0, 0, 0, 51]   \n",
      "\n",
      "                           KNN_acc  \n",
      "0   [99, 1, 1, 0, 49, 0, 0, 0, 52]  \n",
      "1  [101, 0, 0, 1, 48, 0, 0, 0, 52]  \n",
      "2  [100, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "3   [99, 1, 0, 0, 49, 0, 0, 0, 51]  \n",
      "4   [98, 1, 1, 0, 48, 0, 0, 0, 51]  \n",
      "name of the classifier is:DecisionTree_acc\n",
      "The total confusion matrix is:\n",
      "[[495   6   1]\n",
      " [  2 241   1]\n",
      " [  0   0 258]]\n",
      "name of the classifier is:SVM_acc\n",
      "The total confusion matrix is:\n",
      "[[497   4   1]\n",
      " [  1 242   1]\n",
      " [  0   0 258]]\n",
      "name of the classifier is:KNN_acc\n",
      "The total confusion matrix is:\n",
      "[[497   3   2]\n",
      " [  1 243   0]\n",
      " [  0   0 258]]\n"
     ]
    }
   ],
   "source": [
    "###########################Final analysis of intruder and clutter classification for all the Three outputs \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC as SVC \n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomTreesEmbedding, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "#import nltk as nl\n",
    "####simple explanation of 3 NN classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "from numpy import linalg as LA\n",
    "from collections import Counter\n",
    "from scipy.stats.mstats import zscore\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pylab as pl\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "class Results_Framework(object):\n",
    "    \n",
    "    def __init__(self,featureDimension,sheetnameValTrain,sheetnameValTest,class_column):\n",
    "        self.featureDimension = featureDimension\n",
    "        self.sheetnameValTrain = sheetnameValTrain\n",
    "        self.sheetnameValTest = sheetnameValTest\n",
    "        self.class_column = class_column\n",
    "    def read_data(self,directoryPathTrain,directoryPathTest):\n",
    "#        print \"The Feature Dimension is:\" + str(featureDimension)\n",
    "        print \"The SheetValueTrain is:\" + str(sheetnameValTrain)\n",
    "        print \"The SheetValueTestis:\" + str(sheetnameValTest)\n",
    "        val_train = pd.read_excel(directoryPathTrain,sheetname=sheetnameValTrain)\n",
    "        val_test  = pd.read_excel(directoryPathTest,sheetname=sheetnameValTest)\n",
    "        ######################################################################################################\n",
    "        val_data_train = val_train.iloc[:,self.featureDimension]\n",
    "        val_label_train = val_train.iloc[:,self.class_column]\n",
    "        val_data_test = val_test.iloc[:,self.featureDimension]\n",
    "        val_label_test = val_test.iloc[:,self.class_column]\n",
    "        #####################################################################################################\n",
    "        X_scaler = StandardScaler()\n",
    "        train_data = X_scaler.fit_transform(val_data_train)\n",
    "        test_data = X_scaler.transform(val_data_test)\n",
    "        print X_scaler.mean_\n",
    "        print X_scaler.var_\n",
    "        ###########################################################################################\n",
    "        #################################################################################\n",
    "        train_data = np.asarray(train_data)\n",
    "        \n",
    "        #print train_labels\n",
    "        #print len(train_labels)\n",
    "        #for i in range(len(val_label_train)):\n",
    "        #    if val_label_train.iloc[i]==0:\n",
    "        #        val_label_train.iloc[i]=1\n",
    "        train_labels = list(val_label_train)    \n",
    "        test_data = np.asarray(test_data)\n",
    "        \n",
    "        #for i in range(len(val_label_test)):\n",
    "        #    if val_label_test.iloc[i]==0:\n",
    "        #        val_label_test.iloc[i]=1\n",
    "        test_labels = list(val_label_test)        \n",
    "        return train_data,train_labels,test_data,test_labels\n",
    "    \n",
    "    def Class_validation(self,train_data,train_output,test_data,test_labels_modified):\n",
    "        Classifier_estimates = [];\n",
    "        cv = KFold(n=len(train_data),n_folds=5,random_state=12345,shuffle=True)\n",
    "    \n",
    "        param_grid_decison = {'max_depth': [None],\"max_features\":[None],\"min_samples_leaf\": [1,3,10],\"criterion\": [\"gini\",\"entropy\"]}\n",
    "        param_grid_random = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [\"auto\"],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]\n",
    "                 }\n",
    "        param_test_GB = {'max_depth':range(5,16,2),'n_estimators':range(50,100,10)}\n",
    "        parameter_grid_svm = [\n",
    "          {'C': [0.001,0.005,0.01,0.05,0.5,0.1,1.0,5.0,10,50.0,100,200,400,800,1600,3200,4800]}  \n",
    "         \n",
    "    ]\n",
    "        param_grid_ada = {\n",
    "              \"n_estimators\": range(100,150,10),\n",
    "             \n",
    "             }\n",
    "        param_grid_KNN =  [\n",
    "            {'n_neighbors': [3, 11]}, {'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "        ]\n",
    "        #clf1 = GridSearchCV(estimator= RandomForestClassifier(n_estimators=20,random_state=1), param_grid=param_grid_random)\n",
    "        #clf3 = GridSearchCV(estimator = GradientBoostingClassifier(max_features='sqrt', subsample=0.8, random_state=1), param_grid = param_test_GB)\n",
    "        clf1 = GridSearchCV(estimator = tree.DecisionTreeClassifier(random_state=1),param_grid=param_grid_decison)\n",
    "        clf2 = GridSearchCV(estimator= SVC(random_state=1,class_weight='balanced'), param_grid=parameter_grid_svm)\n",
    "        #clf4 = GridSearchCV(estimator = AdaBoostClassifier(random_state=1), param_grid=param_grid_ada)\n",
    "        clf3 = GridSearchCV(estimator = KNN(), param_grid=param_grid_KNN)\n",
    "\n",
    "        y_train = train_output\n",
    "        \n",
    "        models = []\n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        #models.append(('ADA',clf4))\n",
    "        #models.append(('SVM', clf5))\n",
    "        #models.append(('KNN', clf6))\n",
    "    \n",
    "# evaluate each model in turn\n",
    "        results = []\n",
    "        names = []\n",
    "        scoring = 'f1_micro'\n",
    "        best_params = []\n",
    "        for name, model in models:\n",
    "            kfold = model_selection.KFold(n_splits=5, random_state=12345)\n",
    "            cv_results = model_selection.cross_val_score(model, train_data, y_train, cv=kfold, scoring=scoring)\n",
    "            results.append(cv_results)\n",
    "            names.append(name)\n",
    "            model.fit(train_data,y_train)\n",
    "            print \"The best parameter estimates for\"+str(name)+\"is :\"+str(model.best_estimator_)\n",
    "            Classifier_estimates.append(model.best_estimator_)\n",
    "            msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "            print msg\n",
    "        return  Classifier_estimates \n",
    "    def Classification_process(self,train_data_modified,train_labels_modified,test_data_modified,test_labels_True,Classifier_estimates):\n",
    "        models = []\n",
    "        #print \"The classifier:\"\n",
    "        #print Classifier_estimates[0]\n",
    "        clf1 = Classifier_estimates[0]\n",
    "        clf2 = Classifier_estimates[1]\n",
    "        clf3 = Classifier_estimates[2]\n",
    "        \n",
    "    \n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        \n",
    "        # evaluate each model in turn\n",
    "        results_accuracy = []\n",
    "        names = []\n",
    "        scoring = 'f1'\n",
    "        best_params = []\n",
    "        confusion_matrix_values = []\n",
    "        results_precision = []\n",
    "        results_recall = []\n",
    "        results_f1score = []\n",
    "        test_labels_predicted_list = []\n",
    "        for name, model in models:\n",
    "            model.fit(train_data_modified,train_labels_modified)\n",
    "            #print len(train_data_modified)\n",
    "            #print len(train_labels_modified)\n",
    "            test_labels_predicted = model.predict(test_data_modified)\n",
    "            #print len(test_labels_predicted)\n",
    "            #print len(test_labels_predicted)\n",
    "            target_names = ['Clutter','Human','Animal']\n",
    "            print \"The Iteration is :\"+ str(1)+ \"The name of the classifier is:\"+ str(name) \n",
    "            precision,recall,f_score,support = precision_recall_fscore_support(test_labels_True, test_labels_predicted,average='macro')\n",
    "            results_precision.append(precision)\n",
    "            results_recall.append(recall)\n",
    "            results_f1score.append(f_score)\n",
    "            print (classification_report(test_labels_True, test_labels_predicted, target_names=target_names))\n",
    "            count = 0\n",
    "            for i in range(len(test_labels_predicted)):\n",
    "                test_labels_predicted_list.append(test_labels_predicted[i])\n",
    "                if(test_labels_predicted[i] == test_labels_True[i]):\n",
    "                    count = count + 1\n",
    "                    \n",
    "                \n",
    "            print \"The accuracy is:\" + str(float(float(count)/float(len(test_labels_predicted)))) \n",
    "            accuracy = 100 * (float(float(count)/float(len(test_labels_predicted))));\n",
    "            cm = confusion_matrix(test_labels_True, test_labels_predicted, labels =None)\n",
    "            print \"The confusion_matrix is:\" \n",
    "            print(cm) \n",
    "            confusion_matrix_values.append((np.reshape(cm, (1, 9))).tolist()[0])\n",
    "            results_accuracy.append(accuracy)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score\n",
    "        \n",
    "    def main_method(self,directoryTrain,directoryTest):\n",
    "        train_data_modified,train_labels_modified,test_data_modified,test_labels_modified = results_framework.read_data(directoryTrain,directoryTest);\n",
    "        Classifier_estimates = results_framework.Class_validation(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified)\n",
    "        results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.Classification_process(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified,Classifier_estimates)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score          \n",
    "\n",
    "\n",
    "\n",
    "directory_train = \"C:\\\\Users\\\\smart\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\\\\\"\n",
    "#directory_train = \"C:\\\\Users\\\\WSNLab\\\\Dropbox_Tarun\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\"\n",
    "file_name_train = \"Feature_finall_combined_unVAB_CD_background_max_sum_energy_MOG_combined_Kfold_clutter_label_change.xlsx\"\n",
    "directory_test = directory_train\n",
    "file_name_test = file_name_train\n",
    "df = pd.read_excel(directory_train+file_name_train)\n",
    "columns = len(df.columns)\n",
    "featureDimension = range(10,18)\n",
    "class_column = columns-2\n",
    "accuracy_all = []\n",
    "precision_all = []\n",
    "recall_all = []\n",
    "f1score_all = []\n",
    "confusion_matrix_sum_all = [] \n",
    "count_even = 0;\n",
    "count_odd = 1;\n",
    "for i in range(5):    \n",
    "    sheetnameValTrain = count_even;\n",
    "    sheetnameValTest  = count_odd;\n",
    "    print \"##############################################################################################\"\n",
    "    print \"The Analysis of Camera Three class accuracy\" + str(i)\n",
    "    print \"##############################################################################################\"\n",
    "    results_framework = Results_Framework(featureDimension,sheetnameValTrain,sheetnameValTest,class_column)\n",
    "    #accuracy,confusion_matrix_sum = \n",
    "    results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.main_method(os.path.join(directory_train,file_name_train),os.path.join(directory_test,file_name_test))\n",
    "    accuracy_all.append(results_accuracy)\n",
    "    precision_all.append(results_precision)\n",
    "    recall_all.append(results_recall)\n",
    "    f1score_all.append(results_f1score)\n",
    "    \n",
    "    df_accuracy=pd.DataFrame(accuracy_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_precision=pd.DataFrame(precision_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_recall=pd.DataFrame(recall_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_f1score=pd.DataFrame(f1score_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    confusion_matrix_sum_all.append(confusion_matrix_values)\n",
    "    df_confusion_matrix_sum_all=pd.DataFrame(confusion_matrix_sum_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    print \"##############################################################\"\n",
    "    print \"The final accuracies of classifier are:\"\n",
    "    print df_accuracy\n",
    "    print \"##############################################################\"\n",
    "    print \"The final confusion matrix of classifier are:\"\n",
    "    print df_confusion_matrix_sum_all\n",
    "    ###########printing of the whole confusion matrix##################################\n",
    "    if(count_even==8):\n",
    "        for i in range(np.shape(df_confusion_matrix_sum_all)[1]):\n",
    "            xlist = []\n",
    "            xlist = list((df_confusion_matrix_sum_all.iloc[:,i]))\n",
    "            a = [sum(x) for x in zip(*xlist)]\n",
    "            print \"name of the classifier is:\" + str(df_confusion_matrix_sum_all.columns[i])\n",
    "            print \"The total confusion matrix is:\"\n",
    "            print np.reshape(a,(3,3))\n",
    "            #print \"The Sucessful Target Detection is for the classifier for intruder:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[0])/(a[0] + a[1]))\n",
    "            #print \"The Sucessful False Alarms Raisec for the classifier are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[2])/(a[2] + a[3]))\n",
    "            #print \"The missed scenarios are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[1])/(a[0] + a[1]))\n",
    "            #print \"The mean accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').mean()\n",
    "            #print \"The variance of the accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').var()\n",
    "    else:\n",
    "        count_even = count_even + 2\n",
    "        count_odd = count_odd + 2\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for DecisionTree_acc\n",
      "99.0024577842\n",
      "0.128165521398\n",
      "The mean and the variance for SVM_acc\n",
      "99.3029752229\n",
      "0.32525120708\n",
      "The mean and the variance for KNN_acc\n",
      "99.4019652719\n",
      "0.174304471215\n"
     ]
    }
   ],
   "source": [
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_accuracy.iloc[:,0].mean()\n",
    "print df_accuracy.iloc[:,0].var()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_accuracy.iloc[:,1].mean()\n",
    "print df_accuracy.iloc[:,1].var()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_accuracy.iloc[:,2].mean()\n",
    "print df_accuracy.iloc[:,2].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for precision DecisionTree_acc\n",
      "0.988144292118\n",
      "3.55118160952e-05\n",
      "The mean and the variance for precisionSVM_acc\n",
      "0.991623983894\n",
      "6.01676342324e-05\n",
      "The mean and the variance for precisionKNN_acc\n",
      "0.992779281427\n",
      "3.42175681335e-05\n"
     ]
    }
   ],
   "source": [
    "print \"The mean and the variance for precision \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_precision.iloc[:,0].mean()\n",
    "print df_precision.iloc[:,0].var()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_precision.iloc[:,1].mean()\n",
    "print df_precision.iloc[:,1].var()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_precision.iloc[:,2].mean()\n",
    "print df_precision.iloc[:,2].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for recallDecisionTree_acc\n",
      "0.99125830134\n",
      "3.36155564332e-06\n",
      "The mean and the variance for recallSVM_acc\n",
      "0.993952178891\n",
      "1.9257022741e-05\n",
      "The mean and the variance for recallKNN_acc\n",
      "0.995319323769\n",
      "8.96440829439e-06\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0c56a7bc4308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf_recall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf_recall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"The mean and the variance for recall\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_confusion_matrix_sum_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\smart\\Anaconda2\\lib\\site-packages\\pandas\\indexes\\base.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1423\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_recall.iloc[:,0].mean()\n",
    "print df_recall.iloc[:,0].var()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_recall.iloc[:,1].mean()\n",
    "print df_recall.iloc[:,1].var()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_recall.iloc[:,2].mean()\n",
    "print df_recall.iloc[:,2].var()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################Calculation_of_fscore\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_f1score.iloc[:,0].mean()\n",
    "print df_f1score.iloc[:,0].var()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_f1score.iloc[:,1].mean()\n",
    "print df_f1score.iloc[:,1].var()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_f1score.iloc[:,2].mean()\n",
    "print df_f1score.iloc[:,2].var()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
