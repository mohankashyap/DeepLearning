{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy0\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:0\n",
      "The SheetValueTestis:1\n",
      "[ 11922.82196031  34716.31029503]\n",
      "[  4.49956020e+08   2.73913185e+09]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=3,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.986667 (0.017778)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=1600, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.977475 (0.014376)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.982222 (0.025915)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        57\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 13]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.93      1.00      0.97        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.97      0.96      0.96        57\n",
      "\n",
      "The accuracy is:0.964912280702\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 2  0 11]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        57\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 13]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc  KNN_acc\n",
      "0             100.0  96.491228    100.0\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  [28, 0, 0, 0, 16, 0, 2, 0, 11]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy1\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:2\n",
      "The SheetValueTestis:3\n",
      "[ 12959.85625313  31774.10702241]\n",
      "[  5.24169137e+08   1.69818187e+09]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.995556 (0.008889)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=3200, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.973333 (0.032660)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.995556 (0.008889)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.93      1.00      0.97        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.97      0.96      0.96        56\n",
      "\n",
      "The accuracy is:0.964285714286\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 2  0 10]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.97      1.00      0.98        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        56\n",
      "\n",
      "The accuracy is:0.982142857143\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 1  0 11]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       0.88      0.94      0.91        16\n",
      "     Animal       0.91      0.83      0.87        12\n",
      "\n",
      "avg / total       0.95      0.95      0.95        56\n",
      "\n",
      "The accuracy is:0.946428571429\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  2 10]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0        100.000000  96.491228  100.000000\n",
      "1         96.428571  98.214286   94.642857\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  [28, 0, 0, 0, 16, 0, 2, 0, 11]   \n",
      "1  [28, 0, 0, 0, 16, 0, 2, 0, 10]  [28, 0, 0, 0, 16, 0, 1, 0, 11]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  \n",
      "1  [28, 0, 0, 0, 15, 1, 0, 2, 10]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy2\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:4\n",
      "The SheetValueTestis:5\n",
      "[ 12468.06851265  33595.21714041]\n",
      "[  4.89814733e+08   2.50092347e+09]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 1.000000 (0.000000)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=10, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 1.000000 (0.000000)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.986667 (0.026667)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        56\n",
      "\n",
      "The accuracy is:0.982142857143\n",
      "The confusion_matrix is:\n",
      "[[27  0  1]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        56\n",
      "\n",
      "The accuracy is:0.982142857143\n",
      "The confusion_matrix is:\n",
      "[[27  0  1]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       0.94      1.00      0.97        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        56\n",
      "\n",
      "The accuracy is:0.982142857143\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0        100.000000  96.491228  100.000000\n",
      "1         96.428571  98.214286   94.642857\n",
      "2         98.214286  98.214286   98.214286\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  [28, 0, 0, 0, 16, 0, 2, 0, 11]   \n",
      "1  [28, 0, 0, 0, 16, 0, 2, 0, 10]  [28, 0, 0, 0, 16, 0, 1, 0, 11]   \n",
      "2  [27, 0, 1, 0, 16, 0, 0, 0, 12]  [27, 0, 1, 0, 16, 0, 0, 0, 12]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  \n",
      "1  [28, 0, 0, 0, 15, 1, 0, 2, 10]  \n",
      "2  [27, 1, 0, 0, 16, 0, 0, 0, 12]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy3\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:6\n",
      "The SheetValueTestis:7\n",
      "[ 12140.0139095  34783.5077098]\n",
      "[  4.82782049e+08   2.73178613e+09]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=3,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.986667 (0.017778)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=8000, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.955354 (0.037187)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.982222 (0.025915)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        56\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.93      0.96      0.95        28\n",
      "      Human       0.94      1.00      0.97        16\n",
      "     Animal       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.95      0.95      0.95        56\n",
      "\n",
      "The accuracy is:0.946428571429\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 0 16  0]\n",
      " [ 2  0 10]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        56\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0        100.000000  96.491228  100.000000\n",
      "1         96.428571  98.214286   94.642857\n",
      "2         98.214286  98.214286   98.214286\n",
      "3        100.000000  94.642857  100.000000\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  [28, 0, 0, 0, 16, 0, 2, 0, 11]   \n",
      "1  [28, 0, 0, 0, 16, 0, 2, 0, 10]  [28, 0, 0, 0, 16, 0, 1, 0, 11]   \n",
      "2  [27, 0, 1, 0, 16, 0, 0, 0, 12]  [27, 0, 1, 0, 16, 0, 0, 0, 12]   \n",
      "3  [28, 0, 0, 0, 16, 0, 0, 0, 12]  [27, 1, 0, 0, 16, 0, 2, 0, 10]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  \n",
      "1  [28, 0, 0, 0, 15, 1, 0, 2, 10]  \n",
      "2  [27, 1, 0, 0, 16, 0, 0, 0, 12]  \n",
      "3  [28, 0, 0, 0, 16, 0, 0, 0, 12]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy4\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:8\n",
      "The SheetValueTestis:9\n",
      "[ 12493.76834174  35593.91060232]\n",
      "[  4.75325962e+08   2.71412527e+09]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=3,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.986667 (0.017778)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=3200, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.960000 (0.043090)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.982222 (0.025915)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        15\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        55\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.90      1.00      0.95        28\n",
      "      Human       1.00      1.00      1.00        15\n",
      "     Animal       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.95      0.95      0.94        55\n",
      "\n",
      "The accuracy is:0.945454545455\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 15  0]\n",
      " [ 3  0  9]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        15\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        55\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 12]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0        100.000000  96.491228  100.000000\n",
      "1         96.428571  98.214286   94.642857\n",
      "2         98.214286  98.214286   98.214286\n",
      "3        100.000000  94.642857  100.000000\n",
      "4        100.000000  94.545455  100.000000\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  [28, 0, 0, 0, 16, 0, 2, 0, 11]   \n",
      "1  [28, 0, 0, 0, 16, 0, 2, 0, 10]  [28, 0, 0, 0, 16, 0, 1, 0, 11]   \n",
      "2  [27, 0, 1, 0, 16, 0, 0, 0, 12]  [27, 0, 1, 0, 16, 0, 0, 0, 12]   \n",
      "3  [28, 0, 0, 0, 16, 0, 0, 0, 12]  [27, 1, 0, 0, 16, 0, 2, 0, 10]   \n",
      "4  [28, 0, 0, 0, 15, 0, 0, 0, 12]   [28, 0, 0, 0, 15, 0, 3, 0, 9]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  \n",
      "1  [28, 0, 0, 0, 15, 1, 0, 2, 10]  \n",
      "2  [27, 1, 0, 0, 16, 0, 0, 0, 12]  \n",
      "3  [28, 0, 0, 0, 16, 0, 0, 0, 12]  \n",
      "4  [28, 0, 0, 0, 15, 0, 0, 0, 12]  \n",
      "name of the classifier is:DecisionTree_acc\n",
      "The total confusion matrix is:\n",
      "[[139   0   1]\n",
      " [  0  79   0]\n",
      " [  2   0  59]]\n",
      "name of the classifier is:SVM_acc\n",
      "The total confusion matrix is:\n",
      "[[138   1   1]\n",
      " [  0  79   0]\n",
      " [  8   0  53]]\n",
      "name of the classifier is:KNN_acc\n",
      "The total confusion matrix is:\n",
      "[[139   1   0]\n",
      " [  0  78   1]\n",
      " [  0   2  59]]\n"
     ]
    }
   ],
   "source": [
    "###########################Final analysis of intruder and clutter classification for all the Three outputs \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC as SVC \n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomTreesEmbedding, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "#import nltk as nl\n",
    "####simple explanation of 3 NN classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "from numpy import linalg as LA\n",
    "from collections import Counter\n",
    "from scipy.stats.mstats import zscore\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pylab as pl\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pydotplus \n",
    "from IPython.display import Image  \n",
    "class Results_Framework(object):\n",
    "    \n",
    "    def __init__(self,featureDimension,sheetnameValTrain,sheetnameValTest,class_column):\n",
    "        self.featureDimension = featureDimension\n",
    "        self.sheetnameValTrain = sheetnameValTrain\n",
    "        self.sheetnameValTest = sheetnameValTest\n",
    "        self.class_column = class_column\n",
    "    def read_data(self,directoryPathTrain,directoryPathTest):\n",
    "#        print \"The Feature Dimension is:\" + str(featureDimension)\n",
    "        print \"The SheetValueTrain is:\" + str(sheetnameValTrain)\n",
    "        print \"The SheetValueTestis:\" + str(sheetnameValTest)\n",
    "        val_train = pd.read_excel(directoryPathTrain,sheetname=sheetnameValTrain)\n",
    "        val_test  = pd.read_excel(directoryPathTest,sheetname=sheetnameValTest)\n",
    "        ######################################################################################################\n",
    "        val_data_train = val_train.iloc[:,self.featureDimension]\n",
    "        val_label_train = val_train.iloc[:,self.class_column]\n",
    "        val_data_test = val_test.iloc[:,self.featureDimension]\n",
    "        val_label_test = val_test.iloc[:,self.class_column]\n",
    "        #####################################################################################################\n",
    "        X_scaler = StandardScaler()\n",
    "        train_data = X_scaler.fit_transform(val_data_train)\n",
    "        test_data = X_scaler.transform(val_data_test)\n",
    "        print X_scaler.mean_\n",
    "        print X_scaler.var_\n",
    "        ###########################################################################################\n",
    "        #################################################################################\n",
    "        train_data = np.asarray(train_data)\n",
    "        \n",
    "        #print train_labels\n",
    "        #print len(train_labels)\n",
    "        #for i in range(len(val_label_train)):\n",
    "        #    if val_label_train.iloc[i]==0:\n",
    "        #        val_label_train.iloc[i]=1\n",
    "        train_labels = list(val_label_train)    \n",
    "        test_data = np.asarray(test_data)\n",
    "        \n",
    "        #for i in range(len(val_label_test)):\n",
    "        #    if val_label_test.iloc[i]==0:\n",
    "        #        val_label_test.iloc[i]=1\n",
    "        test_labels = list(val_label_test)        \n",
    "        return train_data,train_labels,test_data,test_labels\n",
    "    \n",
    "    def Class_validation(self,train_data,train_output,test_data,test_labels_modified):\n",
    "        Classifier_estimates = [];\n",
    "        cv = KFold(n=len(train_data),n_folds=5,random_state=12345,shuffle=True)\n",
    "    \n",
    "        param_grid_decison = {'max_depth': [None],\"max_features\":[None],\"min_samples_leaf\": [1,3,10],\"criterion\": [\"gini\",\"entropy\"]}\n",
    "        param_grid_random = {\"max_depth\": [3,None],\n",
    "              \"max_features\": [\"auto\"],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]\n",
    "                 }\n",
    "        param_test_GB = {'max_depth':range(5,16,2),'n_estimators':range(50,100,10)}\n",
    "        parameter_grid_svm = [\n",
    "          {'C': [0.5,0.1,1.0,5.0,10,50.0,100,200,400,800,1600,3200,4800,8000]}  \n",
    "        \n",
    "         #\n",
    "    ]\n",
    "        param_grid_ada = {\n",
    "              \"n_estimators\": range(100,150,10),\n",
    "             \n",
    "             }\n",
    "        param_grid_KNN =  [\n",
    "            {'n_neighbors': [5,7,9,11]}, {'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "        ]\n",
    "        #clf1 = GridSearchCV(estimator= RandomForestClassifier(n_estimators=20,random_state=1), param_grid=param_grid_random)\n",
    "        #clf3 = GridSearchCV(estimator = GradientBoostingClassifier(max_features='sqrt', subsample=0.8, random_state=1), param_grid = param_test_GB)\n",
    "        clf1 = GridSearchCV(estimator = tree.DecisionTreeClassifier(random_state=1),param_grid=param_grid_decison)\n",
    "        clf2 = GridSearchCV(estimator= SVC(random_state=1,class_weight='balanced'), param_grid=parameter_grid_svm)\n",
    "        #clf4 = GridSearchCV(estimator = AdaBoostClassifier(random_state=1), param_grid=param_grid_ada)\n",
    "        clf3 = GridSearchCV(estimator = KNN(), param_grid=param_grid_KNN)\n",
    "\n",
    "        y_train = train_output\n",
    "        \n",
    "        models = []\n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        #models.append(('ADA',clf4))\n",
    "        #models.append(('SVM', clf5))\n",
    "        #models.append(('KNN', clf6))\n",
    "    \n",
    "# evaluate each model in turn\n",
    "        results = []\n",
    "        names = []\n",
    "        scoring = 'f1_micro'\n",
    "        best_params = []\n",
    "        for name, model in models:\n",
    "            kfold = model_selection.KFold(n_splits=5, random_state=12345)\n",
    "            cv_results = model_selection.cross_val_score(model, train_data, y_train, cv=kfold, scoring=scoring)\n",
    "            results.append(cv_results)\n",
    "            names.append(name)\n",
    "            model.fit(train_data,y_train)\n",
    "            print \"The best parameter estimates for\"+str(name)+\"is :\"+str(model.best_estimator_)\n",
    "            Classifier_estimates.append(model.best_estimator_)\n",
    "            msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "            print msg\n",
    "        return  Classifier_estimates \n",
    "    def Classification_process(self,train_data_modified,train_labels_modified,test_data_modified,test_labels_True,Classifier_estimates):\n",
    "        models = []\n",
    "        #print \"The classifier:\"\n",
    "        #print Classifier_estimates[0]\n",
    "        clf1 = Classifier_estimates[0]\n",
    "        clf2 = Classifier_estimates[1]\n",
    "        clf3 = Classifier_estimates[2]\n",
    "        \n",
    "    \n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        \n",
    "        # evaluate each model in turn\n",
    "        results_accuracy = []\n",
    "        names = []\n",
    "        scoring = 'f1_micro'\n",
    "        best_params = []\n",
    "        confusion_matrix_values = []\n",
    "        results_precision = []\n",
    "        results_recall = []\n",
    "        results_f1score = []\n",
    "        test_labels_predicted_list = []\n",
    "        for name, model in models:\n",
    "\n",
    "                \n",
    "                #self.count_plot_Decision_Tree = self.count_plot_Decision_Tree + 1\n",
    "            model.fit(train_data_modified,train_labels_modified)\n",
    "            #print len(train_data_modified)\n",
    "            #print len(train_labels_modified)\n",
    "            test_labels_predicted = model.predict(test_data_modified)\n",
    "            if(name=='DecisionTree'):\n",
    "                model.fit(test_data_modified,test_labels_predicted)\n",
    "                with open(\"Decision_Tree.dot\", 'w') as f:\n",
    "                    f = tree.export_graphviz(model, out_file=f)\n",
    "                os.unlink('Decision_Tree.dot')\n",
    "                dot_data = tree.export_graphviz(model, out_file=None) \n",
    "                graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "                graph.write_pdf(\"Decision_Tree_optical_corr.pdf\") \n",
    "                dot_data = tree.export_graphviz(model, out_file=None)  \n",
    "                graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "                Image(graph.create_png())      \n",
    "            #print len(test_labels_predicted)\n",
    "            #print len(test_labels_predicted)\n",
    "            target_names = ['Clutter','Human','Animal']\n",
    "            print \"The Iteration is :\"+ str(1)+ \"The name of the classifier is:\"+ str(name) \n",
    "            precision,recall,f_score,support = precision_recall_fscore_support(test_labels_True, test_labels_predicted,average='macro')\n",
    "            results_precision.append(100 * precision)\n",
    "            results_recall.append(100 * recall)\n",
    "            results_f1score.append(100 * f_score)\n",
    "            print (classification_report(test_labels_True, test_labels_predicted, target_names=target_names))\n",
    "            count = 0\n",
    "            for i in range(len(test_labels_predicted)):\n",
    "                test_labels_predicted_list.append(test_labels_predicted[i])\n",
    "                if(test_labels_predicted[i] == test_labels_True[i]):\n",
    "                    count = count + 1\n",
    "                    \n",
    "                \n",
    "            print \"The accuracy is:\" + str(float(float(count)/float(len(test_labels_predicted)))) \n",
    "            accuracy = 100 * (float(float(count)/float(len(test_labels_predicted))));\n",
    "            cm = confusion_matrix(test_labels_True, test_labels_predicted, labels =None)\n",
    "            print \"The confusion_matrix is:\" \n",
    "            print(cm) \n",
    "            confusion_matrix_values.append((np.reshape(cm, (1, 9))).tolist()[0])\n",
    "            results_accuracy.append(accuracy)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score\n",
    "        \n",
    "    def main_method(self,directoryTrain,directoryTest):\n",
    "        train_data_modified,train_labels_modified,test_data_modified,test_labels_modified = results_framework.read_data(directoryTrain,directoryTest);\n",
    "        Classifier_estimates = results_framework.Class_validation(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified)\n",
    "        results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.Classification_process(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified,Classifier_estimates)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score          \n",
    "\n",
    "\n",
    "\n",
    "directory_train = \"C:\\\\Users\\\\smart\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\\\\\"\n",
    "#directory_train = \"C:\\\\Users\\\\WSNLab\\\\Dropbox_Tarun\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\"\n",
    "#file_name_train = \"Feature_final_reduced_complexity_new_version_camera4_kfold.xlsx\" #earliear version of accuracy 17 * 17 window\n",
    "#file_name_train = \"Feature_final_reduced_complexity_new_version_19_window_4_clutter_random_kfold1.xlsx\" #earliear version of accuracy 19 * 19 window\n",
    "#file_name_train = \"Feature_final_case_for_all_human_and_animal_k-fold.xlsx\"\n",
    "#file_name_train = \"Feature_final_case_for_all_human_and_animal_with_ECE_windy_31_window_final_kfold.xlsx\"\n",
    "#file_name_train = \"Feature_final_reduced_complexity_new_version_19_window_4_clutter_random_with_ECE_windy_final_kfold.xlsx\"\n",
    "\n",
    "\"\"\"When generating the results submitted for sense app for odroid case senario set the \n",
    "f1_results to [macro] instead of using [weighted]\"\"\"\n",
    "\n",
    "directory_test = directory_train\n",
    "file_name_test = file_name_train\n",
    "df = pd.read_excel(directory_train+file_name_train)\n",
    "columns = len(df.columns)\n",
    "featureDimension = range(8,10)\n",
    "class_column = columns-2\n",
    "accuracy_all = []\n",
    "precision_all = []\n",
    "recall_all = []\n",
    "f1score_all = []\n",
    "confusion_matrix_sum_all = [] \n",
    "count_even = 0;\n",
    "count_odd = 1;\n",
    "for i in range(5):    \n",
    "    sheetnameValTrain = count_even;\n",
    "    sheetnameValTest  = count_odd;\n",
    "    print \"##############################################################################################\"\n",
    "    print \"The Analysis of Camera Three class accuracy\" + str(i)\n",
    "    print \"##############################################################################################\"\n",
    "    results_framework = Results_Framework(featureDimension,sheetnameValTrain,sheetnameValTest,class_column)\n",
    "    #accuracy,confusion_matrix_sum = \n",
    "    results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.main_method(os.path.join(directory_train,file_name_train),os.path.join(directory_test,file_name_test))\n",
    "    accuracy_all.append(results_accuracy)\n",
    "    precision_all.append(results_precision)\n",
    "    recall_all.append(results_recall)\n",
    "    f1score_all.append(results_f1score)\n",
    "    \n",
    "    df_accuracy=pd.DataFrame(accuracy_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_precision=pd.DataFrame(precision_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_recall=pd.DataFrame(recall_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_f1score=pd.DataFrame(f1score_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    confusion_matrix_sum_all.append(confusion_matrix_values)\n",
    "    df_confusion_matrix_sum_all=pd.DataFrame(confusion_matrix_sum_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    print \"##############################################################\"\n",
    "    print \"The final accuracies of classifier are:\"\n",
    "    print df_accuracy\n",
    "    print \"##############################################################\"\n",
    "    print \"The final confusion matrix of classifier are:\"\n",
    "    print df_confusion_matrix_sum_all\n",
    "    ###########printing of the whole confusion matrix##################################\n",
    "    if(count_even==8):\n",
    "        for i in range(np.shape(df_confusion_matrix_sum_all)[1]):\n",
    "            xlist = []\n",
    "            xlist = list((df_confusion_matrix_sum_all.iloc[:,i]))\n",
    "            a = [sum(x) for x in zip(*xlist)]\n",
    "            print \"name of the classifier is:\" + str(df_confusion_matrix_sum_all.columns[i])\n",
    "            print \"The total confusion matrix is:\"\n",
    "            print np.reshape(a,(3,3))\n",
    "            #print \"The Sucessful Target Detection is for the classifier for intruder:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[0])/(a[0] + a[1]))\n",
    "            #print \"The Sucessful False Alarms Raisec for the classifier are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[2])/(a[2] + a[3]))\n",
    "            #print \"The missed scenarios are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[1])/(a[0] + a[1]))\n",
    "            #print \"The mean accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').mean()\n",
    "            #print \"The variance of the accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').var()\n",
    "    else:\n",
    "        count_even = count_even + 2\n",
    "        count_odd = count_odd + 2\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[[135   2   3]\n",
    " [  1  78   0]\n",
    " [  0   0  61]]\n",
    "name of the classifier is:SVM_acc\n",
    "The total confusion matrix is:\n",
    "[[136   2   2]\n",
    " [  0  78   1]\n",
    " [  3   1  57]]\n",
    "name of the classifier is:KNN_acc\n",
    "The total confusion matrix is:\n",
    "[[135   2   3]\n",
    " [  0  79   0]\n",
    " [  0   0  61]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for DecisionTree_acc\n",
      "97.8694463431\n",
      "1.91623802966\n",
      "The mean and the variance for SVM_acc\n",
      "97.1488949647\n",
      "0.958155201327\n",
      "The mean and the variance for KNN_acc\n",
      "98.2265892003\n",
      "2.14886378909\n"
     ]
    }
   ],
   "source": [
    "##################Calculation_Of_Accuarcy\n",
    "\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_accuracy.iloc[:,0].mean()\n",
    "print df_accuracy.iloc[:,0].std()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_accuracy.iloc[:,1].mean()\n",
    "print df_accuracy.iloc[:,1].std()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_accuracy.iloc[:,2].mean()\n",
    "print df_accuracy.iloc[:,2].std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for precision DecisionTree_acc\n",
      "100.0\n",
      "0.0\n",
      "The mean and the variance for precisionSVM_acc\n",
      "99.5555555556\n",
      "0.99380799\n",
      "The mean and the variance for precisionKNN_acc\n",
      "99.4871794872\n",
      "1.14670152692\n"
     ]
    }
   ],
   "source": [
    "###################Calculation_of_precision\n",
    "\n",
    "print \"The mean and the variance for precision \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_precision.iloc[:,0].mean()\n",
    "print df_precision.iloc[:,0].std()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_precision.iloc[:,1].mean()\n",
    "print df_precision.iloc[:,1].std()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_precision.iloc[:,2].mean()\n",
    "print df_precision.iloc[:,2].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for recallDecisionTree_acc\n",
      "100.0\n",
      "0.0\n",
      "The mean and the variance for recallSVM_acc\n",
      "98.8888888889\n",
      "2.484519975\n",
      "The mean and the variance for recallKNN_acc\n",
      "99.5833333333\n",
      "0.931694990625\n"
     ]
    }
   ],
   "source": [
    "###################Calculation_of_recall\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_recall.iloc[:,0].mean()\n",
    "print df_recall.iloc[:,0].std()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_recall.iloc[:,1].mean()\n",
    "print df_recall.iloc[:,1].std()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_recall.iloc[:,2].mean()\n",
    "print df_recall.iloc[:,2].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for fscoreDecisionTree_acc\n",
      "97.9013068923\n",
      "1.9340458318\n",
      "The mean and the variance for fscoreSVM_acc\n",
      "96.783907457\n",
      "0.981208067547\n",
      "The mean and the variance for fscoreKNN_acc\n",
      "98.2333197201\n",
      "2.15772379585\n"
     ]
    }
   ],
   "source": [
    "###################Calculation_of_fscore\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_f1score.iloc[:,0].mean()\n",
    "print df_f1score.iloc[:,0].std()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_f1score.iloc[:,1].mean()\n",
    "print df_f1score.iloc[:,1].std()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_f1score.iloc[:,2].mean()\n",
    "print df_f1score.iloc[:,2].std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Feature_finall_combined_unVAB_CD_background_max_sum_energy_MOG_combined_Kfold_clutter_label_change' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-40f53dce01ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFeature_finall_combined_unVAB_CD_background_max_sum_energy_MOG_combined_Kfold_clutter_label_change\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Feature_finall_combined_unVAB_CD_background_max_sum_energy_MOG_combined_Kfold_clutter_label_change' is not defined"
     ]
    }
   ],
   "source": [
    "Feature_finall_combined_unVAB_CD_background_max_sum_energy_MOG_combined_Kfold_clutter_label_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9712230215827338"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(float(138+79+53)/float(138+0+79+0+8+0+53))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.16666666666667"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(float(100+94.5+100)/float(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9452054794520548"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(float(138)/float(8+138))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "97.3+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
