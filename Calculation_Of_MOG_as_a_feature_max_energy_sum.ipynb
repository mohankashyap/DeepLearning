{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy0\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:0\n",
      "The SheetValueTestis:1\n",
      "[  6415.70403587  10048.58295964  18365.83408072  12111.76681614\n",
      "   3820.7309417    5823.0896861   13662.10313901  14169.62331839]\n",
      "[  6.32906263e+07   2.25469232e+08   5.19052825e+08   4.01204753e+08\n",
      "   3.92332996e+07   1.19657957e+08   3.59623258e+08   4.92420063e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=3,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.932828 (0.031290)\n",
      "The best parameter estimates forSVMis :SVC(C=200, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVM: 0.955152 (0.031575)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.946162 (0.030225)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.96      0.96      0.96        28\n",
      "      Human       0.79      0.94      0.86        16\n",
      "     Animal       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.92      0.91      0.91        57\n",
      "\n",
      "The accuracy is:0.912280701754\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 1 15  0]\n",
      " [ 0  3 10]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.87      0.93      0.90        28\n",
      "      Human       0.78      0.88      0.82        16\n",
      "     Animal       1.00      0.69      0.82        13\n",
      "\n",
      "avg / total       0.87      0.86      0.86        57\n",
      "\n",
      "The accuracy is:0.859649122807\n",
      "The confusion_matrix is:\n",
      "[[26  2  0]\n",
      " [ 2 14  0]\n",
      " [ 2  2  9]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.93      1.00      0.97        28\n",
      "      Human       1.00      0.94      0.97        16\n",
      "     Animal       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.97      0.96      0.96        57\n",
      "\n",
      "The accuracy is:0.964912280702\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 1 15  0]\n",
      " [ 1  0 12]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc    KNN_acc\n",
      "0          91.22807  85.964912  96.491228\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                        SVM_acc  \\\n",
      "0  [27, 1, 0, 1, 15, 0, 0, 3, 10]  [26, 2, 0, 2, 14, 0, 2, 2, 9]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 1, 15, 0, 1, 0, 12]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy1\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:2\n",
      "The SheetValueTestis:3\n",
      "[  6399.93303571   9468.125       18094.02678571  11602.16071429\n",
      "   4103.02678571   5714.48214286  13568.45089286  14375.59375   ]\n",
      "[  6.14201666e+07   2.06205840e+08   5.19977300e+08   3.71607612e+08\n",
      "   4.71993766e+07   1.13731903e+08   3.58528365e+08   5.04232320e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.937576 (0.038141)\n",
      "The best parameter estimates forSVMis :SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVM: 0.973232 (0.025899)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.964141 (0.023083)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.93      0.93      0.93        28\n",
      "      Human       1.00      0.88      0.93        16\n",
      "     Animal       0.86      1.00      0.92        12\n",
      "\n",
      "avg / total       0.93      0.93      0.93        56\n",
      "\n",
      "The accuracy is:0.928571428571\n",
      "The confusion_matrix is:\n",
      "[[26  0  2]\n",
      " [ 2 14  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.93      0.93      0.93        28\n",
      "      Human       0.93      0.88      0.90        16\n",
      "     Animal       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.93      0.93      0.93        56\n",
      "\n",
      "The accuracy is:0.928571428571\n",
      "The confusion_matrix is:\n",
      "[[26  1  1]\n",
      " [ 2 14  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.93      0.96      0.95        28\n",
      "      Human       1.00      0.88      0.93        16\n",
      "     Animal       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.95      0.95      0.95        56\n",
      "\n",
      "The accuracy is:0.946428571429\n",
      "The confusion_matrix is:\n",
      "[[27  0  1]\n",
      " [ 2 14  0]\n",
      " [ 0  0 12]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc    KNN_acc\n",
      "0         91.228070  85.964912  96.491228\n",
      "1         92.857143  92.857143  94.642857\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [27, 1, 0, 1, 15, 0, 0, 3, 10]   [26, 2, 0, 2, 14, 0, 2, 2, 9]   \n",
      "1  [26, 0, 2, 2, 14, 0, 0, 0, 12]  [26, 1, 1, 2, 14, 0, 0, 0, 12]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 1, 15, 0, 1, 0, 12]  \n",
      "1  [27, 0, 1, 2, 14, 0, 0, 0, 12]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy2\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:4\n",
      "The SheetValueTestis:5\n",
      "[  6160.83482143  10484.38392857  18335.07589286  11524.55357143\n",
      "   4372.51785714   6438.4375      13964.19642857  14484.07589286]\n",
      "[  6.42530234e+07   2.40739918e+08   5.33176354e+08   3.86174971e+08\n",
      "   4.99804916e+07   1.28907004e+08   3.72766736e+08   4.96059155e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.910707 (0.037194)\n",
      "The best parameter estimates forSVMis :SVC(C=5.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.06, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVM: 0.977677 (0.014056)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.950808 (0.029669)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.96      0.96      0.96        28\n",
      "      Human       0.88      0.88      0.88        16\n",
      "     Animal       0.92      0.92      0.92        12\n",
      "\n",
      "avg / total       0.93      0.93      0.93        56\n",
      "\n",
      "The accuracy is:0.928571428571\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 1 14  1]\n",
      " [ 0  1 11]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.96      0.96      0.96        28\n",
      "      Human       0.88      0.94      0.91        16\n",
      "     Animal       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.95      0.95      0.95        56\n",
      "\n",
      "The accuracy is:0.946428571429\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 1 15  0]\n",
      " [ 0  1 11]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.93      0.96      0.95        28\n",
      "      Human       0.94      0.94      0.94        16\n",
      "     Animal       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.95      0.95      0.95        56\n",
      "\n",
      "The accuracy is:0.946428571429\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 1 15  0]\n",
      " [ 1  0 11]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc    KNN_acc\n",
      "0         91.228070  85.964912  96.491228\n",
      "1         92.857143  92.857143  94.642857\n",
      "2         92.857143  94.642857  94.642857\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [27, 1, 0, 1, 15, 0, 0, 3, 10]   [26, 2, 0, 2, 14, 0, 2, 2, 9]   \n",
      "1  [26, 0, 2, 2, 14, 0, 0, 0, 12]  [26, 1, 1, 2, 14, 0, 0, 0, 12]   \n",
      "2  [27, 1, 0, 1, 14, 1, 0, 1, 11]  [27, 1, 0, 1, 15, 0, 0, 1, 11]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 1, 15, 0, 1, 0, 12]  \n",
      "1  [27, 0, 1, 2, 14, 0, 0, 0, 12]  \n",
      "2  [27, 1, 0, 1, 15, 0, 1, 0, 11]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy3\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:6\n",
      "The SheetValueTestis:7\n",
      "[  6465.23214286  10727.22321429  18173.61160714  10526.15178571\n",
      "   4398.19642857   6335.78571429  13666.76339286  14673.99107143]\n",
      "[  6.57128629e+07   2.43499037e+08   5.27003000e+08   3.48201840e+08\n",
      "   5.41730991e+07   1.41196239e+08   3.61403502e+08   5.31636614e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.928788 (0.045216)\n",
      "The best parameter estimates forSVMis :SVC(C=5.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVM: 0.968788 (0.022624)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.946364 (0.030283)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      0.81      0.90        16\n",
      "     Animal       0.80      1.00      0.89        12\n",
      "\n",
      "avg / total       0.96      0.95      0.95        56\n",
      "\n",
      "The accuracy is:0.946428571429\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 13  3]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      0.94      0.97        16\n",
      "     Animal       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        56\n",
      "\n",
      "The accuracy is:0.982142857143\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       0.93      0.88      0.90        16\n",
      "     Animal       0.85      0.92      0.88        12\n",
      "\n",
      "avg / total       0.95      0.95      0.95        56\n",
      "\n",
      "The accuracy is:0.946428571429\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 14  2]\n",
      " [ 0  1 11]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc    KNN_acc\n",
      "0         91.228070  85.964912  96.491228\n",
      "1         92.857143  92.857143  94.642857\n",
      "2         92.857143  94.642857  94.642857\n",
      "3         94.642857  98.214286  94.642857\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [27, 1, 0, 1, 15, 0, 0, 3, 10]   [26, 2, 0, 2, 14, 0, 2, 2, 9]   \n",
      "1  [26, 0, 2, 2, 14, 0, 0, 0, 12]  [26, 1, 1, 2, 14, 0, 0, 0, 12]   \n",
      "2  [27, 1, 0, 1, 14, 1, 0, 1, 11]  [27, 1, 0, 1, 15, 0, 0, 1, 11]   \n",
      "3  [28, 0, 0, 0, 13, 3, 0, 0, 12]  [28, 0, 0, 0, 15, 1, 0, 0, 12]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 1, 15, 0, 1, 0, 12]  \n",
      "1  [27, 0, 1, 2, 14, 0, 0, 0, 12]  \n",
      "2  [27, 1, 0, 1, 15, 0, 1, 0, 11]  \n",
      "3  [28, 0, 0, 0, 14, 2, 0, 1, 11]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy4\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:8\n",
      "The SheetValueTestis:9\n",
      "[  6104.68444444  10211.83111111  17003.96        11297.69777778\n",
      "   4285.70222222   6195.75555556  13389.57777778  14660.27555556]\n",
      "[  6.34128392e+07   2.41627056e+08   4.84868456e+08   3.78795485e+08\n",
      "   4.98143442e+07   1.22253672e+08   3.45914898e+08   4.92726424e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.928889 (0.021773)\n",
      "The best parameter estimates forSVMis :SVC(C=5.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.067, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVM: 0.960000 (0.021773)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.951111 (0.008889)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       1.00      1.00      1.00        15\n",
      "     Animal       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        55\n",
      "\n",
      "The accuracy is:0.981818181818\n",
      "The confusion_matrix is:\n",
      "[[27  0  1]\n",
      " [ 0 15  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       0.94      1.00      0.97        15\n",
      "     Animal       0.92      0.92      0.92        12\n",
      "\n",
      "avg / total       0.96      0.96      0.96        55\n",
      "\n",
      "The accuracy is:0.963636363636\n",
      "The confusion_matrix is:\n",
      "[[27  0  1]\n",
      " [ 0 15  0]\n",
      " [ 0  1 11]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       0.83      1.00      0.91        15\n",
      "     Animal       0.90      0.75      0.82        12\n",
      "\n",
      "avg / total       0.93      0.93      0.93        55\n",
      "\n",
      "The accuracy is:0.927272727273\n",
      "The confusion_matrix is:\n",
      "[[27  0  1]\n",
      " [ 0 15  0]\n",
      " [ 0  3  9]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc    KNN_acc\n",
      "0         91.228070  85.964912  96.491228\n",
      "1         92.857143  92.857143  94.642857\n",
      "2         92.857143  94.642857  94.642857\n",
      "3         94.642857  98.214286  94.642857\n",
      "4         98.181818  96.363636  92.727273\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [27, 1, 0, 1, 15, 0, 0, 3, 10]   [26, 2, 0, 2, 14, 0, 2, 2, 9]   \n",
      "1  [26, 0, 2, 2, 14, 0, 0, 0, 12]  [26, 1, 1, 2, 14, 0, 0, 0, 12]   \n",
      "2  [27, 1, 0, 1, 14, 1, 0, 1, 11]  [27, 1, 0, 1, 15, 0, 0, 1, 11]   \n",
      "3  [28, 0, 0, 0, 13, 3, 0, 0, 12]  [28, 0, 0, 0, 15, 1, 0, 0, 12]   \n",
      "4  [27, 0, 1, 0, 15, 0, 0, 0, 12]  [27, 0, 1, 0, 15, 0, 0, 1, 11]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 1, 15, 0, 1, 0, 12]  \n",
      "1  [27, 0, 1, 2, 14, 0, 0, 0, 12]  \n",
      "2  [27, 1, 0, 1, 15, 0, 1, 0, 11]  \n",
      "3  [28, 0, 0, 0, 14, 2, 0, 1, 11]  \n",
      "4   [27, 0, 1, 0, 15, 0, 0, 3, 9]  \n",
      "name of the classifier is:DecisionTree_acc\n",
      "The total confusion matrix is:\n",
      "[[135   2   3]\n",
      " [  4  71   4]\n",
      " [  0   4  57]]\n",
      "name of the classifier is:SVM_acc\n",
      "The total confusion matrix is:\n",
      "[[134   4   2]\n",
      " [  5  73   1]\n",
      " [  2   4  55]]\n",
      "name of the classifier is:KNN_acc\n",
      "The total confusion matrix is:\n",
      "[[137   1   2]\n",
      " [  4  73   2]\n",
      " [  2   4  55]]\n"
     ]
    }
   ],
   "source": [
    "###########################Final analysis of intruder and clutter classification for all the Three outputs \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomTreesEmbedding, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "#import nltk as nl\n",
    "####simple explanation of 3 NN classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "from numpy import linalg as LA\n",
    "from collections import Counter\n",
    "from scipy.stats.mstats import zscore\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pylab as pl\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "class Results_Framework(object):\n",
    "    \n",
    "    def __init__(self,featureDimension,sheetnameValTrain,sheetnameValTest,class_column):\n",
    "        self.featureDimension = featureDimension\n",
    "        self.sheetnameValTrain = sheetnameValTrain\n",
    "        self.sheetnameValTest = sheetnameValTest\n",
    "        self.class_column = class_column\n",
    "    def read_data(self,directoryPathTrain,directoryPathTest):\n",
    "#        print \"The Feature Dimension is:\" + str(featureDimension)\n",
    "        print \"The SheetValueTrain is:\" + str(sheetnameValTrain)\n",
    "        print \"The SheetValueTestis:\" + str(sheetnameValTest)\n",
    "        val_train = pd.read_excel(directoryPathTrain,sheetname=sheetnameValTrain)\n",
    "        val_test  = pd.read_excel(directoryPathTest,sheetname=sheetnameValTest)\n",
    "        ######################################################################################################\n",
    "        val_data_train = val_train.iloc[:,self.featureDimension]\n",
    "        val_label_train = val_train.iloc[:,self.class_column]\n",
    "        val_data_test = val_test.iloc[:,self.featureDimension]\n",
    "        val_label_test = val_test.iloc[:,self.class_column]\n",
    "        #####################################################################################################\n",
    "        X_scaler = StandardScaler()\n",
    "        train_data = X_scaler.fit_transform(val_data_train)\n",
    "        test_data = X_scaler.transform(val_data_test)\n",
    "        print X_scaler.mean_\n",
    "        print X_scaler.var_\n",
    "        ###########################################################################################\n",
    "        #################################################################################\n",
    "        train_data = np.asarray(train_data)\n",
    "        \n",
    "        #print train_labels\n",
    "        #print len(train_labels)\n",
    "        #for i in range(len(val_label_train)):\n",
    "        #    if val_label_train.iloc[i]==0:\n",
    "        #        val_label_train.iloc[i]=1\n",
    "        train_labels = list(val_label_train)    \n",
    "        test_data = np.asarray(test_data)\n",
    "        \n",
    "        #for i in range(len(val_label_test)):\n",
    "        #    if val_label_test.iloc[i]==0:\n",
    "        #        val_label_test.iloc[i]=1\n",
    "        test_labels = list(val_label_test)        \n",
    "        return train_data,train_labels,test_data,test_labels\n",
    "    \n",
    "    def Class_validation(self,train_data,train_output,test_data,test_labels_modified):\n",
    "        Classifier_estimates = [];\n",
    "        cv = KFold(n=len(train_data),n_folds=5,random_state=12345,shuffle=True)\n",
    "    \n",
    "        param_grid_decison = {'max_depth': [None],\"max_features\":[None],\"min_samples_leaf\": [1,3,10],\"criterion\": [\"gini\",\"entropy\"]}\n",
    "        param_grid_random = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [\"auto\"],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]\n",
    "                 }\n",
    "        param_test_GB = {'max_depth':range(5,16,2),'n_estimators':range(50,100,10)}\n",
    "        parameter_grid_svm = [\n",
    "          {'C': [0.05,0.09,0.03,0.01,1,0.001,0.002,1.0,5.0,10,50.0,100,200,400,800,1600,3200], 'gamma': [0.067,0.06,0.07,0.065,0.01,0.02,0.05,0.08,0.03,0.1,0.001,0.002,0.1],'kernel': ['rbf']}\n",
    "         \n",
    "    ]\n",
    "        param_grid_ada = {\n",
    "              \"n_estimators\": range(100,150,10),\n",
    "             \n",
    "             }\n",
    "        param_grid_KNN =  [\n",
    "            {'n_neighbors': [5,7,9,11]}, {'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "        ]\n",
    "        #clf1 = GridSearchCV(estimator= RandomForestClassifier(n_estimators=20,random_state=1), param_grid=param_grid_random)\n",
    "        #clf3 = GridSearchCV(estimator = GradientBoostingClassifier(max_features='sqrt', subsample=0.8, random_state=1), param_grid = param_test_GB)\n",
    "        clf1 = GridSearchCV(estimator = tree.DecisionTreeClassifier(random_state=1),param_grid=param_grid_decison)\n",
    "        clf2 = GridSearchCV(estimator= SVC(random_state=1,class_weight='balanced'), param_grid=parameter_grid_svm)\n",
    "        #clf4 = GridSearchCV(estimator = AdaBoostClassifier(random_state=1), param_grid=param_grid_ada)\n",
    "        clf3 = GridSearchCV(estimator = KNN(), param_grid=param_grid_KNN)\n",
    "\n",
    "        y_train = train_output\n",
    "        \n",
    "        models = []\n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        #models.append(('ADA',clf4))\n",
    "        #models.append(('SVM', clf5))\n",
    "        #models.append(('KNN', clf6))\n",
    "    \n",
    "# evaluate each model in turn\n",
    "        results = []\n",
    "        names = []\n",
    "        scoring = 'f1_micro'\n",
    "        best_params = []\n",
    "        for name, model in models:\n",
    "            kfold = model_selection.KFold(n_splits=5, random_state=12345)\n",
    "            cv_results = model_selection.cross_val_score(model, train_data, y_train, cv=kfold, scoring=scoring)\n",
    "            results.append(cv_results)\n",
    "            names.append(name)\n",
    "            model.fit(train_data,y_train)\n",
    "            print \"The best parameter estimates for\"+str(name)+\"is :\"+str(model.best_estimator_)\n",
    "            Classifier_estimates.append(model.best_estimator_)\n",
    "            msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "            print msg\n",
    "        return  Classifier_estimates \n",
    "    def Classification_process(self,train_data_modified,train_labels_modified,test_data_modified,test_labels_True,Classifier_estimates):\n",
    "        models = []\n",
    "        #print \"The classifier:\"\n",
    "        #print Classifier_estimates[0]\n",
    "        clf1 = Classifier_estimates[0]\n",
    "        clf2 = Classifier_estimates[1]\n",
    "        clf3 = Classifier_estimates[2]\n",
    "        \n",
    "    \n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        \n",
    "        # evaluate each model in turn\n",
    "        results_accuracy = []\n",
    "        names = []\n",
    "        scoring = 'f1'\n",
    "        best_params = []\n",
    "        confusion_matrix_values = []\n",
    "        results_precision = []\n",
    "        results_recall = []\n",
    "        results_f1score = []\n",
    "        test_labels_predicted_list = []\n",
    "        for name, model in models:\n",
    "            model.fit(train_data_modified,train_labels_modified)\n",
    "            #print len(train_data_modified)\n",
    "            #print len(train_labels_modified)\n",
    "            test_labels_predicted = model.predict(test_data_modified)\n",
    "            #print len(test_labels_predicted)\n",
    "            #print len(test_labels_predicted)\n",
    "            target_names = ['Clutter','Human','Animal']\n",
    "            print \"The Iteration is :\"+ str(1)+ \"The name of the classifier is:\"+ str(name) \n",
    "            precision,recall,f_score,support = precision_recall_fscore_support(test_labels_True, test_labels_predicted,average='macro')\n",
    "            results_precision.append(100 * precision)\n",
    "            results_recall.append(100 * recall)\n",
    "            results_f1score.append(100 * f_score)\n",
    "            print (classification_report(test_labels_True, test_labels_predicted, target_names=target_names))\n",
    "            count = 0\n",
    "            for i in range(len(test_labels_predicted)):\n",
    "                test_labels_predicted_list.append(test_labels_predicted[i])\n",
    "                if(test_labels_predicted[i] == test_labels_True[i]):\n",
    "                    count = count + 1\n",
    "                    \n",
    "                \n",
    "            print \"The accuracy is:\" + str(float(float(count)/float(len(test_labels_predicted)))) \n",
    "            accuracy = 100 * (float(float(count)/float(len(test_labels_predicted))));\n",
    "            cm = confusion_matrix(test_labels_True, test_labels_predicted, labels =None)\n",
    "            print \"The confusion_matrix is:\" \n",
    "            print(cm) \n",
    "            confusion_matrix_values.append((np.reshape(cm, (1, 9))).tolist()[0])\n",
    "            results_accuracy.append(accuracy)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score\n",
    "        \n",
    "    def main_method(self,directoryTrain,directoryTest):\n",
    "        train_data_modified,train_labels_modified,test_data_modified,test_labels_modified = results_framework.read_data(directoryTrain,directoryTest);\n",
    "        Classifier_estimates = results_framework.Class_validation(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified)\n",
    "        results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.Classification_process(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified,Classifier_estimates)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score          \n",
    "\n",
    "\n",
    "\n",
    "directory_train = \"C:\\\\Users\\\\smart\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\\\\\"\n",
    "#directory_train = \"C:\\\\Users\\\\WSNLab\\\\Dropbox_Tarun\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\"\n",
    "file_name_train = \"Feature_final_case_for_all_human_and_animal_with_mog_kfold.xlsx\"\n",
    "directory_test = directory_train\n",
    "file_name_test = file_name_train\n",
    "df = pd.read_excel(directory_train+file_name_train)\n",
    "columns = len(df.columns)\n",
    "featureDimension = range(18,26)\n",
    "class_column = columns-2\n",
    "accuracy_all = []\n",
    "precision_all = []\n",
    "recall_all = []\n",
    "f1score_all = []\n",
    "confusion_matrix_sum_all = [] \n",
    "count_even = 0;\n",
    "count_odd = 1;\n",
    "for i in range(5):    \n",
    "    sheetnameValTrain = count_even;\n",
    "    sheetnameValTest  = count_odd;\n",
    "    print \"##############################################################################################\"\n",
    "    print \"The Analysis of Camera Three class accuracy\" + str(i)\n",
    "    print \"##############################################################################################\"\n",
    "    results_framework = Results_Framework(featureDimension,sheetnameValTrain,sheetnameValTest,class_column)\n",
    "    #accuracy,confusion_matrix_sum = \n",
    "    results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.main_method(os.path.join(directory_train,file_name_train),os.path.join(directory_test,file_name_test))\n",
    "    accuracy_all.append(results_accuracy)\n",
    "    precision_all.append(results_precision)\n",
    "    recall_all.append(results_recall)\n",
    "    f1score_all.append(results_f1score)\n",
    "    \n",
    "    df_accuracy=pd.DataFrame(accuracy_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_precision=pd.DataFrame(precision_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_recall=pd.DataFrame(recall_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_f1score=pd.DataFrame(f1score_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    confusion_matrix_sum_all.append(confusion_matrix_values)\n",
    "    df_confusion_matrix_sum_all=pd.DataFrame(confusion_matrix_sum_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    print \"##############################################################\"\n",
    "    print \"The final accuracies of classifier are:\"\n",
    "    print df_accuracy\n",
    "    print \"##############################################################\"\n",
    "    print \"The final confusion matrix of classifier are:\"\n",
    "    print df_confusion_matrix_sum_all\n",
    "    ###########printing of the whole confusion matrix##################################\n",
    "    if(count_even==8):\n",
    "        for i in range(np.shape(df_confusion_matrix_sum_all)[1]):\n",
    "            xlist = []\n",
    "            xlist = list((df_confusion_matrix_sum_all.iloc[:,i]))\n",
    "            a = [sum(x) for x in zip(*xlist)]\n",
    "            print \"name of the classifier is:\" + str(df_confusion_matrix_sum_all.columns[i])\n",
    "            print \"The total confusion matrix is:\"\n",
    "            print np.reshape(a,(3,3))\n",
    "            #print \"The Sucessful Target Detection is for the classifier for intruder:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[0])/(a[0] + a[1]))\n",
    "            #print \"The Sucessful False Alarms Raisec for the classifier are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[2])/(a[2] + a[3]))\n",
    "            #print \"The missed scenarios are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[1])/(a[0] + a[1]))\n",
    "            #print \"The mean accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').mean()\n",
    "            #print \"The variance of the accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').var()\n",
    "    else:\n",
    "        count_even = count_even + 2\n",
    "        count_odd = count_odd + 2\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for DecisionTree_acc\n",
      "93.9534062429\n",
      "7.04646339279\n",
      "The mean and the variance for SVM_acc\n",
      "93.6085668717\n",
      "22.2157259709\n",
      "The mean and the variance for KNN_acc\n",
      "94.6294144452\n",
      "3.365646557\n"
     ]
    }
   ],
   "source": [
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_accuracy.iloc[:,0].mean()\n",
    "print df_accuracy.iloc[:,0].var()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_accuracy.iloc[:,1].mean()\n",
    "print df_accuracy.iloc[:,1].var()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_accuracy.iloc[:,2].mean()\n",
    "print df_accuracy.iloc[:,2].var()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for precision DecisionTree_acc\n",
      "93.4566865883\n",
      "5.37831235644\n",
      "The mean and the variance for precisionSVM_acc\n",
      "93.6887224975\n",
      "12.2532902901\n",
      "The mean and the variance for precisionKNN_acc\n",
      "94.7464843586\n",
      "7.2003937851\n"
     ]
    }
   ],
   "source": [
    "print \"The mean and the variance for precision \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_precision.iloc[:,0].mean()\n",
    "print df_precision.iloc[:,0].var()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_precision.iloc[:,1].mean()\n",
    "print df_precision.iloc[:,1].var()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_precision.iloc[:,2].mean()\n",
    "print df_precision.iloc[:,2].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for recallDecisionTree_acc\n",
      "93.3821733822\n",
      "12.7013908922\n",
      "The mean and the variance for recallSVM_acc\n",
      "92.909035409\n",
      "32.6367120237\n",
      "The mean and the variance for recallKNN_acc\n",
      "93.634004884\n",
      "4.75391127577\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0c56a7bc4308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf_recall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf_recall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"The mean and the variance for recall\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_confusion_matrix_sum_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\smart\\Anaconda2\\lib\\site-packages\\pandas\\indexes\\base.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1423\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_recall.iloc[:,0].mean()\n",
    "print df_recall.iloc[:,0].var()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_recall.iloc[:,1].mean()\n",
    "print df_recall.iloc[:,1].var()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_recall.iloc[:,2].mean()\n",
    "print df_recall.iloc[:,2].var()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for fscoreDecisionTree_acc\n",
      "93.0612443307\n",
      "9.4553675374\n",
      "The mean and the variance for fscoreSVM_acc\n",
      "93.0261818071\n",
      "24.9297023234\n",
      "The mean and the variance for fscoreKNN_acc\n",
      "93.9101785873\n",
      "6.66965084777\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-74a083e2e363>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf_f1score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf_f1score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"The mean and the variance for fscore\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_confusion_matrix_sum_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\smart\\Anaconda2\\lib\\site-packages\\pandas\\indexes\\base.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1423\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "###################Calculation_of_fscore\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_f1score.iloc[:,0].mean()\n",
    "print df_f1score.iloc[:,0].var()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_f1score.iloc[:,1].mean()\n",
    "print df_f1score.iloc[:,1].var()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_f1score.iloc[:,2].mean()\n",
    "print df_f1score.iloc[:,2].var()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
