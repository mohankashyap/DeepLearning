{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smart\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy0\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:0\n",
      "The SheetValueTestis:1\n",
      "[  7781.44027016   6945.22752586   9848.8520486   11675.82923433\n",
      "  32542.90590595  37720.09186899  30765.18832316  27588.5273241\n",
      "  12679.67528228  30401.41786277]\n",
      "[  1.75342954e+08   1.77598099e+08   3.12772467e+08   7.24826426e+08\n",
      "   3.49237189e+09   7.19341119e+09   8.21886375e+09   3.83497771e+09\n",
      "   5.04782296e+08   1.48734052e+09]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 1.000000 (0.000000)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=50.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.977475 (0.014376)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.977677 (0.014056)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        57\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 13]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        57\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 13]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       0.93      1.00      0.96        13\n",
      "\n",
      "avg / total       0.98      0.98      0.98        57\n",
      "\n",
      "The accuracy is:0.982456140351\n",
      "The confusion_matrix is:\n",
      "[[27  0  1]\n",
      " [ 0 16  0]\n",
      " [ 0  0 13]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc  SVM_acc    KNN_acc\n",
      "0             100.0    100.0  98.245614\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  [28, 0, 0, 0, 16, 0, 0, 0, 13]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [27, 0, 1, 0, 16, 0, 0, 0, 13]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy1\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:2\n",
      "The SheetValueTestis:3\n",
      "[  7338.29752398   6519.41272022   9914.36363078  11755.96772696\n",
      "  28763.05060133  39244.47377827  25477.62992514  29696.58308515\n",
      "  12419.82218028  30226.39255492]\n",
      "[  1.67528748e+08   1.66909787e+08   3.26180183e+08   7.29643756e+08\n",
      "   1.28380235e+09   8.49992959e+09   4.89747114e+09   4.70030177e+09\n",
      "   4.83665713e+08   1.45343862e+09]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.991111 (0.010887)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=0.5, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.986667 (0.017778)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.986566 (0.010971)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        56\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.96      0.96      0.96        28\n",
      "      Human       1.00      0.88      0.93        16\n",
      "     Animal       0.79      0.92      0.85        12\n",
      "\n",
      "avg / total       0.94      0.93      0.93        56\n",
      "\n",
      "The accuracy is:0.928571428571\n",
      "The confusion_matrix is:\n",
      "[[27  0  1]\n",
      " [ 0 14  2]\n",
      " [ 1  0 11]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       0.94      1.00      0.97        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        56\n",
      "\n",
      "The accuracy is:0.982142857143\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc     SVM_acc    KNN_acc\n",
      "0             100.0  100.000000  98.245614\n",
      "1             100.0   92.857143  98.214286\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  [28, 0, 0, 0, 16, 0, 0, 0, 13]   \n",
      "1  [28, 0, 0, 0, 16, 0, 0, 0, 12]  [27, 0, 1, 0, 14, 2, 1, 0, 11]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [27, 0, 1, 0, 16, 0, 0, 0, 13]  \n",
      "1  [27, 1, 0, 0, 16, 0, 0, 0, 12]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy2\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:4\n",
      "The SheetValueTestis:5\n",
      "[  7483.8986697    6380.44719048  10060.82226692   9998.89626781\n",
      "  32307.96993123  35515.56173636  27424.52543302  25994.62889842\n",
      "  12403.11222671  29744.51093561]\n",
      "[  1.71123243e+08   1.52322797e+08   3.34850882e+08   3.55691534e+08\n",
      "   3.47583991e+09   6.56422967e+09   6.16885520e+09   2.91460766e+09\n",
      "   4.87477436e+08   1.33275056e+09]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 1.000000 (0.000000)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=5.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.977677 (0.019877)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='distance')\n",
      "KNN: 0.977576 (0.020105)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        56\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        56\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        56\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc     SVM_acc     KNN_acc\n",
      "0             100.0  100.000000   98.245614\n",
      "1             100.0   92.857143   98.214286\n",
      "2             100.0  100.000000  100.000000\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  [28, 0, 0, 0, 16, 0, 0, 0, 13]   \n",
      "1  [28, 0, 0, 0, 16, 0, 0, 0, 12]  [27, 0, 1, 0, 14, 2, 1, 0, 11]   \n",
      "2  [28, 0, 0, 0, 16, 0, 0, 0, 12]  [28, 0, 0, 0, 16, 0, 0, 0, 12]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [27, 0, 1, 0, 16, 0, 0, 0, 13]  \n",
      "1  [27, 1, 0, 0, 16, 0, 0, 0, 12]  \n",
      "2  [28, 0, 0, 0, 16, 0, 0, 0, 12]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy3\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:6\n",
      "The SheetValueTestis:7\n",
      "[  7380.98152752   6396.24857219   9523.801356    11330.67699061\n",
      "  31091.57647942  40183.8412049   27360.54112832  30811.61175496\n",
      "  11924.2000157   30365.82606373]\n",
      "[  1.64025283e+08   1.52173940e+08   3.00186415e+08   7.09311735e+08\n",
      "   3.27820198e+09   9.46638903e+09   6.44385763e+09   4.89960258e+09\n",
      "   4.46922146e+08   1.40319105e+09]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 1.000000 (0.000000)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=50.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.986566 (0.010971)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.982121 (0.016658)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        56\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        56\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        56\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc     SVM_acc     KNN_acc\n",
      "0             100.0  100.000000   98.245614\n",
      "1             100.0   92.857143   98.214286\n",
      "2             100.0  100.000000  100.000000\n",
      "3             100.0  100.000000  100.000000\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  [28, 0, 0, 0, 16, 0, 0, 0, 13]   \n",
      "1  [28, 0, 0, 0, 16, 0, 0, 0, 12]  [27, 0, 1, 0, 14, 2, 1, 0, 11]   \n",
      "2  [28, 0, 0, 0, 16, 0, 0, 0, 12]  [28, 0, 0, 0, 16, 0, 0, 0, 12]   \n",
      "3  [28, 0, 0, 0, 16, 0, 0, 0, 12]  [28, 0, 0, 0, 16, 0, 0, 0, 12]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [27, 0, 1, 0, 16, 0, 0, 0, 13]  \n",
      "1  [27, 1, 0, 0, 16, 0, 0, 0, 12]  \n",
      "2  [28, 0, 0, 0, 16, 0, 0, 0, 12]  \n",
      "3  [28, 0, 0, 0, 16, 0, 0, 0, 12]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy4\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:8\n",
      "The SheetValueTestis:9\n",
      "[  7257.41289281   6408.30009078   9380.91922877  11316.74006252\n",
      "  31211.84404932  38149.44242539  29758.53363798  31085.0730766\n",
      "  12576.71117711  29428.42615151]\n",
      "[  1.63224348e+08   1.53849756e+08   2.55140464e+08   6.40571874e+08\n",
      "   3.28924331e+09   7.26390476e+09   7.88890491e+09   5.04146509e+09\n",
      "   4.99218035e+08   1.35613538e+09]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 1.000000 (0.000000)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=5.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.986667 (0.010887)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.986667 (0.010887)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        15\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        55\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       0.94      1.00      0.97        15\n",
      "     Animal       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        55\n",
      "\n",
      "The accuracy is:0.981818181818\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  1 11]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.97      1.00      0.98        28\n",
      "      Human       0.94      1.00      0.97        15\n",
      "     Animal       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.97      0.96      0.96        55\n",
      "\n",
      "The accuracy is:0.963636363636\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 15  0]\n",
      " [ 1  1 10]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc     SVM_acc     KNN_acc\n",
      "0             100.0  100.000000   98.245614\n",
      "1             100.0   92.857143   98.214286\n",
      "2             100.0  100.000000  100.000000\n",
      "3             100.0  100.000000  100.000000\n",
      "4             100.0   98.181818   96.363636\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  [28, 0, 0, 0, 16, 0, 0, 0, 13]   \n",
      "1  [28, 0, 0, 0, 16, 0, 0, 0, 12]  [27, 0, 1, 0, 14, 2, 1, 0, 11]   \n",
      "2  [28, 0, 0, 0, 16, 0, 0, 0, 12]  [28, 0, 0, 0, 16, 0, 0, 0, 12]   \n",
      "3  [28, 0, 0, 0, 16, 0, 0, 0, 12]  [28, 0, 0, 0, 16, 0, 0, 0, 12]   \n",
      "4  [28, 0, 0, 0, 15, 0, 0, 0, 12]  [28, 0, 0, 0, 15, 0, 0, 1, 11]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [27, 0, 1, 0, 16, 0, 0, 0, 13]  \n",
      "1  [27, 1, 0, 0, 16, 0, 0, 0, 12]  \n",
      "2  [28, 0, 0, 0, 16, 0, 0, 0, 12]  \n",
      "3  [28, 0, 0, 0, 16, 0, 0, 0, 12]  \n",
      "4  [28, 0, 0, 0, 15, 0, 1, 1, 10]  \n",
      "name of the classifier is:DecisionTree_acc\n",
      "The total confusion matrix is:\n",
      "[[140   0   0]\n",
      " [  0  79   0]\n",
      " [  0   0  61]]\n",
      "name of the classifier is:SVM_acc\n",
      "The total confusion matrix is:\n",
      "[[139   0   1]\n",
      " [  0  77   2]\n",
      " [  1   1  59]]\n",
      "name of the classifier is:KNN_acc\n",
      "The total confusion matrix is:\n",
      "[[138   1   1]\n",
      " [  0  79   0]\n",
      " [  1   1  59]]\n"
     ]
    }
   ],
   "source": [
    "###########################Final analysis of intruder and clutter classification for all the Three outputs \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC as SVC \n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomTreesEmbedding, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "#import nltk as nl\n",
    "####simple explanation of 3 NN classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "from numpy import linalg as LA\n",
    "from collections import Counter\n",
    "from scipy.stats.mstats import zscore\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pylab as pl\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pydotplus \n",
    "from IPython.display import Image  \n",
    "\n",
    "class Results_Framework(object):\n",
    "    \n",
    "    def __init__(self,featureDimension,sheetnameValTrain,sheetnameValTest,class_column):\n",
    "        self.featureDimension = featureDimension\n",
    "        self.sheetnameValTrain = sheetnameValTrain\n",
    "        self.sheetnameValTest = sheetnameValTest\n",
    "        self.class_column = class_column\n",
    "    def read_data(self,directoryPathTrain,directoryPathTest):\n",
    "#        print \"The Feature Dimension is:\" + str(featureDimension)\n",
    "        print \"The SheetValueTrain is:\" + str(sheetnameValTrain)\n",
    "        print \"The SheetValueTestis:\" + str(sheetnameValTest)\n",
    "        val_train = pd.read_excel(directoryPathTrain,sheetname=sheetnameValTrain)\n",
    "        val_test  = pd.read_excel(directoryPathTest,sheetname=sheetnameValTest)\n",
    "        ######################################################################################################\n",
    "        val_data_train = val_train.iloc[:,self.featureDimension]\n",
    "        val_label_train = val_train.iloc[:,self.class_column]\n",
    "        val_data_test = val_test.iloc[:,self.featureDimension]\n",
    "        val_label_test = val_test.iloc[:,self.class_column]\n",
    "        #####################################################################################################\n",
    "        X_scaler = StandardScaler()\n",
    "        train_data = X_scaler.fit_transform(val_data_train)\n",
    "        test_data = X_scaler.transform(val_data_test)\n",
    "        print X_scaler.mean_\n",
    "        print X_scaler.var_\n",
    "        ###########################################################################################\n",
    "        #################################################################################\n",
    "        train_data = np.asarray(train_data)\n",
    "        \n",
    "        #print train_labels\n",
    "        #print len(train_labels)\n",
    "        #for i in range(len(val_label_train)):\n",
    "        #    if val_label_train.iloc[i]==0:\n",
    "        #        val_label_train.iloc[i]=1\n",
    "        train_labels = list(val_label_train)    \n",
    "        test_data = np.asarray(test_data)\n",
    "        \n",
    "        #for i in range(len(val_label_test)):\n",
    "        #    if val_label_test.iloc[i]==0:\n",
    "        #        val_label_test.iloc[i]=1\n",
    "        test_labels = list(val_label_test)        \n",
    "        return train_data,train_labels,test_data,test_labels\n",
    "    \n",
    "    def Class_validation(self,train_data,train_output,test_data,test_labels_modified):\n",
    "        Classifier_estimates = [];\n",
    "        cv = KFold(n=len(train_data),n_folds=5,random_state=12345,shuffle=True)\n",
    "    \n",
    "        param_grid_decison = {'max_depth': [None],\"max_features\":[None],\"min_samples_leaf\": [1,3,10],\"criterion\": [\"gini\",\"entropy\"]}\n",
    "        param_grid_random = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [\"auto\"],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]\n",
    "                 }\n",
    "        param_test_GB = {'max_depth':range(5,16,2),'n_estimators':range(50,100,10)}\n",
    "        parameter_grid_svm = [\n",
    "          {'C': [0.001,0.005,0.01,0.003,0.007,0.05,0.03,0.07,0.5,0.1,1.0,5.0,10,50.0,200,400,800,1600,3200,4800]}  \n",
    "         \n",
    "    ]\n",
    "        param_grid_ada = {\n",
    "              \"n_estimators\": range(100,150,10),\n",
    "             \n",
    "             }\n",
    "        param_grid_KNN =  [\n",
    "            {'n_neighbors': [3,5,7,9,11]}, {'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']},{'weights':['uniform', 'distance']}\n",
    "                            ]\n",
    "        #clf1 = GridSearchCV(estimator= RandomForestClassifier(n_estimators=20,random_state=1), param_grid=param_grid_random)\n",
    "        #clf3 = GridSearchCV(estimator = GradientBoostingClassifier(max_features='sqrt', subsample=0.8, random_state=1), param_grid = param_test_GB)\n",
    "        clf1 = GridSearchCV(estimator = tree.DecisionTreeClassifier(random_state=1),param_grid=param_grid_decison)\n",
    "        clf2 = GridSearchCV(estimator= SVC(random_state=1,class_weight='balanced'), param_grid=parameter_grid_svm)\n",
    "        #clf4 = GridSearchCV(estimator = AdaBoostClassifier(random_state=1), param_grid=param_grid_ada)\n",
    "        clf3 = GridSearchCV(estimator = KNN(), param_grid=param_grid_KNN)\n",
    "\n",
    "        y_train = train_output\n",
    "        \n",
    "        models = []\n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        #models.append(('ADA',clf4))\n",
    "        #models.append(('SVM', clf5))\n",
    "        #models.append(('KNN', clf6))\n",
    "    \n",
    "# evaluate each model in turn\n",
    "        results = []\n",
    "        names = []\n",
    "        scoring = 'f1_micro'\n",
    "        best_params = []\n",
    "        for name, model in models:\n",
    "            kfold = model_selection.KFold(n_splits=5, random_state=12345)\n",
    "            cv_results = model_selection.cross_val_score(model, train_data, y_train, cv=kfold, scoring=scoring)\n",
    "            results.append(cv_results)\n",
    "            names.append(name)\n",
    "            model.fit(train_data,y_train)\n",
    "            print \"The best parameter estimates for\"+str(name)+\"is :\"+str(model.best_estimator_)\n",
    "            Classifier_estimates.append(model.best_estimator_)\n",
    "            msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "            print msg\n",
    "        return  Classifier_estimates \n",
    "    def Classification_process(self,train_data_modified,train_labels_modified,test_data_modified,test_labels_True,Classifier_estimates):\n",
    "        models = []\n",
    "        #print \"The classifier:\"\n",
    "        #print Classifier_estimates[0]\n",
    "        clf1 = Classifier_estimates[0]\n",
    "        clf2 = Classifier_estimates[1]\n",
    "        clf3 = Classifier_estimates[2]\n",
    "        \n",
    "    \n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        \n",
    "        # evaluate each model in turn\n",
    "        results_accuracy = []\n",
    "        names = []\n",
    "        scoring = 'f1_micro'\n",
    "        best_params = []\n",
    "        confusion_matrix_values = []\n",
    "        results_precision = []\n",
    "        results_recall = []\n",
    "        results_f1score = []\n",
    "        test_labels_predicted_list = []\n",
    "        for name, model in models:\n",
    "            \n",
    "                #self.count_plot_Decision_Tree = self.count_plot_Decision_Tree + 1\n",
    "            model.fit(train_data_modified,train_labels_modified)\n",
    "            #print len(train_data_modified)\n",
    "            #print len(train_labels_modified)\n",
    "            test_labels_predicted = model.predict(test_data_modified)\n",
    "            '''\n",
    "            if(name=='DecisionTree'):\n",
    "                model.fit(train_data_modified,    )\n",
    "                model.predict(test_data_modified)\n",
    "                with open(\"Decision_Tree.dot\", 'w') as f:\n",
    "                    f = tree.export_graphviz(model, out_file=f)\n",
    "                os.unlink('Decision_Tree.dot')\n",
    "                dot_data = tree.export_graphviz(model, out_file=None) \n",
    "                graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "                graph.write_pdf(\"Decision_Tree_optical_e8andcorr_new.pdf\") \n",
    "                dot_data = tree.export_graphviz(model, out_file=None)  \n",
    "                graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "                Image(graph.create_png())\n",
    "             '''   \n",
    "            #print len(test_labels_predicted)\n",
    "            #print len(test_labels_predicted)\n",
    "            target_names = ['Clutter','Human','Animal']\n",
    "            print \"The Iteration is :\"+ str(1)+ \"The name of the classifier is:\"+ str(name) \n",
    "            precision,recall,f_score,support = precision_recall_fscore_support(test_labels_True, test_labels_predicted,average='macro')\n",
    "            results_precision.append(100 * precision)\n",
    "            results_recall.append(100 * recall)\n",
    "            results_f1score.append(100 * f_score)\n",
    "            print (classification_report(test_labels_True, test_labels_predicted, target_names=target_names))\n",
    "            count = 0\n",
    "            for i in range(len(test_labels_predicted)):\n",
    "                test_labels_predicted_list.append(test_labels_predicted[i])\n",
    "                if(test_labels_predicted[i] == test_labels_True[i]):\n",
    "                    count = count + 1\n",
    "                    \n",
    "                \n",
    "            print \"The accuracy is:\" + str(float(float(count)/float(len(test_labels_predicted)))) \n",
    "            accuracy = 100 * (float(float(count)/float(len(test_labels_predicted))));\n",
    "            cm = confusion_matrix(test_labels_True, test_labels_predicted, labels =None)\n",
    "            print \"The confusion_matrix is:\" \n",
    "            print(cm) \n",
    "            confusion_matrix_values.append((np.reshape(cm, (1, 9))).tolist()[0])\n",
    "            results_accuracy.append(accuracy)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score\n",
    "        \n",
    "    def main_method(self,directoryTrain,directoryTest):\n",
    "        train_data_modified,train_labels_modified,test_data_modified,test_labels_modified = results_framework.read_data(directoryTrain,directoryTest);\n",
    "        Classifier_estimates = results_framework.Class_validation(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified)\n",
    "        results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.Classification_process(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified,Classifier_estimates)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score          \n",
    "\n",
    "\n",
    "\n",
    "directory_train = \"C:\\\\Users\\\\smart\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\\\\\"\n",
    "#directory_train = \"C:\\\\Users\\\\WSNLab\\\\Dropbox_Tarun\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\"\n",
    "#file_name_train = \"Feature_final_reduced_complexity_new_version_19_window_4_clutter_random_with_ECE_windy_final_kfold.xlsx\"\n",
    "file_name_train = \"Feature_final_case_for_all_human_and_animal_with_ECE_windy_31_window_final_kfold.xlsx\"\n",
    "directory_test = directory_train\n",
    "file_name_test = file_name_train\n",
    "df = pd.read_excel(directory_train+file_name_train)\n",
    "columns = len(df.columns)\n",
    "featureDimension = range(0,10)\n",
    "class_column = columns-2\n",
    "accuracy_all = []\n",
    "precision_all = []\n",
    "recall_all = []\n",
    "f1score_all = []\n",
    "confusion_matrix_sum_all = [] \n",
    "count_even = 0;\n",
    "count_odd = 1;\n",
    "for i in range(5):    \n",
    "    sheetnameValTrain = count_even;\n",
    "    sheetnameValTest  = count_odd;\n",
    "    print \"##############################################################################################\"\n",
    "    print \"The Analysis of Camera Three class accuracy\" + str(i)\n",
    "    print \"##############################################################################################\"\n",
    "    results_framework = Results_Framework(featureDimension,sheetnameValTrain,sheetnameValTest,class_column)\n",
    "    #accuracy,confusion_matrix_sum = \n",
    "    results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.main_method(os.path.join(directory_train,file_name_train),os.path.join(directory_test,file_name_test))\n",
    "    accuracy_all.append(results_accuracy)\n",
    "    precision_all.append(results_precision)\n",
    "    recall_all.append(results_recall)\n",
    "    f1score_all.append(results_f1score)\n",
    "    \n",
    "    df_accuracy=pd.DataFrame(accuracy_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_precision=pd.DataFrame(precision_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_recall=pd.DataFrame(recall_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_f1score=pd.DataFrame(f1score_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    confusion_matrix_sum_all.append(confusion_matrix_values)\n",
    "    df_confusion_matrix_sum_all=pd.DataFrame(confusion_matrix_sum_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    print \"##############################################################\"\n",
    "    print \"The final accuracies of classifier are:\"\n",
    "    print df_accuracy\n",
    "    print \"##############################################################\"\n",
    "    print \"The final confusion matrix of classifier are:\"\n",
    "    print df_confusion_matrix_sum_all\n",
    "    ###########printing of the whole confusion matrix##################################\n",
    "    if(count_even==8):\n",
    "        for i in range(np.shape(df_confusion_matrix_sum_all)[1]):\n",
    "            xlist = []\n",
    "            xlist = list((df_confusion_matrix_sum_all.iloc[:,i]))\n",
    "            a = [sum(x) for x in zip(*xlist)]\n",
    "            print \"name of the classifier is:\" + str(df_confusion_matrix_sum_all.columns[i])\n",
    "            print \"The total confusion matrix is:\"\n",
    "            print np.reshape(a,(3,3))\n",
    "            #print \"The Sucessful Target Detection is for the classifier for intruder:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[0])/(a[0] + a[1]))\n",
    "            #print \"The Sucessful False Alarms Raisec for the classifier are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[2])/(a[2] + a[3]))\n",
    "            #print \"The missed scenarios are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[1])/(a[0] + a[1]))\n",
    "            #print \"The mean accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').mean()\n",
    "            #print \"The variance of the accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').var()\n",
    "    else:\n",
    "        count_even = count_even + 2\n",
    "        count_odd = count_odd + 2\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for DecisionTree_acc\n",
      "100.0\n",
      "0.0\n",
      "The mean and the variance for SVM_acc\n",
      "98.2077922078\n",
      "3.09298195254\n",
      "The mean and the variance for KNN_acc\n",
      "98.5647072226\n",
      "1.51570605129\n"
     ]
    }
   ],
   "source": [
    "##################Calculation_Of_Accuarcy\n",
    "\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_accuracy.iloc[:,0].mean()\n",
    "print df_accuracy.iloc[:,0].std()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_accuracy.iloc[:,1].mean()\n",
    "print df_accuracy.iloc[:,1].std()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_accuracy.iloc[:,2].mean()\n",
    "print df_accuracy.iloc[:,2].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for precision DecisionTree_acc\n",
      "100.0\n",
      "0.0\n",
      "The mean and the variance for precisionSVM_acc\n",
      "97.9166666667\n",
      "3.60843918244\n",
      "The mean and the variance for precisionKNN_acc\n",
      "98.4851009369\n",
      "1.45685807549\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \"The mean and the variance for precision \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_precision.iloc[:,0].mean()\n",
    "print df_precision.iloc[:,0].std()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_precision.iloc[:,1].mean()\n",
    "print df_precision.iloc[:,1].std()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_precision.iloc[:,2].mean()\n",
    "print df_precision.iloc[:,2].std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for recallDecisionTree_acc\n",
      "100.0\n",
      "0.0\n",
      "The mean and the variance for recallSVM_acc\n",
      "97.8174603175\n",
      "3.53820525796\n",
      "The mean and the variance for recallKNN_acc\n",
      "98.4126984127\n",
      "2.29679303627\n"
     ]
    }
   ],
   "source": [
    "###################Calculation_of_recall\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_recall.iloc[:,0].mean()\n",
    "print df_recall.iloc[:,0].std()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_recall.iloc[:,1].mean()\n",
    "print df_recall.iloc[:,1].std()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_recall.iloc[:,2].mean()\n",
    "print df_recall.iloc[:,2].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for fscoreDecisionTree_acc\n",
      "100.0\n",
      "0.0\n",
      "The mean and the variance for fscoreSVM_acc\n",
      "97.7869104559\n",
      "3.70241576402\n",
      "The mean and the variance for fscoreKNN_acc\n",
      "98.3705685415\n",
      "1.91860636027\n"
     ]
    }
   ],
   "source": [
    "###################Calculation_of_fscore\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_f1score.iloc[:,0].mean()\n",
    "print df_f1score.iloc[:,0].std()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_f1score.iloc[:,1].mean()\n",
    "print df_f1score.iloc[:,1].std()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_f1score.iloc[:,2].mean()\n",
    "print df_f1score.iloc[:,2].std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
