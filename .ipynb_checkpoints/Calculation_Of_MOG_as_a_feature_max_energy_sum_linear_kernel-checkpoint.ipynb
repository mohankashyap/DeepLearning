{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smart\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy0\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:0\n",
      "The SheetValueTestis:1\n",
      "[  6438.61854305  10748.34172185  20439.48344371  13843.76688742\n",
      "   3503.32450331   6802.73774834  15674.79470199  17728.81456954]\n",
      "[  6.22846437e+07   2.43521452e+08   5.46952932e+08   4.19017389e+08\n",
      "   5.09121418e+07   1.67476321e+08   3.82835620e+08   5.66832117e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.990728 (0.009912)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=10, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.912583 (0.017471)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.992053 (0.007723)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      0.98      0.99        89\n",
      "      Human       0.96      0.98      0.97        49\n",
      "    Clutter       0.98      1.00      0.99        52\n",
      "\n",
      "avg / total       0.98      0.98      0.98       190\n",
      "\n",
      "The accuracy is:0.984210526316\n",
      "The confusion_matrix is:\n",
      "[[87  2  0]\n",
      " [ 0 48  1]\n",
      " [ 0  0 52]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       0.94      0.98      0.96        89\n",
      "      Human       0.91      0.82      0.86        49\n",
      "    Clutter       0.94      0.96      0.95        52\n",
      "\n",
      "avg / total       0.93      0.93      0.93       190\n",
      "\n",
      "The accuracy is:0.931578947368\n",
      "The confusion_matrix is:\n",
      "[[87  2  0]\n",
      " [ 6 40  3]\n",
      " [ 0  2 50]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        89\n",
      "      Human       1.00      1.00      1.00        49\n",
      "    Clutter       1.00      1.00      1.00        52\n",
      "\n",
      "avg / total       1.00      1.00      1.00       190\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[89  0  0]\n",
      " [ 0 49  0]\n",
      " [ 0  0 52]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc  KNN_acc\n",
      "0         98.421053  93.157895    100.0\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [87, 2, 0, 0, 48, 1, 0, 0, 52]  [87, 2, 0, 6, 40, 3, 0, 2, 50]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [89, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy1\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:2\n",
      "The SheetValueTestis:3\n",
      "[  6508.21854305  10811.4781457   20483.88741722  13430.93112583\n",
      "   3426.36821192   6391.          15333.85165563  17467.65827815]\n",
      "[  6.27263414e+07   2.44712589e+08   5.49561913e+08   4.05936258e+08\n",
      "   4.87661639e+07   1.54232033e+08   3.78145467e+08   5.50522662e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.988079 (0.011394)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=10, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.908609 (0.021924)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.986755 (0.013892)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        89\n",
      "      Human       1.00      1.00      1.00        49\n",
      "    Clutter       1.00      1.00      1.00        52\n",
      "\n",
      "avg / total       1.00      1.00      1.00       190\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[89  0  0]\n",
      " [ 0 49  0]\n",
      " [ 0  0 52]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       0.89      0.93      0.91        89\n",
      "      Human       0.85      0.90      0.87        49\n",
      "    Clutter       0.96      0.83      0.89        52\n",
      "\n",
      "avg / total       0.90      0.89      0.89       190\n",
      "\n",
      "The accuracy is:0.894736842105\n",
      "The confusion_matrix is:\n",
      "[[83  5  1]\n",
      " [ 4 44  1]\n",
      " [ 6  3 43]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       0.98      1.00      0.99        89\n",
      "      Human       1.00      0.96      0.98        49\n",
      "    Clutter       1.00      1.00      1.00        52\n",
      "\n",
      "avg / total       0.99      0.99      0.99       190\n",
      "\n",
      "The accuracy is:0.989473684211\n",
      "The confusion_matrix is:\n",
      "[[89  0  0]\n",
      " [ 2 47  0]\n",
      " [ 0  0 52]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0         98.421053  93.157895  100.000000\n",
      "1        100.000000  89.473684   98.947368\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [87, 2, 0, 0, 48, 1, 0, 0, 52]  [87, 2, 0, 6, 40, 3, 0, 2, 50]   \n",
      "1  [89, 0, 0, 0, 49, 0, 0, 0, 52]  [83, 5, 1, 4, 44, 1, 6, 3, 43]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [89, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "1  [89, 0, 0, 2, 47, 0, 0, 0, 52]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy2\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:4\n",
      "The SheetValueTestis:5\n",
      "[  6669.00662252  11126.2397351   20987.08211921  14207.6794702\n",
      "   3320.40529801   6560.95364238  15339.53642384  17998.91655629]\n",
      "[  6.35053762e+07   2.43479579e+08   5.41495665e+08   4.29712107e+08\n",
      "   4.46452998e+07   1.57442793e+08   3.73311147e+08   5.66979058e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.993377 (0.007255)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=10, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.924503 (0.035688)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.994702 (0.004956)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      0.98      0.99        89\n",
      "      Human       1.00      0.98      0.99        49\n",
      "    Clutter       0.95      1.00      0.97        52\n",
      "\n",
      "avg / total       0.99      0.98      0.98       190\n",
      "\n",
      "The accuracy is:0.984210526316\n",
      "The confusion_matrix is:\n",
      "[[87  0  2]\n",
      " [ 0 48  1]\n",
      " [ 0  0 52]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       0.89      0.96      0.92        89\n",
      "      Human       0.85      0.82      0.83        49\n",
      "    Clutter       0.98      0.90      0.94        52\n",
      "\n",
      "avg / total       0.91      0.91      0.90       190\n",
      "\n",
      "The accuracy is:0.905263157895\n",
      "The confusion_matrix is:\n",
      "[[85  4  0]\n",
      " [ 8 40  1]\n",
      " [ 2  3 47]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       0.99      1.00      0.99        89\n",
      "      Human       1.00      0.92      0.96        49\n",
      "    Clutter       0.95      1.00      0.97        52\n",
      "\n",
      "avg / total       0.98      0.98      0.98       190\n",
      "\n",
      "The accuracy is:0.978947368421\n",
      "The confusion_matrix is:\n",
      "[[89  0  0]\n",
      " [ 1 45  3]\n",
      " [ 0  0 52]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0         98.421053  93.157895  100.000000\n",
      "1        100.000000  89.473684   98.947368\n",
      "2         98.421053  90.526316   97.894737\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [87, 2, 0, 0, 48, 1, 0, 0, 52]  [87, 2, 0, 6, 40, 3, 0, 2, 50]   \n",
      "1  [89, 0, 0, 0, 49, 0, 0, 0, 52]  [83, 5, 1, 4, 44, 1, 6, 3, 43]   \n",
      "2  [87, 0, 2, 0, 48, 1, 0, 0, 52]  [85, 4, 0, 8, 40, 1, 2, 3, 47]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [89, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "1  [89, 0, 0, 2, 47, 0, 0, 0, 52]  \n",
      "2  [89, 0, 0, 1, 45, 3, 0, 0, 52]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy3\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:6\n",
      "The SheetValueTestis:7\n",
      "[  6425.03566711  10605.59048877  19896.55614267  12816.98546896\n",
      "   3261.21532365   6372.24702774  15593.998679    17152.75693527]\n",
      "[  6.13693977e+07   2.31756079e+08   5.30435740e+08   3.92963326e+08\n",
      "   4.52836745e+07   1.50366928e+08   3.82923989e+08   5.49973386e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.986799 (0.013829)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=0.5, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.920774 (0.017531)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.990746 (0.006743)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      0.98      0.99        88\n",
      "      Human       1.00      1.00      1.00        49\n",
      "    Clutter       0.96      1.00      0.98        51\n",
      "\n",
      "avg / total       0.99      0.99      0.99       188\n",
      "\n",
      "The accuracy is:0.989361702128\n",
      "The confusion_matrix is:\n",
      "[[86  0  2]\n",
      " [ 0 49  0]\n",
      " [ 0  0 51]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       0.90      0.90      0.90        88\n",
      "      Human       0.75      0.82      0.78        49\n",
      "    Clutter       1.00      0.92      0.96        51\n",
      "\n",
      "avg / total       0.89      0.88      0.88       188\n",
      "\n",
      "The accuracy is:0.882978723404\n",
      "The confusion_matrix is:\n",
      "[[79  9  0]\n",
      " [ 9 40  0]\n",
      " [ 0  4 47]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        88\n",
      "      Human       1.00      1.00      1.00        49\n",
      "    Clutter       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       1.00      1.00      1.00       188\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[88  0  0]\n",
      " [ 0 49  0]\n",
      " [ 0  0 51]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0         98.421053  93.157895  100.000000\n",
      "1        100.000000  89.473684   98.947368\n",
      "2         98.421053  90.526316   97.894737\n",
      "3         98.936170  88.297872  100.000000\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [87, 2, 0, 0, 48, 1, 0, 0, 52]  [87, 2, 0, 6, 40, 3, 0, 2, 50]   \n",
      "1  [89, 0, 0, 0, 49, 0, 0, 0, 52]  [83, 5, 1, 4, 44, 1, 6, 3, 43]   \n",
      "2  [87, 0, 2, 0, 48, 1, 0, 0, 52]  [85, 4, 0, 8, 40, 1, 2, 3, 47]   \n",
      "3  [86, 0, 2, 0, 49, 0, 0, 0, 51]  [79, 9, 0, 9, 40, 0, 0, 4, 47]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [89, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "1  [89, 0, 0, 2, 47, 0, 0, 0, 52]  \n",
      "2  [89, 0, 0, 1, 45, 3, 0, 0, 52]  \n",
      "3  [88, 0, 0, 0, 49, 0, 0, 0, 51]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy4\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:8\n",
      "The SheetValueTestis:9\n",
      "[  6569.23746702  10991.66886544  20560.07783641  13319.02770449\n",
      "   3477.176781     6464.30738786  14991.85356201  16837.66754617]\n",
      "[  6.17537692e+07   2.48935059e+08   5.59555004e+08   4.08669879e+08\n",
      "   5.02809507e+07   1.61350068e+08   3.73437299e+08   5.49045808e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.992079 (0.002662)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.897037 (0.026798)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.990755 (0.006747)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        88\n",
      "      Human       1.00      1.00      1.00        48\n",
      "    Clutter       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       1.00      1.00      1.00       187\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[88  0  0]\n",
      " [ 0 48  0]\n",
      " [ 0  0 51]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       0.97      0.95      0.96        88\n",
      "      Human       0.91      0.88      0.89        48\n",
      "    Clutter       0.94      1.00      0.97        51\n",
      "\n",
      "avg / total       0.95      0.95      0.95       187\n",
      "\n",
      "The accuracy is:0.946524064171\n",
      "The confusion_matrix is:\n",
      "[[84  4  0]\n",
      " [ 3 42  3]\n",
      " [ 0  0 51]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       0.98      1.00      0.99        88\n",
      "      Human       1.00      0.96      0.98        48\n",
      "    Clutter       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       0.99      0.99      0.99       187\n",
      "\n",
      "The accuracy is:0.989304812834\n",
      "The confusion_matrix is:\n",
      "[[88  0  0]\n",
      " [ 2 46  0]\n",
      " [ 0  0 51]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0         98.421053  93.157895  100.000000\n",
      "1        100.000000  89.473684   98.947368\n",
      "2         98.421053  90.526316   97.894737\n",
      "3         98.936170  88.297872  100.000000\n",
      "4        100.000000  94.652406   98.930481\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [87, 2, 0, 0, 48, 1, 0, 0, 52]  [87, 2, 0, 6, 40, 3, 0, 2, 50]   \n",
      "1  [89, 0, 0, 0, 49, 0, 0, 0, 52]  [83, 5, 1, 4, 44, 1, 6, 3, 43]   \n",
      "2  [87, 0, 2, 0, 48, 1, 0, 0, 52]  [85, 4, 0, 8, 40, 1, 2, 3, 47]   \n",
      "3  [86, 0, 2, 0, 49, 0, 0, 0, 51]  [79, 9, 0, 9, 40, 0, 0, 4, 47]   \n",
      "4  [88, 0, 0, 0, 48, 0, 0, 0, 51]  [84, 4, 0, 3, 42, 3, 0, 0, 51]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [89, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "1  [89, 0, 0, 2, 47, 0, 0, 0, 52]  \n",
      "2  [89, 0, 0, 1, 45, 3, 0, 0, 52]  \n",
      "3  [88, 0, 0, 0, 49, 0, 0, 0, 51]  \n",
      "4  [88, 0, 0, 2, 46, 0, 0, 0, 51]  \n",
      "name of the classifier is:DecisionTree_acc\n",
      "The total confusion matrix is:\n",
      "[[437   2   4]\n",
      " [  0 242   2]\n",
      " [  0   0 258]]\n",
      "name of the classifier is:SVM_acc\n",
      "The total confusion matrix is:\n",
      "[[418  24   1]\n",
      " [ 30 206   8]\n",
      " [  8  12 238]]\n",
      "name of the classifier is:KNN_acc\n",
      "The total confusion matrix is:\n",
      "[[443   0   0]\n",
      " [  5 236   3]\n",
      " [  0   0 258]]\n"
     ]
    }
   ],
   "source": [
    "###########################Final analysis of intruder and clutter classification for all the Three outputs \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC as SVC \n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomTreesEmbedding, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "#import nltk as nl\n",
    "####simple explanation of 3 NN classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "from numpy import linalg as LA\n",
    "from collections import Counter\n",
    "from scipy.stats.mstats import zscore\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pylab as pl\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "class Results_Framework(object):\n",
    "    \n",
    "    def __init__(self,featureDimension,sheetnameValTrain,sheetnameValTest,class_column):\n",
    "        self.featureDimension = featureDimension\n",
    "        self.sheetnameValTrain = sheetnameValTrain\n",
    "        self.sheetnameValTest = sheetnameValTest\n",
    "        self.class_column = class_column\n",
    "    def read_data(self,directoryPathTrain,directoryPathTest):\n",
    "#        print \"The Feature Dimension is:\" + str(featureDimension)\n",
    "        print \"The SheetValueTrain is:\" + str(sheetnameValTrain)\n",
    "        print \"The SheetValueTestis:\" + str(sheetnameValTest)\n",
    "        val_train = pd.read_excel(directoryPathTrain,sheetname=sheetnameValTrain)\n",
    "        val_test  = pd.read_excel(directoryPathTest,sheetname=sheetnameValTest)\n",
    "        ######################################################################################################\n",
    "        val_data_train = val_train.iloc[:,self.featureDimension]\n",
    "        val_label_train = val_train.iloc[:,self.class_column]\n",
    "        val_data_test = val_test.iloc[:,self.featureDimension]\n",
    "        val_label_test = val_test.iloc[:,self.class_column]\n",
    "        #####################################################################################################\n",
    "        X_scaler = StandardScaler()\n",
    "        train_data = X_scaler.fit_transform(val_data_train)\n",
    "        test_data = X_scaler.transform(val_data_test)\n",
    "        print X_scaler.mean_\n",
    "        print X_scaler.var_\n",
    "        ###########################################################################################\n",
    "        #################################################################################\n",
    "        train_data = np.asarray(train_data)\n",
    "        \n",
    "        #print train_labels\n",
    "        #print len(train_labels)\n",
    "        #for i in range(len(val_label_train)):\n",
    "        #    if val_label_train.iloc[i]==0:\n",
    "        #        val_label_train.iloc[i]=1\n",
    "        train_labels = list(val_label_train)    \n",
    "        test_data = np.asarray(test_data)\n",
    "        \n",
    "        #for i in range(len(val_label_test)):\n",
    "        #    if val_label_test.iloc[i]==0:\n",
    "        #        val_label_test.iloc[i]=1\n",
    "        test_labels = list(val_label_test)        \n",
    "        return train_data,train_labels,test_data,test_labels\n",
    "    \n",
    "    def Class_validation(self,train_data,train_output,test_data,test_labels_modified):\n",
    "        Classifier_estimates = [];\n",
    "        cv = KFold(n=len(train_data),n_folds=5,random_state=12345,shuffle=True)\n",
    "    \n",
    "        param_grid_decison = {'max_depth': [None],\"max_features\":[None],\"min_samples_leaf\": [1,3,10],\"criterion\": [\"gini\",\"entropy\"]}\n",
    "        param_grid_random = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [\"auto\"],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]\n",
    "                 }\n",
    "        param_test_GB = {'max_depth':range(5,16,2),'n_estimators':range(50,100,10)}\n",
    "        parameter_grid_svm = [\n",
    "          {'C': [0.001,0.005,0.01,0.05,0.5,0.1,1.0,5.0,10,50.0,100,200,400,800,1600,3200,4800]}  \n",
    "         \n",
    "    ]\n",
    "        param_grid_ada = {\n",
    "              \"n_estimators\": range(100,150,10),\n",
    "             \n",
    "             }\n",
    "        param_grid_KNN =  [\n",
    "            {'n_neighbors': [3, 11]}, {'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "        ]\n",
    "        #clf1 = GridSearchCV(estimator= RandomForestClassifier(n_estimators=20,random_state=1), param_grid=param_grid_random)\n",
    "        #clf3 = GridSearchCV(estimator = GradientBoostingClassifier(max_features='sqrt', subsample=0.8, random_state=1), param_grid = param_test_GB)\n",
    "        clf1 = GridSearchCV(estimator = tree.DecisionTreeClassifier(random_state=1),param_grid=param_grid_decison)\n",
    "        clf2 = GridSearchCV(estimator= SVC(random_state=1,class_weight='balanced'), param_grid=parameter_grid_svm)\n",
    "        #clf4 = GridSearchCV(estimator = AdaBoostClassifier(random_state=1), param_grid=param_grid_ada)\n",
    "        clf3 = GridSearchCV(estimator = KNN(), param_grid=param_grid_KNN)\n",
    "\n",
    "        y_train = train_output\n",
    "        \n",
    "        models = []\n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        #models.append(('ADA',clf4))\n",
    "        #models.append(('SVM', clf5))\n",
    "        #models.append(('KNN', clf6))\n",
    "    \n",
    "# evaluate each model in turn\n",
    "        results = []\n",
    "        names = []\n",
    "        scoring = 'f1_micro'\n",
    "        best_params = []\n",
    "        for name, model in models:\n",
    "            kfold = model_selection.KFold(n_splits=5, random_state=12345)\n",
    "            cv_results = model_selection.cross_val_score(model, train_data, y_train, cv=kfold, scoring=scoring)\n",
    "            results.append(cv_results)\n",
    "            names.append(name)\n",
    "            model.fit(train_data,y_train)\n",
    "            print \"The best parameter estimates for\"+str(name)+\"is :\"+str(model.best_estimator_)\n",
    "            Classifier_estimates.append(model.best_estimator_)\n",
    "            msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "            print msg\n",
    "        return  Classifier_estimates \n",
    "    def Classification_process(self,train_data_modified,train_labels_modified,test_data_modified,test_labels_True,Classifier_estimates):\n",
    "        models = []\n",
    "        #print \"The classifier:\"\n",
    "        #print Classifier_estimates[0]\n",
    "        clf1 = Classifier_estimates[0]\n",
    "        clf2 = Classifier_estimates[1]\n",
    "        clf3 = Classifier_estimates[2]\n",
    "        \n",
    "    \n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        \n",
    "        # evaluate each model in turn\n",
    "        results_accuracy = []\n",
    "        names = []\n",
    "        scoring = 'f1'\n",
    "        best_params = []\n",
    "        confusion_matrix_values = []\n",
    "        results_precision = []\n",
    "        results_recall = []\n",
    "        results_f1score = []\n",
    "        test_labels_predicted_list = []\n",
    "        for name, model in models:\n",
    "            model.fit(train_data_modified,train_labels_modified)\n",
    "            #print len(train_data_modified)\n",
    "            #print len(train_labels_modified)\n",
    "            test_labels_predicted = model.predict(test_data_modified)\n",
    "            #print len(test_labels_predicted)\n",
    "            #print len(test_labels_predicted)\n",
    "            target_names = ['Clutter','Human','Animal']\n",
    "            print \"The Iteration is :\"+ str(1)+ \"The name of the classifier is:\"+ str(name) \n",
    "            precision,recall,f_score,support = precision_recall_fscore_support(test_labels_True, test_labels_predicted)\n",
    "            results_precision.append(precision)\n",
    "            results_recall.append(recall)\n",
    "            results_f1score.append(f_score)\n",
    "            print (classification_report(test_labels_True, test_labels_predicted, target_names=target_names))\n",
    "            count = 0\n",
    "            for i in range(len(test_labels_predicted)):\n",
    "                test_labels_predicted_list.append(test_labels_predicted[i])\n",
    "                if(test_labels_predicted[i] == test_labels_True[i]):\n",
    "                    count = count + 1\n",
    "                    \n",
    "                \n",
    "            print \"The accuracy is:\" + str(float(float(count)/float(len(test_labels_predicted)))) \n",
    "            accuracy = 100 * (float(float(count)/float(len(test_labels_predicted))));\n",
    "            cm = confusion_matrix(test_labels_True, test_labels_predicted, labels =None)\n",
    "            print \"The confusion_matrix is:\" \n",
    "            print(cm) \n",
    "            confusion_matrix_values.append((np.reshape(cm, (1, 9))).tolist()[0])\n",
    "            results_accuracy.append(accuracy)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score\n",
    "        \n",
    "    def main_method(self,directoryTrain,directoryTest):\n",
    "        train_data_modified,train_labels_modified,test_data_modified,test_labels_modified = results_framework.read_data(directoryTrain,directoryTest);\n",
    "        Classifier_estimates = results_framework.Class_validation(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified)\n",
    "        results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.Classification_process(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified,Classifier_estimates)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score          \n",
    "\n",
    "\n",
    "\n",
    "directory_train = \"C:\\\\Users\\\\smart\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\\\\\"\n",
    "#directory_train = \"C:\\\\Users\\\\WSNLab\\\\Dropbox_Tarun\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\"\n",
    "file_name_train = \"Feature_finall_combined_unVAB_CD_background_max_sum_energy_new_clutter_windy_mog_final_kfold.xlsx\"\n",
    "directory_test = directory_train\n",
    "file_name_test = file_name_train\n",
    "df = pd.read_excel(directory_train+file_name_train)\n",
    "columns = len(df.columns)\n",
    "featureDimension = range(10,18)\n",
    "class_column = columns-2\n",
    "accuracy_all = []\n",
    "precision_all = []\n",
    "recall_all = []\n",
    "f1score_all = []\n",
    "confusion_matrix_sum_all = [] \n",
    "count_even = 0;\n",
    "count_odd = 1;\n",
    "for i in range(5):    \n",
    "    sheetnameValTrain = count_even;\n",
    "    sheetnameValTest  = count_odd;\n",
    "    print \"##############################################################################################\"\n",
    "    print \"The Analysis of Camera Three class accuracy\" + str(i)\n",
    "    print \"##############################################################################################\"\n",
    "    results_framework = Results_Framework(featureDimension,sheetnameValTrain,sheetnameValTest,class_column)\n",
    "    #accuracy,confusion_matrix_sum = \n",
    "    results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.main_method(os.path.join(directory_train,file_name_train),os.path.join(directory_test,file_name_test))\n",
    "    accuracy_all.append(results_accuracy)\n",
    "    precision_all.append(results_precision)\n",
    "    recall_all.append(results_recall)\n",
    "    f1score_all.append(results_f1score)\n",
    "    \n",
    "    df_accuracy=pd.DataFrame(accuracy_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_precision=pd.DataFrame(precision_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_recall=pd.DataFrame(recall_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_f1score=pd.DataFrame(f1score_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    confusion_matrix_sum_all.append(confusion_matrix_values)\n",
    "    df_confusion_matrix_sum_all=pd.DataFrame(confusion_matrix_sum_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    print \"##############################################################\"\n",
    "    print \"The final accuracies of classifier are:\"\n",
    "    print df_accuracy\n",
    "    print \"##############################################################\"\n",
    "    print \"The final confusion matrix of classifier are:\"\n",
    "    print df_confusion_matrix_sum_all\n",
    "    ###########printing of the whole confusion matrix##################################\n",
    "    if(count_even==8):\n",
    "        for i in range(np.shape(df_confusion_matrix_sum_all)[1]):\n",
    "            xlist = []\n",
    "            xlist = list((df_confusion_matrix_sum_all.iloc[:,i]))\n",
    "            a = [sum(x) for x in zip(*xlist)]\n",
    "            print \"name of the classifier is:\" + str(df_confusion_matrix_sum_all.columns[i])\n",
    "            print \"The total confusion matrix is:\"\n",
    "            print np.reshape(a,(3,3))\n",
    "            #print \"The Sucessful Target Detection is for the classifier for intruder:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[0])/(a[0] + a[1]))\n",
    "            #print \"The Sucessful False Alarms Raisec for the classifier are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[2])/(a[2] + a[3]))\n",
    "            #print \"The missed scenarios are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[1])/(a[0] + a[1]))\n",
    "            #print \"The mean accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').mean()\n",
    "            #print \"The variance of the accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').var()\n",
    "    else:\n",
    "        count_even = count_even + 2\n",
    "        count_odd = count_odd + 2\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_accuracy.iloc[:,0].mean()\n",
    "print df_accuracy.iloc[:,0].var()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_accuracy.iloc[:,1].mean()\n",
    "print df_accuracy.iloc[:,1].var()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_accuracy.iloc[:,2].mean()\n",
    "print df_accuracy.iloc[:,2].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"The mean and the variance for precision \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_precision.iloc[:,0].mean()\n",
    "print df_precision.iloc[:,0].var()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_precision.iloc[:,1].mean()\n",
    "print df_precision.iloc[:,1].var()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_precision.iloc[:,2].mean()\n",
    "print df_precision.iloc[:,2].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_recall.iloc[:,0].mean()\n",
    "print df_recall.iloc[:,0].var()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_recall.iloc[:,1].mean()\n",
    "print df_recall.iloc[:,1].var()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_recall.iloc[:,2].mean()\n",
    "print df_recall.iloc[:,2].var()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################Calculation_of_fscore\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_f1score.iloc[:,0].mean()\n",
    "print df_f1score.iloc[:,0].var()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_f1score.iloc[:,1].mean()\n",
    "print df_f1score.iloc[:,1].var()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_f1score.iloc[:,2].mean()\n",
    "print df_f1score.iloc[:,2].var()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
