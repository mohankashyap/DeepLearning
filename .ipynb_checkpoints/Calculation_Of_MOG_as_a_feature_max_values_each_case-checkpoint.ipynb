{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smart\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy0\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:0\n",
      "The SheetValueTestis:1\n",
      "[ 10143.34304636  15873.77350993  31908.37483444  21282.60662252\n",
      "   8468.67417219  14147.33509934  31323.19072848  24679.45562914]\n",
      "[  9.98162760e+07   2.76975718e+08   7.69685949e+08   7.30735495e+08\n",
      "   1.11208741e+08   2.56304906e+08   6.09337140e+08   7.64707188e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.988079 (0.017471)\n",
      "The best parameter estimates forSVMis :SVC(C=5.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.067, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVM: 0.996026 (0.005298)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.993377 (0.004188)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       0.99      0.99      0.99        89\n",
      "      Human       0.98      0.98      0.98        49\n",
      "    Clutter       1.00      1.00      1.00        52\n",
      "\n",
      "avg / total       0.99      0.99      0.99       190\n",
      "\n",
      "The accuracy is:0.989473684211\n",
      "The confusion_matrix is:\n",
      "[[88  1  0]\n",
      " [ 1 48  0]\n",
      " [ 0  0 52]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        89\n",
      "      Human       0.98      1.00      0.99        49\n",
      "    Clutter       1.00      0.98      0.99        52\n",
      "\n",
      "avg / total       0.99      0.99      0.99       190\n",
      "\n",
      "The accuracy is:0.994736842105\n",
      "The confusion_matrix is:\n",
      "[[89  0  0]\n",
      " [ 0 49  0]\n",
      " [ 0  1 51]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        89\n",
      "      Human       1.00      1.00      1.00        49\n",
      "    Clutter       1.00      1.00      1.00        52\n",
      "\n",
      "avg / total       1.00      1.00      1.00       190\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[89  0  0]\n",
      " [ 0 49  0]\n",
      " [ 0  0 52]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc  KNN_acc\n",
      "0         98.947368  99.473684    100.0\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [88, 1, 0, 1, 48, 0, 0, 0, 52]  [89, 0, 0, 0, 49, 0, 0, 1, 51]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [89, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy1\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:2\n",
      "The SheetValueTestis:3\n",
      "[ 10156.98675497  15666.71258278  31812.95761589  20843.01192053\n",
      "   8411.51258278  13577.98278146  31302.89536424  24251.66092715]\n",
      "[  9.73100347e+07   2.71981397e+08   7.62760602e+08   7.22622616e+08\n",
      "   1.08220282e+08   2.32815947e+08   6.06541921e+08   7.49991312e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.988079 (0.009733)\n",
      "The best parameter estimates forSVMis :SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.08, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVM: 0.996026 (0.005298)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.996026 (0.005298)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        89\n",
      "      Human       0.98      1.00      0.99        49\n",
      "    Clutter       1.00      0.98      0.99        52\n",
      "\n",
      "avg / total       0.99      0.99      0.99       190\n",
      "\n",
      "The accuracy is:0.994736842105\n",
      "The confusion_matrix is:\n",
      "[[89  0  0]\n",
      " [ 0 49  0]\n",
      " [ 0  1 51]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        89\n",
      "      Human       0.98      1.00      0.99        49\n",
      "    Clutter       1.00      0.98      0.99        52\n",
      "\n",
      "avg / total       0.99      0.99      0.99       190\n",
      "\n",
      "The accuracy is:0.994736842105\n",
      "The confusion_matrix is:\n",
      "[[89  0  0]\n",
      " [ 0 49  0]\n",
      " [ 0  1 51]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        89\n",
      "      Human       0.98      1.00      0.99        49\n",
      "    Clutter       1.00      0.98      0.99        52\n",
      "\n",
      "avg / total       0.99      0.99      0.99       190\n",
      "\n",
      "The accuracy is:0.994736842105\n",
      "The confusion_matrix is:\n",
      "[[89  0  0]\n",
      " [ 0 49  0]\n",
      " [ 0  1 51]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0         98.947368  99.473684  100.000000\n",
      "1         99.473684  99.473684   99.473684\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [88, 1, 0, 1, 48, 0, 0, 0, 52]  [89, 0, 0, 0, 49, 0, 0, 1, 51]   \n",
      "1  [89, 0, 0, 0, 49, 0, 0, 1, 51]  [89, 0, 0, 0, 49, 0, 0, 1, 51]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [89, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "1  [89, 0, 0, 0, 49, 0, 0, 1, 51]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy2\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:4\n",
      "The SheetValueTestis:5\n",
      "[ 10259.6781457   16048.33245033  32057.0397351   21288.6397351\n",
      "   8393.08476821  14209.6         31426.09801325  24826.59337748]\n",
      "[  9.72315835e+07   2.70357820e+08   7.62675064e+08   7.18394541e+08\n",
      "   1.05058549e+08   2.51086081e+08   5.98589624e+08   7.63145679e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.990728 (0.009912)\n",
      "The best parameter estimates forSVMis :SVC(C=5.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.08, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVM: 0.998675 (0.002649)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.996026 (0.003244)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       0.99      1.00      0.99        89\n",
      "      Human       1.00      0.98      0.99        49\n",
      "    Clutter       1.00      1.00      1.00        52\n",
      "\n",
      "avg / total       0.99      0.99      0.99       190\n",
      "\n",
      "The accuracy is:0.994736842105\n",
      "The confusion_matrix is:\n",
      "[[89  0  0]\n",
      " [ 1 48  0]\n",
      " [ 0  0 52]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        89\n",
      "      Human       1.00      0.98      0.99        49\n",
      "    Clutter       0.98      1.00      0.99        52\n",
      "\n",
      "avg / total       0.99      0.99      0.99       190\n",
      "\n",
      "The accuracy is:0.994736842105\n",
      "The confusion_matrix is:\n",
      "[[89  0  0]\n",
      " [ 0 48  1]\n",
      " [ 0  0 52]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        89\n",
      "      Human       1.00      1.00      1.00        49\n",
      "    Clutter       1.00      1.00      1.00        52\n",
      "\n",
      "avg / total       1.00      1.00      1.00       190\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[89  0  0]\n",
      " [ 0 49  0]\n",
      " [ 0  0 52]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0         98.947368  99.473684  100.000000\n",
      "1         99.473684  99.473684   99.473684\n",
      "2         99.473684  99.473684  100.000000\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [88, 1, 0, 1, 48, 0, 0, 0, 52]  [89, 0, 0, 0, 49, 0, 0, 1, 51]   \n",
      "1  [89, 0, 0, 0, 49, 0, 0, 1, 51]  [89, 0, 0, 0, 49, 0, 0, 1, 51]   \n",
      "2  [89, 0, 0, 1, 48, 0, 0, 0, 52]  [89, 0, 0, 0, 48, 1, 0, 0, 52]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [89, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "1  [89, 0, 0, 0, 49, 0, 0, 1, 51]  \n",
      "2  [89, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy3\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:6\n",
      "The SheetValueTestis:7\n",
      "[  9965.50726552  15792.41479524  31577.66974901  19666.57859974\n",
      "   8199.54953765  13798.58652576  31134.5984148   23466.18494055]\n",
      "[  9.35982258e+07   2.61741227e+08   7.63160965e+08   6.80045746e+08\n",
      "   1.05992084e+08   2.38666500e+08   6.05619211e+08   7.37250284e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.990781 (0.015343)\n",
      "The best parameter estimates forSVMis :SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.08, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVM: 0.996044 (0.005268)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.996044 (0.005268)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        88\n",
      "      Human       1.00      1.00      1.00        49\n",
      "    Clutter       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       1.00      1.00      1.00       188\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[88  0  0]\n",
      " [ 0 49  0]\n",
      " [ 0  0 51]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        88\n",
      "      Human       1.00      1.00      1.00        49\n",
      "    Clutter       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       1.00      1.00      1.00       188\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[88  0  0]\n",
      " [ 0 49  0]\n",
      " [ 0  0 51]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        88\n",
      "      Human       1.00      1.00      1.00        49\n",
      "    Clutter       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       1.00      1.00      1.00       188\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[88  0  0]\n",
      " [ 0 49  0]\n",
      " [ 0  0 51]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc     SVM_acc     KNN_acc\n",
      "0         98.947368   99.473684  100.000000\n",
      "1         99.473684   99.473684   99.473684\n",
      "2         99.473684   99.473684  100.000000\n",
      "3        100.000000  100.000000  100.000000\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [88, 1, 0, 1, 48, 0, 0, 0, 52]  [89, 0, 0, 0, 49, 0, 0, 1, 51]   \n",
      "1  [89, 0, 0, 0, 49, 0, 0, 1, 51]  [89, 0, 0, 0, 49, 0, 0, 1, 51]   \n",
      "2  [89, 0, 0, 1, 48, 0, 0, 0, 52]  [89, 0, 0, 0, 48, 1, 0, 0, 52]   \n",
      "3  [88, 0, 0, 0, 49, 0, 0, 0, 51]  [88, 0, 0, 0, 49, 0, 0, 0, 51]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [89, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "1  [89, 0, 0, 0, 49, 0, 0, 1, 51]  \n",
      "2  [89, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "3  [88, 0, 0, 0, 49, 0, 0, 0, 51]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy4\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:8\n",
      "The SheetValueTestis:9\n",
      "[ 10345.73218997  16004.          31669.35224274  20374.54221636\n",
      "   8456.84036939  14060.9116095   31100.88918206  23495.56068602]\n",
      "[  9.96091721e+07   2.76185438e+08   7.67809796e+08   7.09512223e+08\n",
      "   1.11438802e+08   2.56378234e+08   6.07973935e+08   7.43630727e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.986842 (0.020384)\n",
      "The best parameter estimates forSVMis :SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.08, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVM: 0.994719 (0.004951)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.996044 (0.003230)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        88\n",
      "      Human       1.00      1.00      1.00        48\n",
      "    Clutter       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       1.00      1.00      1.00       187\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[88  0  0]\n",
      " [ 0 48  0]\n",
      " [ 0  0 51]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        88\n",
      "      Human       1.00      1.00      1.00        48\n",
      "    Clutter       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       1.00      1.00      1.00       187\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[88  0  0]\n",
      " [ 0 48  0]\n",
      " [ 0  0 51]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Animal       1.00      1.00      1.00        88\n",
      "      Human       1.00      1.00      1.00        48\n",
      "    Clutter       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       1.00      1.00      1.00       187\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[88  0  0]\n",
      " [ 0 48  0]\n",
      " [ 0  0 51]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc     SVM_acc     KNN_acc\n",
      "0         98.947368   99.473684  100.000000\n",
      "1         99.473684   99.473684   99.473684\n",
      "2         99.473684   99.473684  100.000000\n",
      "3        100.000000  100.000000  100.000000\n",
      "4        100.000000  100.000000  100.000000\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [88, 1, 0, 1, 48, 0, 0, 0, 52]  [89, 0, 0, 0, 49, 0, 0, 1, 51]   \n",
      "1  [89, 0, 0, 0, 49, 0, 0, 1, 51]  [89, 0, 0, 0, 49, 0, 0, 1, 51]   \n",
      "2  [89, 0, 0, 1, 48, 0, 0, 0, 52]  [89, 0, 0, 0, 48, 1, 0, 0, 52]   \n",
      "3  [88, 0, 0, 0, 49, 0, 0, 0, 51]  [88, 0, 0, 0, 49, 0, 0, 0, 51]   \n",
      "4  [88, 0, 0, 0, 48, 0, 0, 0, 51]  [88, 0, 0, 0, 48, 0, 0, 0, 51]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [89, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "1  [89, 0, 0, 0, 49, 0, 0, 1, 51]  \n",
      "2  [89, 0, 0, 0, 49, 0, 0, 0, 52]  \n",
      "3  [88, 0, 0, 0, 49, 0, 0, 0, 51]  \n",
      "4  [88, 0, 0, 0, 48, 0, 0, 0, 51]  \n",
      "name of the classifier is:DecisionTree_acc\n",
      "The total confusion matrix is:\n",
      "[[442   1   0]\n",
      " [  2 242   0]\n",
      " [  0   1 257]]\n",
      "name of the classifier is:SVM_acc\n",
      "The total confusion matrix is:\n",
      "[[443   0   0]\n",
      " [  0 243   1]\n",
      " [  0   2 256]]\n",
      "name of the classifier is:KNN_acc\n",
      "The total confusion matrix is:\n",
      "[[443   0   0]\n",
      " [  0 244   0]\n",
      " [  0   1 257]]\n"
     ]
    }
   ],
   "source": [
    "###########################Final analysis of intruder and clutter classification for all the Three outputs \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC as SVC \n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomTreesEmbedding, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "#import nltk as nl\n",
    "####simple explanation of 3 NN classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "from numpy import linalg as LA\n",
    "from collections import Counter\n",
    "from scipy.stats.mstats import zscore\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pylab as pl\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "class Results_Framework(object):\n",
    "    \n",
    "    def __init__(self,featureDimension,sheetnameValTrain,sheetnameValTest,class_column):\n",
    "        self.featureDimension = featureDimension\n",
    "        self.sheetnameValTrain = sheetnameValTrain\n",
    "        self.sheetnameValTest = sheetnameValTest\n",
    "        self.class_column = class_column\n",
    "    def read_data(self,directoryPathTrain,directoryPathTest):\n",
    "#        print \"The Feature Dimension is:\" + str(featureDimension)\n",
    "        print \"The SheetValueTrain is:\" + str(sheetnameValTrain)\n",
    "        print \"The SheetValueTestis:\" + str(sheetnameValTest)\n",
    "        val_train = pd.read_excel(directoryPathTrain,sheetname=sheetnameValTrain)\n",
    "        val_test  = pd.read_excel(directoryPathTest,sheetname=sheetnameValTest)\n",
    "        ######################################################################################################\n",
    "        val_data_train = val_train.iloc[:,self.featureDimension]\n",
    "        val_label_train = val_train.iloc[:,self.class_column]\n",
    "        val_data_test = val_test.iloc[:,self.featureDimension]\n",
    "        val_label_test = val_test.iloc[:,self.class_column]\n",
    "        #####################################################################################################\n",
    "        X_scaler = StandardScaler()\n",
    "        train_data = X_scaler.fit_transform(val_data_train)\n",
    "        test_data = X_scaler.transform(val_data_test)\n",
    "        print X_scaler.mean_\n",
    "        print X_scaler.var_\n",
    "        ###########################################################################################\n",
    "        #################################################################################\n",
    "        train_data = np.asarray(train_data)\n",
    "        \n",
    "        #print train_labels\n",
    "        #print len(train_labels)\n",
    "        #for i in range(len(val_label_train)):\n",
    "        #    if val_label_train.iloc[i]==0:\n",
    "        #        val_label_train.iloc[i]=1\n",
    "        train_labels = list(val_label_train)    \n",
    "        test_data = np.asarray(test_data)\n",
    "        \n",
    "        #for i in range(len(val_label_test)):\n",
    "        #    if val_label_test.iloc[i]==0:\n",
    "        #        val_label_test.iloc[i]=1\n",
    "        test_labels = list(val_label_test)        \n",
    "        return train_data,train_labels,test_data,test_labels\n",
    "    \n",
    "    def Class_validation(self,train_data,train_output,test_data,test_labels_modified):\n",
    "        Classifier_estimates = [];\n",
    "        cv = KFold(n=len(train_data),n_folds=5,random_state=12345,shuffle=True)\n",
    "    \n",
    "        param_grid_decison = {'max_depth': [None],\"max_features\":[None],\"min_samples_leaf\": [1,3,10],\"criterion\": [\"gini\",\"entropy\"]}\n",
    "        param_grid_random = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [\"auto\"],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]\n",
    "                 }\n",
    "        param_test_GB = {'max_depth':range(5,16,2),'n_estimators':range(50,100,10)}\n",
    "        parameter_grid_svm = [\n",
    "          {'C': [0.001,0.005,0.01,0.05,0.5,0.1,1.0,5.0,10,50.0,100,200,400,800,1600,3200,4800]}  \n",
    "         \n",
    "    ]\n",
    "        param_grid_ada = {\n",
    "              \"n_estimators\": range(100,150,10),\n",
    "             \n",
    "             }\n",
    "        param_grid_KNN =  [\n",
    "            {'n_neighbors': [3, 11]}, {'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "        ]\n",
    "        #clf1 = GridSearchCV(estimator= RandomForestClassifier(n_estimators=20,random_state=1), param_grid=param_grid_random)\n",
    "        #clf3 = GridSearchCV(estimator = GradientBoostingClassifier(max_features='sqrt', subsample=0.8, random_state=1), param_grid = param_test_GB)\n",
    "        clf1 = GridSearchCV(estimator = tree.DecisionTreeClassifier(random_state=1),param_grid=param_grid_decison)\n",
    "        clf2 = GridSearchCV(estimator= SVC(random_state=1,class_weight='balanced'), param_grid=parameter_grid_svm)\n",
    "        #clf4 = GridSearchCV(estimator = AdaBoostClassifier(random_state=1), param_grid=param_grid_ada)\n",
    "        clf3 = GridSearchCV(estimator = KNN(), param_grid=param_grid_KNN)\n",
    "\n",
    "        y_train = train_output\n",
    "        \n",
    "        models = []\n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        #models.append(('ADA',clf4))\n",
    "        #models.append(('SVM', clf5))\n",
    "        #models.append(('KNN', clf6))\n",
    "    \n",
    "# evaluate each model in turn\n",
    "        results = []\n",
    "        names = []\n",
    "        scoring = 'f1_micro'\n",
    "        best_params = []\n",
    "        for name, model in models:\n",
    "            kfold = model_selection.KFold(n_splits=5, random_state=12345)\n",
    "            cv_results = model_selection.cross_val_score(model, train_data, y_train, cv=kfold, scoring=scoring)\n",
    "            results.append(cv_results)\n",
    "            names.append(name)\n",
    "            model.fit(train_data,y_train)\n",
    "            print \"The best parameter estimates for\"+str(name)+\"is :\"+str(model.best_estimator_)\n",
    "            Classifier_estimates.append(model.best_estimator_)\n",
    "            msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "            print msg\n",
    "        return  Classifier_estimates \n",
    "    def Classification_process(self,train_data_modified,train_labels_modified,test_data_modified,test_labels_True,Classifier_estimates):\n",
    "        models = []\n",
    "        #print \"The classifier:\"\n",
    "        #print Classifier_estimates[0]\n",
    "        clf1 = Classifier_estimates[0]\n",
    "        clf2 = Classifier_estimates[1]\n",
    "        clf3 = Classifier_estimates[2]\n",
    "        \n",
    "    \n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        \n",
    "        # evaluate each model in turn\n",
    "        results_accuracy = []\n",
    "        names = []\n",
    "        scoring = 'f1'\n",
    "        best_params = []\n",
    "        confusion_matrix_values = []\n",
    "        results_precision = []\n",
    "        results_recall = []\n",
    "        results_f1score = []\n",
    "        test_labels_predicted_list = []\n",
    "        for name, model in models:\n",
    "            model.fit(train_data_modified,train_labels_modified)\n",
    "            #print len(train_data_modified)\n",
    "            #print len(train_labels_modified)\n",
    "            test_labels_predicted = model.predict(test_data_modified)\n",
    "            #print len(test_labels_predicted)\n",
    "            #print len(test_labels_predicted)\n",
    "            target_names = ['Clutter','Human','Animal']\n",
    "            print \"The Iteration is :\"+ str(1)+ \"The name of the classifier is:\"+ str(name) \n",
    "            precision,recall,f_score,support = precision_recall_fscore_support(test_labels_True, test_labels_predicted)\n",
    "            results_precision.append(precision)\n",
    "            results_recall.append(recall)\n",
    "            results_f1score.append(f_score)\n",
    "            print (classification_report(test_labels_True, test_labels_predicted, target_names=target_names))\n",
    "            count = 0\n",
    "            for i in range(len(test_labels_predicted)):\n",
    "                test_labels_predicted_list.append(test_labels_predicted[i])\n",
    "                if(test_labels_predicted[i] == test_labels_True[i]):\n",
    "                    count = count + 1\n",
    "                    \n",
    "                \n",
    "            print \"The accuracy is:\" + str(float(float(count)/float(len(test_labels_predicted)))) \n",
    "            accuracy = 100 * (float(float(count)/float(len(test_labels_predicted))));\n",
    "            cm = confusion_matrix(test_labels_True, test_labels_predicted, labels =None)\n",
    "            print \"The confusion_matrix is:\" \n",
    "            print(cm) \n",
    "            confusion_matrix_values.append((np.reshape(cm, (1, 9))).tolist()[0])\n",
    "            results_accuracy.append(accuracy)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score\n",
    "        \n",
    "    def main_method(self,directoryTrain,directoryTest):\n",
    "        train_data_modified,train_labels_modified,test_data_modified,test_labels_modified = results_framework.read_data(directoryTrain,directoryTest);\n",
    "        Classifier_estimates = results_framework.Class_validation(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified)\n",
    "        results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.Classification_process(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified,Classifier_estimates)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score          \n",
    "\n",
    "\n",
    "\n",
    "directory_train = \"C:\\\\Users\\\\smart\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\\\\\"\n",
    "#directory_train = \"C:\\\\Users\\\\WSNLab\\\\Dropbox_Tarun\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\"\n",
    "file_name_train = \"Feature_finall_combined_unVAB_CD_background_max_sum_energy_new_clutter_windy_mog_final_kfold.xlsx\"\n",
    "directory_test = directory_train\n",
    "file_name_test = file_name_train\n",
    "df = pd.read_excel(directory_train+file_name_train)\n",
    "columns = len(df.columns)\n",
    "featureDimension = range(26,34)\n",
    "class_column = columns-2\n",
    "accuracy_all = []\n",
    "precision_all = []\n",
    "recall_all = []\n",
    "f1score_all = []\n",
    "confusion_matrix_sum_all = [] \n",
    "count_even = 0;\n",
    "count_odd = 1;\n",
    "for i in range(5):    \n",
    "    sheetnameValTrain = count_even;\n",
    "    sheetnameValTest  = count_odd;\n",
    "    print \"##############################################################################################\"\n",
    "    print \"The Analysis of Camera Three class accuracy\" + str(i)\n",
    "    print \"##############################################################################################\"\n",
    "    results_framework = Results_Framework(featureDimension,sheetnameValTrain,sheetnameValTest,class_column)\n",
    "    #accuracy,confusion_matrix_sum = \n",
    "    results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.main_method(os.path.join(directory_train,file_name_train),os.path.join(directory_test,file_name_test))\n",
    "    accuracy_all.append(results_accuracy)\n",
    "    precision_all.append(results_precision)\n",
    "    recall_all.append(results_recall)\n",
    "    f1score_all.append(results_f1score)\n",
    "    \n",
    "    df_accuracy=pd.DataFrame(accuracy_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_precision=pd.DataFrame(precision_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_recall=pd.DataFrame(recall_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_f1score=pd.DataFrame(f1score_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    confusion_matrix_sum_all.append(confusion_matrix_values)\n",
    "    df_confusion_matrix_sum_all=pd.DataFrame(confusion_matrix_sum_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    print \"##############################################################\"\n",
    "    print \"The final accuracies of classifier are:\"\n",
    "    print df_accuracy\n",
    "    print \"##############################################################\"\n",
    "    print \"The final confusion matrix of classifier are:\"\n",
    "    print df_confusion_matrix_sum_all\n",
    "    ###########printing of the whole confusion matrix##################################\n",
    "    if(count_even==8):\n",
    "        for i in range(np.shape(df_confusion_matrix_sum_all)[1]):\n",
    "            xlist = []\n",
    "            xlist = list((df_confusion_matrix_sum_all.iloc[:,i]))\n",
    "            a = [sum(x) for x in zip(*xlist)]\n",
    "            print \"name of the classifier is:\" + str(df_confusion_matrix_sum_all.columns[i])\n",
    "            print \"The total confusion matrix is:\"\n",
    "            print np.reshape(a,(3,3))\n",
    "            #print \"The Sucessful Target Detection is for the classifier for intruder:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[0])/(a[0] + a[1]))\n",
    "            #print \"The Sucessful False Alarms Raisec for the classifier are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[2])/(a[2] + a[3]))\n",
    "            #print \"The missed scenarios are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[1])/(a[0] + a[1]))\n",
    "            #print \"The mean accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').mean()\n",
    "            #print \"The variance of the accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').var()\n",
    "    else:\n",
    "        count_even = count_even + 2\n",
    "        count_odd = count_odd + 2\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_accuracy.iloc[:,0].mean()\n",
    "print df_accuracy.iloc[:,0].var()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_accuracy.iloc[:,1].mean()\n",
    "print df_accuracy.iloc[:,1].var()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_accuracy.iloc[:,2].mean()\n",
    "print df_accuracy.iloc[:,2].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"The mean and the variance for precision \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_precision.iloc[:,0].mean()\n",
    "print df_precision.iloc[:,0].var()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_precision.iloc[:,1].mean()\n",
    "print df_precision.iloc[:,1].var()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_precision.iloc[:,2].mean()\n",
    "print df_precision.iloc[:,2].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_recall.iloc[:,0].mean()\n",
    "print df_recall.iloc[:,0].var()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_recall.iloc[:,1].mean()\n",
    "print df_recall.iloc[:,1].var()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_recall.iloc[:,2].mean()\n",
    "print df_recall.iloc[:,2].var()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################Calculation_of_fscore\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_f1score.iloc[:,0].mean()\n",
    "print df_f1score.iloc[:,0].var()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_f1score.iloc[:,1].mean()\n",
    "print df_f1score.iloc[:,1].var()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_f1score.iloc[:,2].mean()\n",
    "print df_f1score.iloc[:,2].var()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
