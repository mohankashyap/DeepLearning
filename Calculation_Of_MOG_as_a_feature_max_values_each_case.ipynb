{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy0\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:0\n",
      "The SheetValueTestis:1\n",
      "[  9869.41704036  15030.64125561  29026.28251121  17970.81165919\n",
      "   9337.64573991  13608.19282511  28168.96412556  20580.49327354]\n",
      "[  9.19032529e+07   2.63434299e+08   8.02367647e+08   6.83279449e+08\n",
      "   1.07736277e+08   2.21668656e+08   6.49863521e+08   7.16021168e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.986465 (0.018132)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=1, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.955253 (0.024626)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.977475 (0.028591)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       0.89      1.00      0.94        16\n",
      "     Animal       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.97      0.96      0.97        57\n",
      "\n",
      "The accuracy is:0.964912280702\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 0 16  0]\n",
      " [ 0  1 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       0.80      1.00      0.89        16\n",
      "     Animal       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.94      0.93      0.93        57\n",
      "\n",
      "The accuracy is:0.929824561404\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 0 16  0]\n",
      " [ 0  3 10]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       0.84      1.00      0.91        16\n",
      "     Animal       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.96      0.95      0.95        57\n",
      "\n",
      "The accuracy is:0.947368421053\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  3 10]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc    KNN_acc\n",
      "0         96.491228  92.982456  94.736842\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [27, 1, 0, 0, 16, 0, 0, 1, 12]  [27, 1, 0, 0, 16, 0, 0, 3, 10]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 3, 10]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy1\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:2\n",
      "The SheetValueTestis:3\n",
      "[  9851.63839286  14311.61607143  28810.04464286  17976.19196429\n",
      "   9538.31696429  13595.75892857  27612.75892857  20619.29910714]\n",
      "[  9.15285361e+07   2.44805052e+08   7.89371160e+08   6.73450092e+08\n",
      "   1.03248234e+08   2.22267169e+08   6.44866120e+08   7.38714559e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.964343 (0.017703)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=0.03, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.932828 (0.037797)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.964242 (0.017883)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      0.81      0.90        16\n",
      "     Animal       0.80      1.00      0.89        12\n",
      "\n",
      "avg / total       0.96      0.95      0.95        56\n",
      "\n",
      "The accuracy is:0.946428571429\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 13  3]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.93      0.96        28\n",
      "      Human       0.89      1.00      0.94        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.97      0.96      0.96        56\n",
      "\n",
      "The accuracy is:0.964285714286\n",
      "The confusion_matrix is:\n",
      "[[26  2  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      0.94      0.97        16\n",
      "     Animal       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        56\n",
      "\n",
      "The accuracy is:0.982142857143\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0 12]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc    KNN_acc\n",
      "0         96.491228  92.982456  94.736842\n",
      "1         94.642857  96.428571  98.214286\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [27, 1, 0, 0, 16, 0, 0, 1, 12]  [27, 1, 0, 0, 16, 0, 0, 3, 10]   \n",
      "1  [28, 0, 0, 0, 13, 3, 0, 0, 12]  [26, 2, 0, 0, 16, 0, 0, 0, 12]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 3, 10]  \n",
      "1  [28, 0, 0, 0, 15, 1, 0, 0, 12]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy2\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:4\n",
      "The SheetValueTestis:5\n",
      "[  9778.68303571  15405.29464286  29236.95089286  17761.09821429\n",
      "   9287.81696429  14032.84375     28440.94642857  20343.79017857]\n",
      "[  9.57856361e+07   2.72528044e+08   7.73892320e+08   6.78724417e+08\n",
      "   1.03649722e+08   2.33072543e+08   6.34588985e+08   7.05174171e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.977778 (0.019876)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=0.05, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.946364 (0.038855)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.991111 (0.010887)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        56\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       0.80      1.00      0.89        16\n",
      "     Animal       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.94      0.93      0.93        56\n",
      "\n",
      "The accuracy is:0.928571428571\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 0 16  0]\n",
      " [ 0  3  9]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       0.89      1.00      0.94        16\n",
      "     Animal       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.97      0.96      0.96        56\n",
      "\n",
      "The accuracy is:0.964285714286\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 0 16  0]\n",
      " [ 0  1 11]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc    KNN_acc\n",
      "0         96.491228  92.982456  94.736842\n",
      "1         94.642857  96.428571  98.214286\n",
      "2        100.000000  92.857143  96.428571\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [27, 1, 0, 0, 16, 0, 0, 1, 12]  [27, 1, 0, 0, 16, 0, 0, 3, 10]   \n",
      "1  [28, 0, 0, 0, 13, 3, 0, 0, 12]  [26, 2, 0, 0, 16, 0, 0, 0, 12]   \n",
      "2  [28, 0, 0, 0, 16, 0, 0, 0, 12]   [27, 1, 0, 0, 16, 0, 0, 3, 9]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 3, 10]  \n",
      "1  [28, 0, 0, 0, 15, 1, 0, 0, 12]  \n",
      "2  [27, 1, 0, 0, 16, 0, 0, 1, 11]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy3\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:6\n",
      "The SheetValueTestis:7\n",
      "[ 10035.27232143  15444.02232143  28844.00892857  17256.66071429\n",
      "   9850.70535714  13789.24553571  27863.93303571  19990.12053571]\n",
      "[  1.01033817e+08   2.75010598e+08   7.66751343e+08   6.71216944e+08\n",
      "   1.15408331e+08   2.31407426e+08   6.30351183e+08   7.04985189e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=3,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.973333 (0.032660)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=0.09, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.937374 (0.022277)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.964343 (0.010764)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.90      1.00      0.95        28\n",
      "      Human       0.93      0.81      0.87        16\n",
      "     Animal       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.93      0.93      0.93        56\n",
      "\n",
      "The accuracy is:0.928571428571\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 3 13  0]\n",
      " [ 0  1 11]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.97      1.00      0.98        28\n",
      "      Human       1.00      0.94      0.97        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        56\n",
      "\n",
      "The accuracy is:0.982142857143\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 1 15  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.97      1.00      0.98        28\n",
      "      Human       1.00      0.94      0.97        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        56\n",
      "\n",
      "The accuracy is:0.982142857143\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 1 15  0]\n",
      " [ 0  0 12]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc    KNN_acc\n",
      "0         96.491228  92.982456  94.736842\n",
      "1         94.642857  96.428571  98.214286\n",
      "2        100.000000  92.857143  96.428571\n",
      "3         92.857143  98.214286  98.214286\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [27, 1, 0, 0, 16, 0, 0, 1, 12]  [27, 1, 0, 0, 16, 0, 0, 3, 10]   \n",
      "1  [28, 0, 0, 0, 13, 3, 0, 0, 12]  [26, 2, 0, 0, 16, 0, 0, 0, 12]   \n",
      "2  [28, 0, 0, 0, 16, 0, 0, 0, 12]   [27, 1, 0, 0, 16, 0, 0, 3, 9]   \n",
      "3  [28, 0, 0, 3, 13, 0, 0, 1, 11]  [28, 0, 0, 1, 15, 0, 0, 0, 12]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 3, 10]  \n",
      "1  [28, 0, 0, 0, 15, 1, 0, 0, 12]  \n",
      "2  [27, 1, 0, 0, 16, 0, 0, 1, 11]  \n",
      "3  [28, 0, 0, 1, 15, 0, 0, 0, 12]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy4\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:8\n",
      "The SheetValueTestis:9\n",
      "[  9953.98666667  15317.68        28167.67111111  17797.10222222\n",
      "   9404.98222222  13629.02666667  27156.73777778  21142.98222222]\n",
      "[  9.92084925e+07   2.76859339e+08   7.63962393e+08   6.88393280e+08\n",
      "   1.14329301e+08   2.29437791e+08   6.11300708e+08   7.22572376e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.964444 (0.030144)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=0.05, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.946667 (0.038746)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.951111 (0.035556)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        15\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        55\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.89      0.94        28\n",
      "      Human       0.78      0.93      0.85        15\n",
      "     Animal       0.92      0.92      0.92        12\n",
      "\n",
      "avg / total       0.92      0.91      0.91        55\n",
      "\n",
      "The accuracy is:0.909090909091\n",
      "The confusion_matrix is:\n",
      "[[25  3  0]\n",
      " [ 0 14  1]\n",
      " [ 0  1 11]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        15\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        55\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 12]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0         96.491228  92.982456   94.736842\n",
      "1         94.642857  96.428571   98.214286\n",
      "2        100.000000  92.857143   96.428571\n",
      "3         92.857143  98.214286   98.214286\n",
      "4        100.000000  90.909091  100.000000\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [27, 1, 0, 0, 16, 0, 0, 1, 12]  [27, 1, 0, 0, 16, 0, 0, 3, 10]   \n",
      "1  [28, 0, 0, 0, 13, 3, 0, 0, 12]  [26, 2, 0, 0, 16, 0, 0, 0, 12]   \n",
      "2  [28, 0, 0, 0, 16, 0, 0, 0, 12]   [27, 1, 0, 0, 16, 0, 0, 3, 9]   \n",
      "3  [28, 0, 0, 3, 13, 0, 0, 1, 11]  [28, 0, 0, 1, 15, 0, 0, 0, 12]   \n",
      "4  [28, 0, 0, 0, 15, 0, 0, 0, 12]  [25, 3, 0, 0, 14, 1, 0, 1, 11]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 3, 10]  \n",
      "1  [28, 0, 0, 0, 15, 1, 0, 0, 12]  \n",
      "2  [27, 1, 0, 0, 16, 0, 0, 1, 11]  \n",
      "3  [28, 0, 0, 1, 15, 0, 0, 0, 12]  \n",
      "4  [28, 0, 0, 0, 15, 0, 0, 0, 12]  \n",
      "name of the classifier is:DecisionTree_acc\n",
      "The total confusion matrix is:\n",
      "[[139   1   0]\n",
      " [  3  73   3]\n",
      " [  0   2  59]]\n",
      "name of the classifier is:SVM_acc\n",
      "The total confusion matrix is:\n",
      "[[133   7   0]\n",
      " [  1  77   1]\n",
      " [  0   7  54]]\n",
      "name of the classifier is:KNN_acc\n",
      "The total confusion matrix is:\n",
      "[[139   1   0]\n",
      " [  1  77   1]\n",
      " [  0   4  57]]\n"
     ]
    }
   ],
   "source": [
    "###########################Final analysis of intruder and clutter classification for all the Three outputs \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import  LinearSVC as SVC \n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomTreesEmbedding, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "#import nltk as nl\n",
    "####simple explanation of 3 NN classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "from numpy import linalg as LA\n",
    "from collections import Counter\n",
    "from scipy.stats.mstats import zscore\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pylab as pl\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "class Results_Framework(object):\n",
    "    \n",
    "    def __init__(self,featureDimension,sheetnameValTrain,sheetnameValTest,class_column):\n",
    "        self.featureDimension = featureDimension\n",
    "        self.sheetnameValTrain = sheetnameValTrain\n",
    "        self.sheetnameValTest = sheetnameValTest\n",
    "        self.class_column = class_column\n",
    "    def read_data(self,directoryPathTrain,directoryPathTest):\n",
    "#        print \"The Feature Dimension is:\" + str(featureDimension)\n",
    "        print \"The SheetValueTrain is:\" + str(sheetnameValTrain)\n",
    "        print \"The SheetValueTestis:\" + str(sheetnameValTest)\n",
    "        val_train = pd.read_excel(directoryPathTrain,sheetname=sheetnameValTrain)\n",
    "        val_test  = pd.read_excel(directoryPathTest,sheetname=sheetnameValTest)\n",
    "        ######################################################################################################\n",
    "        val_data_train = val_train.iloc[:,self.featureDimension]\n",
    "        val_label_train = val_train.iloc[:,self.class_column]\n",
    "        val_data_test = val_test.iloc[:,self.featureDimension]\n",
    "        val_label_test = val_test.iloc[:,self.class_column]\n",
    "        #####################################################################################################\n",
    "        X_scaler = StandardScaler()\n",
    "        train_data = X_scaler.fit_transform(val_data_train)\n",
    "        test_data = X_scaler.transform(val_data_test)\n",
    "        print X_scaler.mean_\n",
    "        print X_scaler.var_\n",
    "        ###########################################################################################\n",
    "        #################################################################################\n",
    "        train_data = np.asarray(train_data)\n",
    "        \n",
    "        #print train_labels\n",
    "        #print len(train_labels)\n",
    "        #for i in range(len(val_label_train)):\n",
    "        #    if val_label_train.iloc[i]==0:\n",
    "        #        val_label_train.iloc[i]=1\n",
    "        train_labels = list(val_label_train)    \n",
    "        test_data = np.asarray(test_data)\n",
    "        \n",
    "        #for i in range(len(val_label_test)):\n",
    "        #    if val_label_test.iloc[i]==0:\n",
    "        #        val_label_test.iloc[i]=1\n",
    "        test_labels = list(val_label_test)        \n",
    "        return train_data,train_labels,test_data,test_labels\n",
    "    \n",
    "    def Class_validation(self,train_data,train_output,test_data,test_labels_modified):\n",
    "        Classifier_estimates = [];\n",
    "        cv = KFold(n=len(train_data),n_folds=5,random_state=12345,shuffle=True)\n",
    "    \n",
    "        param_grid_decison = {'max_depth': [None],\"max_features\":[None],\"min_samples_leaf\": [1,3,10],\"criterion\": [\"gini\",\"entropy\"]}\n",
    "        param_grid_random = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [\"auto\"],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]\n",
    "                 }\n",
    "        param_test_GB = {'max_depth':range(5,16,2),'n_estimators':range(50,100,10)}\n",
    "        parameter_grid_svm = [\n",
    "          {'C': [0.05,0.09,0.03,0.01,1,0.001,0.002,1.0,5.0,10,50.0,100,200,400,800,1600,3200]}#, 'gamma': [0.067,0.06,0.07,0.065,0.01,0.02,0.05,0.08,0.03,0.1,0.001,0.002,0.1],'kernel': ['rbf']}\n",
    "         \n",
    "    ]\n",
    "        param_grid_ada = {\n",
    "              \"n_estimators\": range(100,150,10),\n",
    "             \n",
    "             }\n",
    "        param_grid_KNN =  [\n",
    "            {'n_neighbors': [5,7,9,11]}, {'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "        ]\n",
    "        #clf1 = GridSearchCV(estimator= RandomForestClassifier(n_estimators=20,random_state=1), param_grid=param_grid_random)\n",
    "        #clf3 = GridSearchCV(estimator = GradientBoostingClassifier(max_features='sqrt', subsample=0.8, random_state=1), param_grid = param_test_GB)\n",
    "        clf1 = GridSearchCV(estimator = tree.DecisionTreeClassifier(random_state=1),param_grid=param_grid_decison)\n",
    "        clf2 = GridSearchCV(estimator= SVC(random_state=1,class_weight='balanced'), param_grid=parameter_grid_svm)\n",
    "        #clf4 = GridSearchCV(estimator = AdaBoostClassifier(random_state=1), param_grid=param_grid_ada)\n",
    "        clf3 = GridSearchCV(estimator = KNN(), param_grid=param_grid_KNN)\n",
    "\n",
    "        y_train = train_output\n",
    "        \n",
    "        models = []\n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        #models.append(('ADA',clf4))\n",
    "        #models.append(('SVM', clf5))\n",
    "        #models.append(('KNN', clf6))\n",
    "    \n",
    "# evaluate each model in turn\n",
    "        results = []\n",
    "        names = []\n",
    "        scoring = 'f1_micro'\n",
    "        best_params = []\n",
    "        for name, model in models:\n",
    "            kfold = model_selection.KFold(n_splits=5, random_state=12345)\n",
    "            cv_results = model_selection.cross_val_score(model, train_data, y_train, cv=kfold, scoring=scoring)\n",
    "            results.append(cv_results)\n",
    "            names.append(name)\n",
    "            model.fit(train_data,y_train)\n",
    "            print \"The best parameter estimates for\"+str(name)+\"is :\"+str(model.best_estimator_)\n",
    "            Classifier_estimates.append(model.best_estimator_)\n",
    "            msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "            print msg\n",
    "        return  Classifier_estimates \n",
    "    def Classification_process(self,train_data_modified,train_labels_modified,test_data_modified,test_labels_True,Classifier_estimates):\n",
    "        models = []\n",
    "        #print \"The classifier:\"\n",
    "        #print Classifier_estimates[0]\n",
    "        clf1 = Classifier_estimates[0]\n",
    "        clf2 = Classifier_estimates[1]\n",
    "        clf3 = Classifier_estimates[2]\n",
    "        \n",
    "    \n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        \n",
    "        # evaluate each model in turn\n",
    "        results_accuracy = []\n",
    "        names = []\n",
    "        scoring = 'f1'\n",
    "        best_params = []\n",
    "        confusion_matrix_values = []\n",
    "        results_precision = []\n",
    "        results_recall = []\n",
    "        results_f1score = []\n",
    "        test_labels_predicted_list = []\n",
    "        for name, model in models:\n",
    "            model.fit(train_data_modified,train_labels_modified)\n",
    "            #print len(train_data_modified)\n",
    "            #print len(train_labels_modified)\n",
    "            test_labels_predicted = model.predict(test_data_modified)\n",
    "            #print len(test_labels_predicted)\n",
    "            #print len(test_labels_predicted)\n",
    "            target_names = ['Clutter','Human','Animal']\n",
    "            print \"The Iteration is :\"+ str(1)+ \"The name of the classifier is:\"+ str(name) \n",
    "            precision,recall,f_score,support = precision_recall_fscore_support(test_labels_True, test_labels_predicted,average='macro')\n",
    "            results_precision.append(precision)\n",
    "            results_recall.append(recall)\n",
    "            results_f1score.append(f_score)\n",
    "            print (classification_report(test_labels_True, test_labels_predicted, target_names=target_names))\n",
    "            count = 0\n",
    "            for i in range(len(test_labels_predicted)):\n",
    "                test_labels_predicted_list.append(test_labels_predicted[i])\n",
    "                if(test_labels_predicted[i] == test_labels_True[i]):\n",
    "                    count = count + 1\n",
    "                    \n",
    "                \n",
    "            print \"The accuracy is:\" + str(float(float(count)/float(len(test_labels_predicted)))) \n",
    "            accuracy = 100 * (float(float(count)/float(len(test_labels_predicted))));\n",
    "            cm = confusion_matrix(test_labels_True, test_labels_predicted, labels =None)\n",
    "            print \"The confusion_matrix is:\" \n",
    "            print(cm) \n",
    "            confusion_matrix_values.append((np.reshape(cm, (1, 9))).tolist()[0])\n",
    "            results_accuracy.append(accuracy)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score\n",
    "        \n",
    "    def main_method(self,directoryTrain,directoryTest):\n",
    "        train_data_modified,train_labels_modified,test_data_modified,test_labels_modified = results_framework.read_data(directoryTrain,directoryTest);\n",
    "        Classifier_estimates = results_framework.Class_validation(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified)\n",
    "        results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.Classification_process(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified,Classifier_estimates)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score          \n",
    "\n",
    "\n",
    "\n",
    "directory_train = \"C:\\\\Users\\\\smart\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\\\\\"\n",
    "#directory_train = \"C:\\\\Users\\\\WSNLab\\\\Dropbox_Tarun\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\"\n",
    "file_name_train = \"Feature_final_case_for_all_human_and_animal_with_mog_kfold.xlsx\"\n",
    "directory_test = directory_train\n",
    "file_name_test = file_name_train\n",
    "df = pd.read_excel(directory_train+file_name_train)\n",
    "columns = len(df.columns)\n",
    "featureDimension = range(26,34)\n",
    "class_column = columns-2\n",
    "accuracy_all = []\n",
    "precision_all = []\n",
    "recall_all = []\n",
    "f1score_all = []\n",
    "confusion_matrix_sum_all = [] \n",
    "count_even = 0;\n",
    "count_odd = 1;\n",
    "for i in range(5):    \n",
    "    sheetnameValTrain = count_even;\n",
    "    sheetnameValTest  = count_odd;\n",
    "    print \"##############################################################################################\"\n",
    "    print \"The Analysis of Camera Three class accuracy\" + str(i)\n",
    "    print \"##############################################################################################\"\n",
    "    results_framework = Results_Framework(featureDimension,sheetnameValTrain,sheetnameValTest,class_column)\n",
    "    #accuracy,confusion_matrix_sum = \n",
    "    results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.main_method(os.path.join(directory_train,file_name_train),os.path.join(directory_test,file_name_test))\n",
    "    accuracy_all.append(results_accuracy)\n",
    "    precision_all.append(results_precision)\n",
    "    recall_all.append(results_recall)\n",
    "    f1score_all.append(results_f1score)\n",
    "    \n",
    "    df_accuracy=pd.DataFrame(accuracy_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_precision=pd.DataFrame(precision_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_recall=pd.DataFrame(recall_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_f1score=pd.DataFrame(f1score_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    confusion_matrix_sum_all.append(confusion_matrix_values)\n",
    "    df_confusion_matrix_sum_all=pd.DataFrame(confusion_matrix_sum_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    print \"##############################################################\"\n",
    "    print \"The final accuracies of classifier are:\"\n",
    "    print df_accuracy\n",
    "    print \"##############################################################\"\n",
    "    print \"The final confusion matrix of classifier are:\"\n",
    "    print df_confusion_matrix_sum_all\n",
    "    ###########printing of the whole confusion matrix##################################\n",
    "    if(count_even==8):\n",
    "        for i in range(np.shape(df_confusion_matrix_sum_all)[1]):\n",
    "            xlist = []\n",
    "            xlist = list((df_confusion_matrix_sum_all.iloc[:,i]))\n",
    "            a = [sum(x) for x in zip(*xlist)]\n",
    "            print \"name of the classifier is:\" + str(df_confusion_matrix_sum_all.columns[i])\n",
    "            print \"The total confusion matrix is:\"\n",
    "            print np.reshape(a,(3,3))\n",
    "            #print \"The Sucessful Target Detection is for the classifier for intruder:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[0])/(a[0] + a[1]))\n",
    "            #print \"The Sucessful False Alarms Raisec for the classifier are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[2])/(a[2] + a[3]))\n",
    "            #print \"The missed scenarios are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[1])/(a[0] + a[1]))\n",
    "            #print \"The mean accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').mean()\n",
    "            #print \"The variance of the accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').var()\n",
    "    else:\n",
    "        count_even = count_even + 2\n",
    "        count_odd = count_odd + 2\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for DecisionTree_acc\n",
      "96.798245614\n",
      "3.19275400205\n",
      "The mean and the variance for SVM_acc\n",
      "94.2783094099\n",
      "2.96505141569\n",
      "The mean and the variance for KNN_acc\n",
      "97.5187969925\n",
      "2.00322504125\n"
     ]
    }
   ],
   "source": [
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_accuracy.iloc[:,0].mean()\n",
    "print df_accuracy.iloc[:,0].std()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_accuracy.iloc[:,1].mean()\n",
    "print df_accuracy.iloc[:,1].std()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_accuracy.iloc[:,2].mean()\n",
    "print df_accuracy.iloc[:,2].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for precision DecisionTree_acc\n",
      "0.968045741594\n",
      "0.0310418582975\n",
      "The mean and the variance for precisionSVM_acc\n",
      "0.943256704981\n",
      "0.0341597018722\n",
      "The mean and the variance for precisionKNN_acc\n",
      "0.9746392211\n",
      "0.0207096579402\n"
     ]
    }
   ],
   "source": [
    "print \"The mean and the variance for precision \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_precision.iloc[:,0].mean()\n",
    "print df_precision.iloc[:,0].std()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_precision.iloc[:,1].mean()\n",
    "print df_precision.iloc[:,1].std()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_precision.iloc[:,2].mean()\n",
    "print df_precision.iloc[:,2].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for recallDecisionTree_acc\n",
      "0.961935286935\n",
      "0.0394379304079\n",
      "The mean and the variance for recallSVM_acc\n",
      "0.937115384615\n",
      "0.0372027063947\n",
      "The mean and the variance for recallKNN_acc\n",
      "0.968345543346\n",
      "0.0289391436643\n"
     ]
    }
   ],
   "source": [
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_recall.iloc[:,0].mean()\n",
    "print df_recall.iloc[:,0].std()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_recall.iloc[:,1].mean()\n",
    "print df_recall.iloc[:,1].std()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_recall.iloc[:,2].mean()\n",
    "print df_recall.iloc[:,2].std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for fscoreDecisionTree_acc\n",
      "0.96271841424\n",
      "0.0368963929017\n",
      "The mean and the variance for fscoreSVM_acc\n",
      "0.935400497793\n",
      "0.0373975411613\n",
      "The mean and the variance for fscoreKNN_acc\n",
      "0.969420488969\n",
      "0.0273142143055\n"
     ]
    }
   ],
   "source": [
    "###################Calculation_of_fscore\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_f1score.iloc[:,0].mean()\n",
    "print df_f1score.iloc[:,0].std()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_f1score.iloc[:,1].mean()\n",
    "print df_f1score.iloc[:,1].std()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_f1score.iloc[:,2].mean()\n",
    "print df_f1score.iloc[:,2].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
