{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smart\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy0\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:0\n",
      "The SheetValueTestis:1\n",
      "[  3813.30044843   6731.31390135  14181.52466368   6202.14349776\n",
      "   4202.9103139    6344.60986547  14039.6367713   10100.48430493]\n",
      "[  5.59230919e+07   1.53716563e+08   4.22179170e+08   1.67738681e+08\n",
      "   9.05211883e+07   1.48444140e+08   4.18609542e+08   3.16967149e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.959596 (0.021861)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=0.01, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.968485 (0.023102)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.973232 (0.032647)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.97      1.00      0.98        28\n",
      "      Human       1.00      0.94      0.97        16\n",
      "     Animal       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       0.98      0.98      0.98        57\n",
      "\n",
      "The accuracy is:0.982456140351\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 1 15  0]\n",
      " [ 0  0 13]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       0.94      1.00      0.97        16\n",
      "     Animal       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       0.98      0.98      0.98        57\n",
      "\n",
      "The accuracy is:0.982456140351\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 13]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        57\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 13]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc  KNN_acc\n",
      "0         98.245614  98.245614    100.0\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 1, 15, 0, 0, 0, 13]  [27, 1, 0, 0, 16, 0, 0, 0, 13]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy1\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:2\n",
      "The SheetValueTestis:3\n",
      "[  3698.25         7213.05803571  14793.16964286   5913.62946429\n",
      "   3766.58928571   5530.98660714  12897.99107143   9984.13839286]\n",
      "[  4.99998197e+07   1.69123006e+08   4.48777839e+08   1.77583201e+08\n",
      "   7.52294582e+07   1.14371630e+08   3.99309967e+08   3.21819013e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.968889 (0.030144)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=0.05, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.986667 (0.010887)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.986667 (0.010887)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.97      1.00      0.98        28\n",
      "      Human       1.00      0.94      0.97        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        56\n",
      "\n",
      "The accuracy is:0.982142857143\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 1 15  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.82      0.90        28\n",
      "      Human       0.76      1.00      0.86        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.93      0.91      0.91        56\n",
      "\n",
      "The accuracy is:0.910714285714\n",
      "The confusion_matrix is:\n",
      "[[23  5  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.96      0.93      0.95        28\n",
      "      Human       0.89      1.00      0.94        16\n",
      "     Animal       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.95      0.95      0.95        56\n",
      "\n",
      "The accuracy is:0.946428571429\n",
      "The confusion_matrix is:\n",
      "[[26  2  0]\n",
      " [ 0 16  0]\n",
      " [ 1  0 11]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0         98.245614  98.245614  100.000000\n",
      "1         98.214286  91.071429   94.642857\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 1, 15, 0, 0, 0, 13]  [27, 1, 0, 0, 16, 0, 0, 0, 13]   \n",
      "1  [28, 0, 0, 1, 15, 0, 0, 0, 12]  [23, 5, 0, 0, 16, 0, 0, 0, 12]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  \n",
      "1  [26, 2, 0, 0, 16, 0, 1, 0, 11]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy2\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:4\n",
      "The SheetValueTestis:5\n",
      "[  3920.60267857   7639.85714286  15286.12053571   6715.29017857\n",
      "   3593.72767857   5791.76339286  13216.1875       9891.54017857]\n",
      "[  5.31451494e+07   1.79658636e+08   4.37660856e+08   1.93738181e+08\n",
      "   6.57902232e+07   1.20645045e+08   4.01488063e+08   3.09296555e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.964242 (0.017883)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=0.5, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.964242 (0.030206)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.973232 (0.025899)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        56\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       0.94      1.00      0.97        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        56\n",
      "\n",
      "The accuracy is:0.982142857143\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.93      1.00      0.97        28\n",
      "      Human       1.00      0.94      0.97        16\n",
      "     Animal       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.97      0.96      0.96        56\n",
      "\n",
      "The accuracy is:0.964285714286\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 1 15  0]\n",
      " [ 1  0 11]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc    SVM_acc     KNN_acc\n",
      "0         98.245614  98.245614  100.000000\n",
      "1         98.214286  91.071429   94.642857\n",
      "2        100.000000  98.214286   96.428571\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 1, 15, 0, 0, 0, 13]  [27, 1, 0, 0, 16, 0, 0, 0, 13]   \n",
      "1  [28, 0, 0, 1, 15, 0, 0, 0, 12]  [23, 5, 0, 0, 16, 0, 0, 0, 12]   \n",
      "2  [28, 0, 0, 0, 16, 0, 0, 0, 12]  [27, 1, 0, 0, 16, 0, 0, 0, 12]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  \n",
      "1  [26, 2, 0, 0, 16, 0, 1, 0, 11]  \n",
      "2  [28, 0, 0, 1, 15, 0, 1, 0, 11]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy3\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:6\n",
      "The SheetValueTestis:7\n",
      "[  4088.44196429   7798.73660714  15160.80803571   6838.88839286\n",
      "   4370.79464286   6399.77232143  13393.66517857  10098.94196429]\n",
      "[  5.91403362e+07   1.76978655e+08   4.48545113e+08   1.92483634e+08\n",
      "   9.41100222e+07   1.48361060e+08   3.97790549e+08   3.30226584e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.973232 (0.016604)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=0.5, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.964343 (0.026617)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.982121 (0.016658)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       0.94      0.94      0.94        16\n",
      "     Animal       0.92      0.92      0.92        12\n",
      "\n",
      "avg / total       0.96      0.96      0.96        56\n",
      "\n",
      "The accuracy is:0.964285714286\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  1 11]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        56\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        16\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        56\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0 12]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc     SVM_acc     KNN_acc\n",
      "0         98.245614   98.245614  100.000000\n",
      "1         98.214286   91.071429   94.642857\n",
      "2        100.000000   98.214286   96.428571\n",
      "3         96.428571  100.000000  100.000000\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 1, 15, 0, 0, 0, 13]  [27, 1, 0, 0, 16, 0, 0, 0, 13]   \n",
      "1  [28, 0, 0, 1, 15, 0, 0, 0, 12]  [23, 5, 0, 0, 16, 0, 0, 0, 12]   \n",
      "2  [28, 0, 0, 0, 16, 0, 0, 0, 12]  [27, 1, 0, 0, 16, 0, 0, 0, 12]   \n",
      "3  [28, 0, 0, 0, 15, 1, 0, 1, 11]  [28, 0, 0, 0, 16, 0, 0, 0, 12]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  \n",
      "1  [26, 2, 0, 0, 16, 0, 1, 0, 11]  \n",
      "2  [28, 0, 0, 1, 15, 0, 1, 0, 11]  \n",
      "3  [28, 0, 0, 0, 16, 0, 0, 0, 12]  \n",
      "##############################################################################################\n",
      "The Analysis of Camera Three class accuracy4\n",
      "##############################################################################################\n",
      "The SheetValueTrain is:8\n",
      "The SheetValueTestis:9\n",
      "[  4223.87555556   7531.23111111  15490.17777778   6961.94222222\n",
      "   4054.17777778   5856.68888889  13000.53333333  10229.21333333]\n",
      "[  6.01015309e+07   1.59025981e+08   4.47438955e+08   1.99848910e+08\n",
      "   8.70187593e+07   1.31891629e+08   3.86425848e+08   3.28161042e+08]\n",
      "The best parameter estimates forDecisionTreeis :DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "DecisionTree: 0.964444 (0.033259)\n",
      "The best parameter estimates forSVMis :LinearSVC(C=0.5, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM: 0.968889 (0.022662)\n",
      "The best parameter estimates forKNNis :KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
      "           weights='uniform')\n",
      "KNN: 0.977778 (0.014055)\n",
      "The Iteration is :1The name of the classifier is:DecisionTree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      0.96      0.98        28\n",
      "      Human       0.94      1.00      0.97        15\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        55\n",
      "\n",
      "The accuracy is:0.981818181818\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       0.96      0.96      0.96        28\n",
      "      Human       0.93      0.93      0.93        15\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.96      0.96      0.96        55\n",
      "\n",
      "The accuracy is:0.963636363636\n",
      "The confusion_matrix is:\n",
      "[[27  1  0]\n",
      " [ 1 14  0]\n",
      " [ 0  0 12]]\n",
      "The Iteration is :1The name of the classifier is:KNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Clutter       1.00      1.00      1.00        28\n",
      "      Human       1.00      1.00      1.00        15\n",
      "     Animal       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        55\n",
      "\n",
      "The accuracy is:1.0\n",
      "The confusion_matrix is:\n",
      "[[28  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 12]]\n",
      "##############################################################\n",
      "The final accuracies of classifier are:\n",
      "   DecisionTree_acc     SVM_acc     KNN_acc\n",
      "0         98.245614   98.245614  100.000000\n",
      "1         98.214286   91.071429   94.642857\n",
      "2        100.000000   98.214286   96.428571\n",
      "3         96.428571  100.000000  100.000000\n",
      "4         98.181818   96.363636  100.000000\n",
      "##############################################################\n",
      "The final confusion matrix of classifier are:\n",
      "                 DecisionTree_acc                         SVM_acc  \\\n",
      "0  [28, 0, 0, 1, 15, 0, 0, 0, 13]  [27, 1, 0, 0, 16, 0, 0, 0, 13]   \n",
      "1  [28, 0, 0, 1, 15, 0, 0, 0, 12]  [23, 5, 0, 0, 16, 0, 0, 0, 12]   \n",
      "2  [28, 0, 0, 0, 16, 0, 0, 0, 12]  [27, 1, 0, 0, 16, 0, 0, 0, 12]   \n",
      "3  [28, 0, 0, 0, 15, 1, 0, 1, 11]  [28, 0, 0, 0, 16, 0, 0, 0, 12]   \n",
      "4  [27, 1, 0, 0, 15, 0, 0, 0, 12]  [27, 1, 0, 1, 14, 0, 0, 0, 12]   \n",
      "\n",
      "                          KNN_acc  \n",
      "0  [28, 0, 0, 0, 16, 0, 0, 0, 13]  \n",
      "1  [26, 2, 0, 0, 16, 0, 1, 0, 11]  \n",
      "2  [28, 0, 0, 1, 15, 0, 1, 0, 11]  \n",
      "3  [28, 0, 0, 0, 16, 0, 0, 0, 12]  \n",
      "4  [28, 0, 0, 0, 15, 0, 0, 0, 12]  \n",
      "name of the classifier is:DecisionTree_acc\n",
      "The total confusion matrix is:\n",
      "[[139   1   0]\n",
      " [  2  76   1]\n",
      " [  0   1  60]]\n",
      "name of the classifier is:SVM_acc\n",
      "The total confusion matrix is:\n",
      "[[132   8   0]\n",
      " [  1  78   0]\n",
      " [  0   0  61]]\n",
      "name of the classifier is:KNN_acc\n",
      "The total confusion matrix is:\n",
      "[[138   2   0]\n",
      " [  1  78   0]\n",
      " [  2   0  59]]\n"
     ]
    }
   ],
   "source": [
    "###########################Final analysis of intruder and clutter classification for all the Three outputs \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC as SVC \n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomTreesEmbedding, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "#import nltk as nl\n",
    "####simple explanation of 3 NN classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "from numpy import linalg as LA\n",
    "from collections import Counter\n",
    "from scipy.stats.mstats import zscore\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pylab as pl\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "class Results_Framework(object):\n",
    "    \n",
    "    def __init__(self,featureDimension,sheetnameValTrain,sheetnameValTest,class_column):\n",
    "        self.featureDimension = featureDimension\n",
    "        self.sheetnameValTrain = sheetnameValTrain\n",
    "        self.sheetnameValTest = sheetnameValTest\n",
    "        self.class_column = class_column\n",
    "    def read_data(self,directoryPathTrain,directoryPathTest):\n",
    "#        print \"The Feature Dimension is:\" + str(featureDimension)\n",
    "        print \"The SheetValueTrain is:\" + str(sheetnameValTrain)\n",
    "        print \"The SheetValueTestis:\" + str(sheetnameValTest)\n",
    "        val_train = pd.read_excel(directoryPathTrain,sheetname=sheetnameValTrain)\n",
    "        val_test  = pd.read_excel(directoryPathTest,sheetname=sheetnameValTest)\n",
    "        ######################################################################################################\n",
    "        val_data_train = val_train.iloc[:,self.featureDimension]\n",
    "        val_label_train = val_train.iloc[:,self.class_column]\n",
    "        val_data_test = val_test.iloc[:,self.featureDimension]\n",
    "        val_label_test = val_test.iloc[:,self.class_column]\n",
    "        #####################################################################################################\n",
    "        X_scaler = StandardScaler()\n",
    "        train_data = X_scaler.fit_transform(val_data_train)\n",
    "        test_data = X_scaler.transform(val_data_test)\n",
    "        print X_scaler.mean_\n",
    "        print X_scaler.var_\n",
    "        ###########################################################################################\n",
    "        #################################################################################\n",
    "        train_data = np.asarray(train_data)\n",
    "        \n",
    "        #print train_labels\n",
    "        #print len(train_labels)\n",
    "        #for i in range(len(val_label_train)):\n",
    "        #    if val_label_train.iloc[i]==0:\n",
    "        #        val_label_train.iloc[i]=1\n",
    "        train_labels = list(val_label_train)    \n",
    "        test_data = np.asarray(test_data)\n",
    "        \n",
    "        #for i in range(len(val_label_test)):\n",
    "        #    if val_label_test.iloc[i]==0:\n",
    "        #        val_label_test.iloc[i]=1\n",
    "        test_labels = list(val_label_test)        \n",
    "        return train_data,train_labels,test_data,test_labels\n",
    "    \n",
    "    def Class_validation(self,train_data,train_output,test_data,test_labels_modified):\n",
    "        Classifier_estimates = [];\n",
    "        cv = KFold(n=len(train_data),n_folds=5,random_state=12345,shuffle=True)\n",
    "    \n",
    "        param_grid_decison = {'max_depth': [None],\"max_features\":[None],\"min_samples_leaf\": [1,3,10],\"criterion\": [\"gini\",\"entropy\"]}\n",
    "        param_grid_random = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [\"auto\"],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]\n",
    "                 }\n",
    "        param_test_GB = {'max_depth':range(5,16,2),'n_estimators':range(50,100,10)}\n",
    "        parameter_grid_svm = [\n",
    "          {'C': [0.001,0.005,0.01,0.003,0.007,0.05,0.03,0.07,0.5,0.1,1.0,5.0,10,50.0,200,400,800,1600,3200,4800]}  \n",
    "         \n",
    "    ]\n",
    "        param_grid_ada = {\n",
    "              \"n_estimators\": range(100,150,10),\n",
    "             \n",
    "             }\n",
    "        param_grid_KNN =  [\n",
    "            {'n_neighbors': [5,7,9,11]}, {'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "        ]\n",
    "        #clf1 = GridSearchCV(estimator= RandomForestClassifier(n_estimators=20,random_state=1), param_grid=param_grid_random)\n",
    "        #clf3 = GridSearchCV(estimator = GradientBoostingClassifier(max_features='sqrt', subsample=0.8, random_state=1), param_grid = param_test_GB)\n",
    "        clf1 = GridSearchCV(estimator = tree.DecisionTreeClassifier(random_state=1),param_grid=param_grid_decison)\n",
    "        clf2 = GridSearchCV(estimator= SVC(random_state=1,class_weight='balanced'), param_grid=parameter_grid_svm)\n",
    "        #clf4 = GridSearchCV(estimator = AdaBoostClassifier(random_state=1), param_grid=param_grid_ada)\n",
    "        clf3 = GridSearchCV(estimator = KNN(), param_grid=param_grid_KNN)\n",
    "\n",
    "        y_train = train_output\n",
    "        \n",
    "        models = []\n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        #models.append(('ADA',clf4))\n",
    "        #models.append(('SVM', clf5))\n",
    "        #models.append(('KNN', clf6))\n",
    "    \n",
    "# evaluate each model in turn\n",
    "        results = []\n",
    "        names = []\n",
    "        scoring = 'f1_micro'\n",
    "        best_params = []\n",
    "        for name, model in models:\n",
    "            kfold = model_selection.KFold(n_splits=5, random_state=12345)\n",
    "            cv_results = model_selection.cross_val_score(model, train_data, y_train, cv=kfold, scoring=scoring)\n",
    "            results.append(cv_results)\n",
    "            names.append(name)\n",
    "            model.fit(train_data,y_train)\n",
    "            print \"The best parameter estimates for\"+str(name)+\"is :\"+str(model.best_estimator_)\n",
    "            Classifier_estimates.append(model.best_estimator_)\n",
    "            msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "            print msg\n",
    "        return  Classifier_estimates \n",
    "    def Classification_process(self,train_data_modified,train_labels_modified,test_data_modified,test_labels_True,Classifier_estimates):\n",
    "        models = []\n",
    "        #print \"The classifier:\"\n",
    "        #print Classifier_estimates[0]\n",
    "        clf1 = Classifier_estimates[0]\n",
    "        clf2 = Classifier_estimates[1]\n",
    "        clf3 = Classifier_estimates[2]\n",
    "        \n",
    "    \n",
    "        models.append(('DecisionTree',clf1 ))\n",
    "        models.append(('SVM', clf2))\n",
    "        models.append(('KNN', clf3))\n",
    "        \n",
    "        # evaluate each model in turn\n",
    "        results_accuracy = []\n",
    "        names = []\n",
    "        scoring = 'f1_micro'\n",
    "        best_params = []\n",
    "        confusion_matrix_values = []\n",
    "        results_precision = []\n",
    "        results_recall = []\n",
    "        results_f1score = []\n",
    "        test_labels_predicted_list = []\n",
    "        for name, model in models:\n",
    "            model.fit(train_data_modified,train_labels_modified)\n",
    "            #print len(train_data_modified)\n",
    "            #print len(train_labels_modified)\n",
    "            test_labels_predicted = model.predict(test_data_modified)\n",
    "            #print len(test_labels_predicted)\n",
    "            #print len(test_labels_predicted)\n",
    "            target_names = ['Clutter','Human','Animal']\n",
    "            print \"The Iteration is :\"+ str(1)+ \"The name of the classifier is:\"+ str(name) \n",
    "            precision,recall,f_score,support = precision_recall_fscore_support(test_labels_True, test_labels_predicted,average='macro')\n",
    "            results_precision.append(100 * precision)\n",
    "            results_recall.append(100 * recall)\n",
    "            results_f1score.append(100 * f_score)\n",
    "            print (classification_report(test_labels_True, test_labels_predicted, target_names=target_names))\n",
    "            count = 0\n",
    "            for i in range(len(test_labels_predicted)):\n",
    "                test_labels_predicted_list.append(test_labels_predicted[i])\n",
    "                if(test_labels_predicted[i] == test_labels_True[i]):\n",
    "                    count = count + 1\n",
    "                    \n",
    "                \n",
    "            print \"The accuracy is:\" + str(float(float(count)/float(len(test_labels_predicted)))) \n",
    "            accuracy = 100 * (float(float(count)/float(len(test_labels_predicted))));\n",
    "            cm = confusion_matrix(test_labels_True, test_labels_predicted, labels =None)\n",
    "            print \"The confusion_matrix is:\" \n",
    "            print(cm) \n",
    "            confusion_matrix_values.append((np.reshape(cm, (1, 9))).tolist()[0])\n",
    "            results_accuracy.append(accuracy)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score\n",
    "        \n",
    "    def main_method(self,directoryTrain,directoryTest):\n",
    "        train_data_modified,train_labels_modified,test_data_modified,test_labels_modified = results_framework.read_data(directoryTrain,directoryTest);\n",
    "        Classifier_estimates = results_framework.Class_validation(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified)\n",
    "        results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.Classification_process(train_data_modified,train_labels_modified,test_data_modified,test_labels_modified,Classifier_estimates)\n",
    "        return results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score          \n",
    "\n",
    "\n",
    "\n",
    "directory_train = \"C:\\\\Users\\\\smart\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\\\\\"\n",
    "#directory_train = \"C:\\\\Users\\\\WSNLab\\\\Dropbox_Tarun\\\\Dropbox\\\\Abhimanyu\\\\Algorithm_Comparison\\\\Matlab_Code\\\\Matlab_All_Codes\\\\Camera_Analysis\"\n",
    "#file_name_train = \"Feature_final_reduced_complexity_new_version_19_window_4_clutter_random_with_ECE_windy_final_kfold.xlsx\"\n",
    "file_name_train = \"Feature_final_case_for_all_human_and_animal_with_ECE_windy_31_window_final_kfold.xlsx\"\n",
    "directory_test = directory_train\n",
    "file_name_test = file_name_train\n",
    "df = pd.read_excel(directory_train+file_name_train)\n",
    "columns = len(df.columns)\n",
    "featureDimension = range(10,18)\n",
    "class_column = columns-2\n",
    "accuracy_all = []\n",
    "precision_all = []\n",
    "recall_all = []\n",
    "f1score_all = []\n",
    "confusion_matrix_sum_all = [] \n",
    "count_even = 0;\n",
    "count_odd = 1;\n",
    "for i in range(5):    \n",
    "    sheetnameValTrain = count_even;\n",
    "    sheetnameValTest  = count_odd;\n",
    "    print \"##############################################################################################\"\n",
    "    print \"The Analysis of Camera Three class accuracy\" + str(i)\n",
    "    print \"##############################################################################################\"\n",
    "    results_framework = Results_Framework(featureDimension,sheetnameValTrain,sheetnameValTest,class_column)\n",
    "    #accuracy,confusion_matrix_sum = \n",
    "    results_accuracy,confusion_matrix_values,results_precision,results_recall,results_f1score = results_framework.main_method(os.path.join(directory_train,file_name_train),os.path.join(directory_test,file_name_test))\n",
    "    accuracy_all.append(results_accuracy)\n",
    "    precision_all.append(results_precision)\n",
    "    recall_all.append(results_recall)\n",
    "    f1score_all.append(results_f1score)\n",
    "    \n",
    "    df_accuracy=pd.DataFrame(accuracy_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_precision=pd.DataFrame(precision_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_recall=pd.DataFrame(recall_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    df_f1score=pd.DataFrame(f1score_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    confusion_matrix_sum_all.append(confusion_matrix_values)\n",
    "    df_confusion_matrix_sum_all=pd.DataFrame(confusion_matrix_sum_all,columns=['DecisionTree_acc','SVM_acc','KNN_acc'])\n",
    "    \n",
    "    print \"##############################################################\"\n",
    "    print \"The final accuracies of classifier are:\"\n",
    "    print df_accuracy\n",
    "    print \"##############################################################\"\n",
    "    print \"The final confusion matrix of classifier are:\"\n",
    "    print df_confusion_matrix_sum_all\n",
    "    ###########printing of the whole confusion matrix##################################\n",
    "    if(count_even==8):\n",
    "        for i in range(np.shape(df_confusion_matrix_sum_all)[1]):\n",
    "            xlist = []\n",
    "            xlist = list((df_confusion_matrix_sum_all.iloc[:,i]))\n",
    "            a = [sum(x) for x in zip(*xlist)]\n",
    "            print \"name of the classifier is:\" + str(df_confusion_matrix_sum_all.columns[i])\n",
    "            print \"The total confusion matrix is:\"\n",
    "            print np.reshape(a,(3,3))\n",
    "            #print \"The Sucessful Target Detection is for the classifier for intruder:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[0])/(a[0] + a[1]))\n",
    "            #print \"The Sucessful False Alarms Raisec for the classifier are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[2])/(a[2] + a[3]))\n",
    "            #print \"The missed scenarios are:\" + str(df_confusion_matrix_sum_all.columns[i]) + str((a[1])/(a[0] + a[1]))\n",
    "            #print \"The mean accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').mean()\n",
    "            #print \"The variance of the accuracy is:\" + df_accuracy.iloc[:,1].astype('float64').var()\n",
    "    else:\n",
    "        count_even = count_even + 2\n",
    "        count_odd = count_odd + 2\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 11, 12, 13, 14, 15, 16, 17]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " DecisionTree_acc     SVM_acc     KNN_acc\n",
    "0         98.245614   98.245614  100.000000\n",
    "1         98.214286   91.071429   96.428571\n",
    "2         98.214286   98.214286   98.214286\n",
    "3        100.000000  100.000000   98.214286\n",
    "4         94.545455   96.363636   98.181818\n",
    "\n",
    "[[132   8   0]\n",
    " [  1  78   0]\n",
    " [  0   0  61]]\n",
    "[[130  10   0]\n",
    " [  6  73   0]\n",
    " [  0   1  60]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for DecisionTree_acc\n",
      "98.214057872\n",
      "1.26289215347\n",
      "The mean and the variance for SVM_acc\n",
      "96.7789929369\n",
      "3.44001240448\n",
      "The mean and the variance for KNN_acc\n",
      "98.2142857143\n",
      "2.52538136138\n"
     ]
    }
   ],
   "source": [
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_accuracy.iloc[:,0].mean()\n",
    "print df_accuracy.iloc[:,0].std()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_accuracy.iloc[:,1].mean()\n",
    "print df_accuracy.iloc[:,1].std()\n",
    "print \"The mean and the variance for \" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_accuracy.iloc[:,2].mean()\n",
    "print df_accuracy.iloc[:,2].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for precision DecisionTree_acc\n",
      "98.1513409962\n",
      "1.83884035689\n",
      "The mean and the variance for precisionSVM_acc\n",
      "96.9458450047\n",
      "2.98683382759\n",
      "The mean and the variance for precisionKNN_acc\n",
      "98.5679012346\n",
      "2.1834756513\n"
     ]
    }
   ],
   "source": [
    "print \"The mean and the variance for precision \" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_precision.iloc[:,0].mean()\n",
    "print df_precision.iloc[:,0].std()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_precision.iloc[:,1].mean()\n",
    "print df_precision.iloc[:,1].std()\n",
    "print \"The mean and the variance for precision\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_precision.iloc[:,2].mean()\n",
    "print df_precision.iloc[:,2].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for recallDecisionTree_acc\n",
      "97.9563492063\n",
      "1.79204126056\n",
      "The mean and the variance for recallSVM_acc\n",
      "97.6507936508\n",
      "2.36209463309\n",
      "The mean and the variance for recallKNN_acc\n",
      "97.996031746\n",
      "2.74606328544\n"
     ]
    }
   ],
   "source": [
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_recall.iloc[:,0].mean()\n",
    "print df_recall.iloc[:,0].std()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_recall.iloc[:,1].mean()\n",
    "print df_recall.iloc[:,1].std()\n",
    "print \"The mean and the variance for recall\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_recall.iloc[:,2].mean()\n",
    "print df_recall.iloc[:,2].std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and the variance for fscoreDecisionTree_acc\n",
      "98.0274862376\n",
      "1.76881620298\n",
      "The mean and the variance for fscoreSVM_acc\n",
      "97.1164999989\n",
      "2.98785147639\n",
      "The mean and the variance for fscoreKNN_acc\n",
      "98.2195578078\n",
      "2.49913428842\n"
     ]
    }
   ],
   "source": [
    "###################Calculation_of_fscore\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[0])\n",
    "print df_f1score.iloc[:,0].mean()\n",
    "print df_f1score.iloc[:,0].std()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[1])\n",
    "print df_f1score.iloc[:,1].mean()\n",
    "print df_f1score.iloc[:,1].std()\n",
    "print \"The mean and the variance for fscore\" + str(df_confusion_matrix_sum_all.columns[2])\n",
    "print df_f1score.iloc[:,2].mean()\n",
    "print df_f1score.iloc[:,2].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
